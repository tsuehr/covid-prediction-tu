{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLL_V4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d17BEQFdPTqc"
      },
      "source": [
        "import scipy.stats\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import expon, truncexpon, truncnorm, nbinom, norm\n",
        "import pandas as pd\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import distributions\n",
        "from torch import rand\n",
        "from torch import autograd\n",
        "from torch import optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdBc47jlPTqe"
      },
      "source": [
        "np.random.seed(seed=101)\n",
        "torch.manual_seed(101)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "dtype = torch.float64\n",
        "device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "EaFwH9Vm7YMg",
        "outputId": "920e1cc8-927a-4230-a1fb-09120b0bffd9"
      },
      "source": [
        "data = pd.read_csv('covid19model.csv')\n",
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>hospit</th>\n",
              "      <th>serial_interval</th>\n",
              "      <th>delay_distr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-02-17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046535</td>\n",
              "      <td>1.300600e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-02-18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.087065</td>\n",
              "      <td>3.004645e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-02-19</td>\n",
              "      <td>0</td>\n",
              "      <td>0.112061</td>\n",
              "      <td>4.467391e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-02-20</td>\n",
              "      <td>0</td>\n",
              "      <td>0.119346</td>\n",
              "      <td>5.547300e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-02-21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.114540</td>\n",
              "      <td>6.242203e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>2021-03-25</td>\n",
              "      <td>38</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.817211e-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>2021-03-26</td>\n",
              "      <td>31</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.349426e-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>2021-03-27</td>\n",
              "      <td>39</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.959313e-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>2021-03-28</td>\n",
              "      <td>32</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.633974e-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>2021-03-29</td>\n",
              "      <td>45</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.362655e-32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>407 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  hospit  serial_interval   delay_distr\n",
              "0    2020-02-17       0         0.046535  1.300600e-02\n",
              "1    2020-02-18       0         0.087065  3.004645e-02\n",
              "2    2020-02-19       0         0.112061  4.467391e-02\n",
              "3    2020-02-20       0         0.119346  5.547300e-02\n",
              "4    2020-02-21       0         0.114540  6.242203e-02\n",
              "..          ...     ...              ...           ...\n",
              "402  2021-03-25      38         0.000000  2.817211e-32\n",
              "403  2021-03-26      31         0.000000  2.349426e-32\n",
              "404  2021-03-27      39         0.000000  1.959313e-32\n",
              "405  2021-03-28      32         0.000000  1.633974e-32\n",
              "406  2021-03-29      45         0.000000  1.362655e-32\n",
              "\n",
              "[407 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2IY_KzX7uV9"
      },
      "source": [
        "# Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7remU4ygPTqf"
      },
      "source": [
        "cero = torch.tensor(0., requires_grad=False, device=device, dtype=dtype)\n",
        "num_impute = 6\n",
        "observed_daily_hospit = torch.tensor(data.hospit, requires_grad=False, device=device, dtype=dtype)\n",
        "pi = torch.tensor(data.delay_distr, requires_grad=False, device=device, dtype=dtype)\n",
        "serial_interval = torch.tensor(data.serial_interval, requires_grad=False, device=device, dtype=dtype)\n",
        "population = torch.tensor(5793636, requires_grad=False, device=device, dtype=dtype)\n",
        "num_observations = len(observed_daily_hospit)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG5jECpf77Xk"
      },
      "source": [
        "## Initialize latent variables/parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XhscamaPTqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb2c194-f423-412d-9df9-5b78d5ada18d"
      },
      "source": [
        "tau_prime = torch.tensor(np.random.exponential(1 / 0.03), requires_grad=True, device=device, dtype=dtype)\n",
        "phi_prime = torch.tensor(truncnorm.rvs((0 - 25) / 10, (np.inf - 25) / 10, loc=25, scale=10), requires_grad=True, device=device, dtype=dtype) # has to be positive, between 0-50 --> uniform # dispersion (shape) parameter for observations\n",
        "R0_prime = torch.tensor(truncnorm.rvs((2 - 3.6) / 0.8, (5 - 3.6) / 0.8, loc=3.6, scale=0.8), requires_grad=True, device=device, dtype=dtype)  # probably gamma or inverse gamma distribution (compare to truncated normal) # initial reproduction number\n",
        "alpha_prime = torch.tensor(truncnorm.rvs((0 - 1/100) / 1/100, (5/100 - 1/100) / 1/100, loc=1/100, scale=1/100), requires_grad=True, device=device, dtype=dtype) # uniform distribution between (0-5%) # probability to get hospitalized\n",
        "sigma_prime = torch.tensor(truncnorm.rvs((0 - 0.1) / 0.3, (0.5 - 0.1) / 0.3, loc=0.1, scale=0.3), requires_grad=True, device=device, dtype=dtype)  # positive, tricky, gamma or inverse gamma, log normal  --> try something out, large sigma--> prone to overfitting # standart deviation of random walk step\n",
        "\n",
        "epsilon_t = torch.zeros(num_observations, device=device)\n",
        "epsilon_t[0] = torch.distributions.Normal(cero, sigma_prime.detach()).rsample()\n",
        "for t in range(1, num_observations):\n",
        "  epsilon_t[t] = torch.distributions.Normal(epsilon_t[t - 1].detach(), sigma_prime.detach()).rsample()\n",
        "epsilon_t.requires_grad_(True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4062, -0.6443, -0.7379, -0.5224, -1.0346, -0.8584, -0.9320, -1.0597,\n",
              "        -1.2271, -2.1625, -1.9980, -1.9351, -2.5766, -2.6399, -2.8520, -2.3127,\n",
              "        -2.2400, -2.1588, -1.6862, -1.7545, -2.1455, -2.1636, -2.2423, -1.9797,\n",
              "        -1.7461, -1.8958, -2.0178, -1.7697, -1.1899, -1.5608, -1.2986, -0.9878,\n",
              "        -1.1975, -0.8651, -1.3561, -1.3298, -1.3777, -1.6734, -1.5581, -1.3892,\n",
              "        -0.9920, -1.1048, -1.2804, -1.7002, -1.6482, -1.9254, -1.9525, -1.6132,\n",
              "        -1.9811, -1.7413, -1.5891, -1.5620, -1.2712, -1.5568, -1.1379, -1.0850,\n",
              "        -1.0561, -0.6375, -0.5553, -0.4397, -0.1980, -0.2442, -0.0438,  0.0886,\n",
              "        -0.0346,  0.0927,  0.2458, -0.2554, -0.6296, -1.1790, -1.6244, -1.6822,\n",
              "        -1.5316, -1.8503, -1.9239, -2.1913, -2.6200, -2.6891, -2.6408, -2.6501,\n",
              "        -2.7506, -3.0649, -3.4478, -3.4980, -4.0263, -4.1605, -4.3302, -4.1965,\n",
              "        -4.3513, -4.5640, -4.2001, -4.0767, -4.0118, -4.0224, -3.5900, -3.1960,\n",
              "        -3.5165, -3.0897, -2.7679, -2.0599, -2.3264, -2.2728, -2.3868, -2.4457,\n",
              "        -2.1072, -1.4317, -1.6422, -2.2177, -2.6457, -2.4337, -2.6734, -2.3276,\n",
              "        -2.6588, -2.9793, -2.9843, -3.2477, -3.3368, -3.2478, -3.2717, -3.5486,\n",
              "        -3.2559, -3.2838, -2.9769, -2.1630, -1.9310, -2.0309, -1.8851, -1.9015,\n",
              "        -2.0187, -2.1279, -1.9944, -2.0514, -2.0136, -2.0512, -2.0931, -2.4190,\n",
              "        -2.4278, -2.5599, -2.8164, -2.5468, -2.8613, -3.0447, -2.6980, -3.3626,\n",
              "        -3.2200, -3.2626, -3.3423, -3.4049, -3.5286, -3.6759, -3.5529, -3.3115,\n",
              "        -3.2037, -2.8429, -2.4783, -2.1741, -1.6415, -1.5179, -1.8472, -1.7043,\n",
              "        -1.6049, -1.4770, -1.4599, -1.4449, -1.6367, -1.6285, -1.6432, -1.6003,\n",
              "        -1.8026, -1.7167, -1.7861, -2.0337, -1.9578, -2.4670, -2.0855, -1.8689,\n",
              "        -1.5897, -1.2418, -0.9088, -0.3114,  0.2085, -0.2372, -0.1814, -0.1722,\n",
              "        -0.2372,  0.0678, -0.3317, -0.1988, -1.1196, -1.0384, -0.6253, -0.7208,\n",
              "        -0.4989, -0.4922, -0.9951, -0.9284, -1.0117, -0.8368, -0.5952, -0.3131,\n",
              "         0.0519, -0.4966, -0.7928, -0.8935, -1.0461, -0.8409, -1.1285, -1.7481,\n",
              "        -1.5604, -1.6710, -1.8672, -1.8347, -1.3745, -1.9537, -1.7314, -1.4200,\n",
              "        -1.3934, -1.5300, -1.7519, -1.6372, -1.5728, -1.7700, -1.8836, -2.3945,\n",
              "        -2.3191, -1.8398, -2.2704, -1.9938, -2.1676, -2.2368, -1.8591, -1.6974,\n",
              "        -1.3262, -1.4363, -1.6878, -1.6224, -1.5387, -1.0397, -1.1296, -0.8485,\n",
              "        -0.8601, -0.5636, -0.8249, -0.5664, -0.8242, -0.7860, -1.2785, -1.3583,\n",
              "        -1.2094, -0.8570, -0.6449, -0.2714, -0.3515, -0.6763, -0.8196, -0.9757,\n",
              "        -1.0231, -0.7319, -1.0296, -0.8677, -0.8283, -0.7603, -0.6460, -0.7171,\n",
              "        -0.8685, -0.5866, -0.4563, -0.5788, -0.7472, -1.2121, -1.2842, -1.3632,\n",
              "        -1.0133, -0.7221, -0.6481, -0.4974, -0.6079, -0.1602, -0.7346, -0.7321,\n",
              "        -0.5599, -0.4247, -0.5425, -0.2190, -0.3136, -0.0626,  0.1494,  1.0166,\n",
              "         0.8274,  0.9900,  1.5195,  0.8736,  0.9748,  1.1319,  1.2602,  1.0284,\n",
              "         1.1556,  1.0908,  1.2538,  1.1709,  1.6944,  1.6119,  1.3155,  1.4514,\n",
              "         1.5784,  2.0880,  2.0321,  2.2719,  2.4926,  2.6567,  2.2848,  2.2638,\n",
              "         2.1597,  2.3206,  2.3380,  2.4200,  2.4763,  2.3003,  2.1518,  2.6020,\n",
              "         2.6113,  2.4885,  2.4798,  2.2825,  2.2287,  1.6632,  1.1708,  1.2397,\n",
              "         1.5780,  2.0547,  2.0981,  2.0337,  2.1404,  1.7567,  1.4868,  1.7066,\n",
              "         1.9083,  2.0455,  2.0434,  1.7166,  1.8430,  1.5980,  1.7975,  1.6326,\n",
              "         2.2069,  2.4912,  3.0972,  3.1313,  3.4253,  3.8023,  3.5228,  3.1510,\n",
              "         3.6991,  3.8266,  3.6347,  3.9249,  3.7223,  3.3062,  3.1448,  2.6121,\n",
              "         2.3787,  2.6168,  2.6262,  2.7565,  3.0695,  3.2299,  3.4249,  3.4766,\n",
              "         3.4546,  3.3117,  3.2180,  3.5295,  3.3876,  3.3875,  3.3163,  3.8985,\n",
              "         3.6657,  3.5652,  3.2327,  3.1224,  3.3068,  3.0599,  3.1539,  3.2379,\n",
              "         3.3183,  3.3682,  3.2676,  3.4098,  3.8077,  3.6387,  3.7528,  3.8877,\n",
              "         4.2399,  4.2130,  3.7059,  3.3967,  3.4823,  3.6857,  4.3476,  4.2720,\n",
              "         4.5019,  4.7881,  4.7068,  4.7690,  5.2762,  4.9082,  4.7801],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fI1Yjma8CL8"
      },
      "source": [
        "# Define Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzGQf6SVVjVE"
      },
      "source": [
        "def bij_transform(prime, lower, upper):\n",
        "    # Recieves a value in [-inf, inf] and returns value in [low, upper]\n",
        "    bij = 1 / (1 + torch.exp(-prime))\n",
        "    scale = upper - lower\n",
        "    return scale * bij + lower\n",
        "\n",
        "def bij_transform_inf(prime):\n",
        "    return torch.exp(prime)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CF2bx-79_eo"
      },
      "source": [
        "def calc_prior_loss(tau, phi, R0, alpha, sigma):\n",
        "  # log likelihood wrt. our prior (\"regularisation\")\n",
        "  # ll stands for log-likelihood\n",
        "  multiplier = 1e+3\n",
        "  ll = torch.tensor(0.0, device=device)\n",
        "\n",
        "  ll += (tau-(1/0.03))**2 * multiplier\n",
        "\n",
        "  ll += (phi-25)**2 * multiplier\n",
        "\n",
        "  ll += (R0-3.6)**2 * multiplier\n",
        "\n",
        "  ll += (alpha-0.01)**2 * multiplier\n",
        "\n",
        "  ll += (sigma-0.1)**2 * multiplier\n",
        "\n",
        "  return ll"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt27Ab2l9_hC"
      },
      "source": [
        "def seed_init_infect(y):\n",
        "  # Initialize newly_infected, cumulative_infected, St\n",
        "  newly_infected = torch.zeros(num_observations, device=device, dtype=dtype)  # number of newly infected\n",
        "  cumulative_infected = torch.zeros(num_observations, device=device)  # cumulative number of infected\n",
        "  \n",
        "  St = torch.zeros(num_observations, device=device)  # fraction of susceptible population\n",
        "  # seed initial infection / impute first num_impute days\n",
        "  newly_infected[0:num_impute] = y.clone()\n",
        "  cumulative_infected[0] = 0.\n",
        "  cumulative_infected[1:num_impute] = torch.cumsum(newly_infected[0:num_impute - 1].clone(), dim=0)\n",
        "  St[0:num_impute] = torch.tensor([torch.maximum(population.clone() - x, torch.tensor(0)) / population for x in cumulative_infected[0:num_impute].clone()])\n",
        "  return newly_infected, cumulative_infected, St"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf9tMHun9_j0"
      },
      "source": [
        "def calc_Rt(R0, epsilon_t, sigma, ll):\n",
        "  # Initialize eta_t\n",
        "  eta_t = torch.zeros(num_observations, device=device)  # transformed reproduction number\n",
        "\n",
        "  # calculate Rt: the basic reproduction number\n",
        "  # basic reproduction number as a latent random walk\n",
        "  beta_0 = torch.log(R0)\n",
        "  eta_t[0] = beta_0\n",
        "  for t in range(1, num_observations):\n",
        "      dist_epsilon_t = torch.distributions.Normal(epsilon_t[t - 1], sigma)\n",
        "      ll += dist_epsilon_t.log_prob(epsilon_t[t - 1])\n",
        "  eta_t[1:num_observations] = beta_0 + epsilon_t[0:num_observations-1].clone()\n",
        "  Rt = torch.exp(eta_t)\n",
        "  return Rt, ll"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcM7ArwKRp60"
      },
      "source": [
        "def calc_infections(cumulative_infected, newly_infected, St, Rt):\n",
        "  # Initialize effectively_infectious\n",
        "  effectively_infectious = torch.zeros(num_observations, device=device)  # effective number of infectious individuals\n",
        "  \n",
        "  # calculate infections\n",
        "  for t in range(num_impute, num_observations):\n",
        "      # Update cumulative newly_infected\n",
        "      cumulative_infected[t] = cumulative_infected[t - 1].clone() + newly_infected[t - 1].clone()\n",
        "      # Adjusts for portion of pop that are susceptible\n",
        "      St[t] = torch.maximum(population.clone() - cumulative_infected[t].clone(), cero) / population.clone()\n",
        "      # effective number of infectous individuals\n",
        "      ni_temp = newly_infected[:t].view(1, 1, -1).clone()\n",
        "      si_temp = torch.flip(serial_interval, (0,))[-t:].view(1, 1, -1)\n",
        "      effectively_infectious[t] = torch.nn.functional.conv1d(ni_temp, si_temp)\n",
        "      \n",
        "      newly_infected[t] = St[t].clone() * Rt[t].clone() * effectively_infectious[t].clone()\n",
        "  return newly_infected"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrSVBFldAD-l"
      },
      "source": [
        "def calc_hospit(newly_infected, alpha):\n",
        "  # Initialize expected_daily_hospit\n",
        "  expected_daily_hospit = torch.zeros(num_observations, device=device)  # expected number of daily hospitalizations\n",
        "\n",
        "  # calculate expected number of hospitalizations\n",
        "  expected_daily_hospit[0] = (1e-15) * newly_infected[0].clone()\n",
        "  for t in range(1, num_observations):\n",
        "      ni_temp = newly_infected[:t].view(1, 1, -1)\n",
        "      pi_temp = torch.flip(pi, (0,))[-t-1:-1].view(1, 1, -1)\n",
        "      expected_daily_hospit[t] = torch.nn.functional.conv1d(ni_temp, pi_temp)\n",
        "  expected_daily_hospit = alpha * expected_daily_hospit\n",
        "  return expected_daily_hospit"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvgAHKIXAEBU"
      },
      "source": [
        "def compare_results(expected_daily_hospit, phi, ll):\n",
        "  # compare observed hospitalizations to model results\n",
        "  # likelihood of the data wrt. to the model\n",
        "\n",
        "  for i in range(0, num_observations):\n",
        "      p = 1/(1+ expected_daily_hospit[i]/phi)\n",
        "      dist = torch.distributions.negative_binomial.NegativeBinomial(phi, p-torch.tensor(2.225e-5))\n",
        "      ll += dist.log_prob(observed_daily_hospit[i])\n",
        "  return ll"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZMf1XWoAtSt"
      },
      "source": [
        "def forward_pass():\n",
        "  # Initialize y\n",
        "  tau = bij_transform_inf(tau_prime)\n",
        "  y = torch.distributions.exponential.Exponential(1/tau).rsample()\n",
        "  R0 = bij_transform(R0_prime, lower=2, upper=5)\n",
        "  phi = bij_transform(phi_prime, lower=1, upper=50)\n",
        "  alpha = bij_transform(alpha_prime, lower=0, upper=0.05)\n",
        "  sigma = bij_transform(sigma_prime, lower=0, upper=0.5)\n",
        "\n",
        "  # Calculate prior loss\n",
        "  ll = calc_prior_loss(tau, phi, R0, alpha, sigma)\n",
        "\n",
        "  # Seed initial infections\n",
        "  newly_infected, cumulative_infected, St = seed_init_infect(y)\n",
        "  \n",
        "  # Calculate Rt & random walk loss\n",
        "  Rt, ll = calc_Rt(R0, epsilon_t, sigma, ll)\n",
        "\n",
        "  # Calculate infections\n",
        "  newly_infected = calc_infections(cumulative_infected, newly_infected, St, Rt)\n",
        "  \n",
        "  # Calculate expected hospitalizations\n",
        "  expected_daily_hospit = calc_hospit(newly_infected, alpha)\n",
        "  \n",
        "  # Compare observed hospitalizations to model results\n",
        "  ll = compare_results(expected_daily_hospit, phi, ll)\n",
        "\n",
        "  return expected_daily_hospit, Rt, ll, tau, R0, phi, alpha, sigma"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg2pWcC384K0"
      },
      "source": [
        "# Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "BBZ3KIq1PTqk",
        "outputId": "c31370b2-5e3d-467e-ef62-df0e09551776"
      },
      "source": [
        "learning_rate = 1e-4\n",
        "epochs = 1000\n",
        "complete_time = time.time()\n",
        "\n",
        "for k in range (epochs):\n",
        "    start_time = time.time()\n",
        "    decay = (1 - (k / (epochs*1e5))) ** 2\n",
        "    learning_rate = learning_rate * decay\n",
        "\n",
        "    # forward pass - calculate expected_daily_hospit\n",
        "    expected_daily_hospit, Rt, ll, tau, R0, phi, alpha, sigma = forward_pass()\n",
        "\n",
        "    #backward pass\n",
        "    loss = ll\n",
        "    loss.backward()\n",
        "\n",
        "    if k%5 == 0:\n",
        "      print(f'Time Step: {k}|| Loss: {loss},  R0:{R0}, grad: {R0_prime.grad}, alpha: {alpha} grad: {alpha_prime.grad}, phi: {phi} grad: {phi_prime.grad}, sigma: {sigma} grad {sigma_prime.grad}, epsilon_t.mean: {epsilon_t.mean()} grad.mean {epsilon_t.grad.mean()}')\n",
        "      print(\"This Run:  %s seconds\" % (time.time() - start_time))\n",
        "    with torch.no_grad(): # this part is SGD. can also replace with loss.step\n",
        "        tau_prime -= learning_rate * tau_prime.grad\n",
        "        phi_prime -= learning_rate * phi_prime.grad \n",
        "        R0_prime -= learning_rate * R0_prime.grad \n",
        "        alpha_prime -= learning_rate * alpha_prime.grad \n",
        "        sigma_prime -= learning_rate * sigma_prime.grad \n",
        "        epsilon_t -= learning_rate * epsilon_t.grad \n",
        "\n",
        "        tau_prime.grad = None\n",
        "        phi_prime.grad = None\n",
        "        R0_prime.grad = None\n",
        "        alpha_prime.grad = None\n",
        "        sigma_prime.grad = None\n",
        "        epsilon_t.grad = None\n",
        "\n",
        "    \n",
        "    if k%100 == 0:    \n",
        "      plt.plot(expected_daily_hospit.cpu().detach().numpy(), label='expected_daily_hospit')\n",
        "      plt.plot(observed_daily_hospit.cpu().detach().numpy(), label='observed_daily_hospit')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "print(\"Complete Run:  %s seconds\" % (time.time() - complete_time))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4672eaf8cc6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# forward pass - calculate expected_daily_hospit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mexpected_daily_hospit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-21666fe27515>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;31m# Compare observed hospitalizations to model results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_daily_hospit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexpected_daily_hospit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-27ea8a9d044f>\u001b[0m in \u001b[0;36mcompare_results\u001b[0;34m(expected_daily_hospit, phi, ll)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mexpected_daily_hospit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_binomial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNegativeBinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.225e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved_daily_hospit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/negative_binomial.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, total_count, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNegativeBinomial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip checking lazily-constructed args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The parameter {} has invalid values\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The parameter probs has invalid values"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jGDyZ34JCLQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}