{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLL_V3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsuehr/covid-prediction-tu/blob/Epid_Model/users/Anuar/NLL_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d17BEQFdPTqc"
      },
      "source": [
        "import scipy.stats\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import expon, truncexpon, truncnorm, nbinom, norm\n",
        "import pandas as pd\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import distributions\n",
        "from torch import rand\n",
        "from torch import autograd\n",
        "from torch import optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdBc47jlPTqe"
      },
      "source": [
        "np.random.seed(seed=101)\n",
        "torch.manual_seed(101)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "dtype = torch.float64\n",
        "device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EaFwH9Vm7YMg",
        "outputId": "8bd6ccf5-d97a-49c9-aa86-4916be9f9bd4"
      },
      "source": [
        "data = pd.read_csv('covid19model.csv')\n",
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>hospit</th>\n",
              "      <th>serial_interval</th>\n",
              "      <th>delay_distr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-02-17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046535</td>\n",
              "      <td>1.300600e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-02-18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.087065</td>\n",
              "      <td>3.004645e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-02-19</td>\n",
              "      <td>0</td>\n",
              "      <td>0.112061</td>\n",
              "      <td>4.467391e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-02-20</td>\n",
              "      <td>0</td>\n",
              "      <td>0.119346</td>\n",
              "      <td>5.547300e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-02-21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.114540</td>\n",
              "      <td>6.242203e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>2021-03-25</td>\n",
              "      <td>38</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.817211e-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>2021-03-26</td>\n",
              "      <td>31</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.349426e-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>2021-03-27</td>\n",
              "      <td>39</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.959313e-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>2021-03-28</td>\n",
              "      <td>32</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.633974e-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>2021-03-29</td>\n",
              "      <td>45</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.362655e-32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>407 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  hospit  serial_interval   delay_distr\n",
              "0    2020-02-17       0         0.046535  1.300600e-02\n",
              "1    2020-02-18       0         0.087065  3.004645e-02\n",
              "2    2020-02-19       0         0.112061  4.467391e-02\n",
              "3    2020-02-20       0         0.119346  5.547300e-02\n",
              "4    2020-02-21       0         0.114540  6.242203e-02\n",
              "..          ...     ...              ...           ...\n",
              "402  2021-03-25      38         0.000000  2.817211e-32\n",
              "403  2021-03-26      31         0.000000  2.349426e-32\n",
              "404  2021-03-27      39         0.000000  1.959313e-32\n",
              "405  2021-03-28      32         0.000000  1.633974e-32\n",
              "406  2021-03-29      45         0.000000  1.362655e-32\n",
              "\n",
              "[407 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seIKt9FY5OF"
      },
      "source": [
        "def trunc_exponential(scale, upper):\n",
        "    sample = torch.distributions.exponential.Exponential(1/scale).rsample()\n",
        "    sample = sample/torch.tensor(1-torch.exp(-upper/scale))\n",
        "    return sample\n",
        "# torch.distributions.exponential.Exponential(1/scale).sample()/torch.tensor(1-torch.exp(-upper/scale))\n",
        "\n",
        "def trunc_normal(mu, sigma, under, upper):\n",
        "    distribution = torch.distributions.normal.Normal(loc=mu, scale=sigma, validate_args=None)\n",
        "    normal_sample = distribution.rsample()\n",
        "    cumulative = distribution.cdf(torch.tensor(upper)) - distribution.cdf(torch.tensor(under))\n",
        "    return normal_sample/cumulative"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2IY_KzX7uV9"
      },
      "source": [
        "# Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7remU4ygPTqf"
      },
      "source": [
        "cero = torch.tensor(0., requires_grad=False, device=device, dtype=dtype)\n",
        "num_impute = 6\n",
        "observed_daily_hospit = torch.tensor(data.hospit, requires_grad=False, device=device, dtype=dtype)\n",
        "pi = torch.tensor(data.delay_distr, requires_grad=False, device=device, dtype=dtype)\n",
        "serial_interval = torch.tensor(data.serial_interval, requires_grad=False, device=device, dtype=dtype)\n",
        "population = torch.tensor(5793636, requires_grad=False, device=device, dtype=dtype)\n",
        "num_observations = len(observed_daily_hospit)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG5jECpf77Xk"
      },
      "source": [
        "## Initialize latent variables/parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4QAEdWKMBxF"
      },
      "source": [
        "# Create domain transformation functions:\n",
        "def transform_r0(R0_prime, lower, upper):\n",
        "  # Recieves a value in [-inf, inf] and returns value in [low, upper]\n",
        "  bij = 1/(1+torch.exp(-R0_prime))\n",
        "  scale = upper - lower\n",
        "  return scale*bij + lower\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XhscamaPTqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a757b7e-e73a-4c7a-df34-94d54ce4f9d0"
      },
      "source": [
        "tau= torch.tensor(np.random.exponential(1 / 0.03), requires_grad=True, device=device, dtype=dtype)\n",
        "phi = torch.tensor(truncnorm.rvs((0 - 25) / 10, (np.inf - 25) / 10, loc=25, scale=10), requires_grad=True, device=device, dtype=dtype) # has to be positive, between 0-50 --> uniform # dispersion (shape) parameter for observations\n",
        "alpha = torch.tensor(truncnorm.rvs((0 - 1/100) / 1/100, (5/100 - 1/100) / 1/100, loc=1/100, scale=1/100), requires_grad=True, device=device, dtype=dtype) # uniform distribution between (0-5%) # probability to get hospitalized\n",
        "sigma = torch.tensor(truncnorm.rvs((0 - 0.1) / 0.3, (0.5 - 0.1) / 0.3, loc=0.1, scale=0.3), requires_grad=True, device=device, dtype=dtype)  # positive, tricky, gamma or inverse gamma, log normal  --> try something out, large sigma--> prone to overfitting # standart deviation of random walk step\n",
        "\n",
        "R0_prime = torch.rand(1, dtype=dtype, device=device, requires_grad=True)\n",
        "R0 = transform_r0(R0_prime, lower=2, upper=5)\n",
        "\n",
        "\n",
        "\n",
        "epsilon_t = torch.zeros(num_observations, device=device)\n",
        "epsilon_t[0] = torch.distributions.Normal(cero, sigma.detach()).rsample()\n",
        "for t in range(1, num_observations):\n",
        "  epsilon_t[t] = torch.distributions.Normal(epsilon_t[t - 1].detach(), sigma.detach()).rsample()\n",
        "epsilon_t.requires_grad_(True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-8.8592e-03, -7.0310e-02, -8.3121e-02, -6.4970e-03,  3.9006e-02,\n",
              "        -5.6481e-02,  2.6919e-02,  1.0483e-01,  1.2950e-01,  1.2872e-01,\n",
              "         1.7187e-01,  2.4616e-01,  2.9850e-01,  2.6638e-01,  2.9082e-01,\n",
              "         2.6140e-01,  4.4035e-01,  5.2068e-01,  5.1382e-01,  4.2920e-01,\n",
              "         3.7923e-01,  3.4636e-01,  2.4963e-01,  3.7242e-01,  3.3134e-01,\n",
              "         3.7909e-01,  2.7869e-01,  3.9855e-01,  4.3456e-01,  4.1970e-01,\n",
              "         3.7246e-01,  3.2783e-01,  2.5934e-01,  2.1251e-01,  2.1788e-01,\n",
              "         1.0346e-01,  6.8713e-02,  9.1145e-02,  1.2755e-01,  3.0210e-01,\n",
              "         2.2850e-01,  1.4846e-01,  1.1218e-01, -6.4545e-03, -4.5229e-02,\n",
              "        -5.2489e-03, -7.8238e-02, -7.4937e-02, -8.2481e-02, -9.7743e-02,\n",
              "         1.6623e-03,  1.0845e-01,  9.8130e-02,  8.8166e-02,  5.6671e-02,\n",
              "         1.4375e-02, -1.0984e-02, -4.3088e-02,  1.0157e-01,  2.2300e-01,\n",
              "         2.1348e-01,  2.4352e-01,  2.2771e-01,  2.9474e-01,  3.5758e-01,\n",
              "         4.6845e-01,  5.0056e-01,  4.0158e-01,  4.7864e-01,  4.3932e-01,\n",
              "         3.9325e-01,  2.6936e-01,  1.5818e-01,  1.4613e-01,  8.9449e-02,\n",
              "         1.5559e-01,  6.3372e-02, -1.0124e-01,  9.1575e-03,  1.8930e-02,\n",
              "        -6.6238e-02, -5.0927e-02, -1.2807e-01, -1.7217e-01, -1.3994e-01,\n",
              "        -2.0363e-01, -1.9666e-01, -9.3536e-02, -1.0520e-01, -8.5000e-02,\n",
              "        -2.5459e-01, -3.4633e-01, -3.1109e-01, -3.0548e-01, -2.6138e-01,\n",
              "        -3.1118e-01, -2.9409e-01, -3.3597e-01, -2.5709e-01, -2.7157e-01,\n",
              "        -3.2719e-01, -2.5211e-01, -2.1490e-01, -1.9066e-01, -8.3528e-02,\n",
              "        -1.0766e-01, -4.9901e-02, -9.8162e-02, -1.0338e-01, -1.6898e-01,\n",
              "        -2.2964e-01, -3.0860e-01, -3.3654e-01, -4.5148e-01, -4.8641e-01,\n",
              "        -4.2670e-01, -3.2780e-01, -2.6625e-01, -4.0204e-01, -2.4642e-01,\n",
              "        -2.8375e-01, -2.5575e-01, -8.9267e-02, -1.0171e-01, -1.7865e-01,\n",
              "         8.6845e-03,  8.1645e-02,  1.4882e-01,  2.5570e-01,  3.8428e-01,\n",
              "         4.9280e-01,  5.8983e-01,  7.0461e-01,  7.1657e-01,  6.0182e-01,\n",
              "         6.2463e-01,  6.8082e-01,  7.2036e-01,  6.3160e-01,  5.9919e-01,\n",
              "         4.6985e-01,  4.3663e-01,  6.0877e-01,  5.6781e-01,  6.3807e-01,\n",
              "         7.0546e-01,  8.0049e-01,  8.3702e-01,  8.5203e-01,  8.9366e-01,\n",
              "         8.6547e-01,  9.0452e-01,  8.7275e-01,  8.5916e-01,  8.5711e-01,\n",
              "         8.3782e-01,  8.7305e-01,  8.0546e-01,  7.6624e-01,  7.5876e-01,\n",
              "         7.8080e-01,  8.0830e-01,  8.9147e-01,  8.9304e-01,  9.1389e-01,\n",
              "         9.7077e-01,  1.0469e+00,  1.0526e+00,  1.0551e+00,  1.1667e+00,\n",
              "         1.1136e+00,  1.2244e+00,  1.2315e+00,  1.2028e+00,  1.1851e+00,\n",
              "         1.1497e+00,  1.1333e+00,  1.0931e+00,  1.2301e+00,  1.1713e+00,\n",
              "         1.1864e+00,  1.1800e+00,  1.2378e+00,  1.2446e+00,  1.1732e+00,\n",
              "         1.2044e+00,  1.1543e+00,  1.0890e+00,  1.2727e+00,  1.2650e+00,\n",
              "         1.2609e+00,  1.2552e+00,  1.2548e+00,  1.3363e+00,  1.3475e+00,\n",
              "         1.2857e+00,  1.2983e+00,  1.3350e+00,  1.2055e+00,  1.1595e+00,\n",
              "         1.2391e+00,  1.1962e+00,  1.1350e+00,  1.1608e+00,  1.1160e+00,\n",
              "         1.2141e+00,  1.3596e+00,  1.2967e+00,  1.3003e+00,  1.3811e+00,\n",
              "         1.4187e+00,  1.5542e+00,  1.5938e+00,  1.5835e+00,  1.4731e+00,\n",
              "         1.4160e+00,  1.4746e+00,  1.5214e+00,  1.4770e+00,  1.5971e+00,\n",
              "         1.6164e+00,  1.7278e+00,  1.7432e+00,  1.6947e+00,  1.6939e+00,\n",
              "         1.6207e+00,  1.6403e+00,  1.5510e+00,  1.5613e+00,  1.5852e+00,\n",
              "         1.4623e+00,  1.3347e+00,  1.2665e+00,  1.2264e+00,  1.2028e+00,\n",
              "         1.2477e+00,  1.2579e+00,  1.1985e+00,  1.1542e+00,  1.1865e+00,\n",
              "         1.1297e+00,  1.1693e+00,  1.0916e+00,  1.0680e+00,  1.0268e+00,\n",
              "         1.1036e+00,  1.1086e+00,  1.0630e+00,  1.0246e+00,  1.0048e+00,\n",
              "         9.4493e-01,  8.4967e-01,  7.4953e-01,  7.6151e-01,  7.6823e-01,\n",
              "         8.2514e-01,  7.6496e-01,  8.0896e-01,  7.6602e-01,  7.6881e-01,\n",
              "         9.2200e-01,  9.5678e-01,  1.0081e+00,  1.0458e+00,  9.0571e-01,\n",
              "         9.4994e-01,  1.0023e+00,  1.0989e+00,  1.1061e+00,  1.0054e+00,\n",
              "         1.0372e+00,  1.0508e+00,  1.0379e+00,  9.9519e-01,  1.0291e+00,\n",
              "         1.0772e+00,  1.0576e+00,  9.7601e-01,  9.9677e-01,  9.7013e-01,\n",
              "         9.7210e-01,  1.0330e+00,  9.7186e-01,  9.7166e-01,  9.4423e-01,\n",
              "         9.8512e-01,  1.0556e+00,  1.0514e+00,  1.0030e+00,  1.1357e+00,\n",
              "         1.1774e+00,  1.1730e+00,  1.2263e+00,  1.3497e+00,  1.2652e+00,\n",
              "         1.4038e+00,  1.5273e+00,  1.6329e+00,  1.7177e+00,  1.8921e+00,\n",
              "         1.9187e+00,  1.8477e+00,  1.7999e+00,  1.8110e+00,  1.8296e+00,\n",
              "         1.7740e+00,  1.7640e+00,  1.7954e+00,  1.7420e+00,  1.8082e+00,\n",
              "         1.7471e+00,  1.7245e+00,  1.7417e+00,  1.7885e+00,  1.9123e+00,\n",
              "         1.9443e+00,  1.9696e+00,  2.0244e+00,  2.0108e+00,  1.8907e+00,\n",
              "         1.9919e+00,  2.0518e+00,  2.0847e+00,  2.1962e+00,  2.2436e+00,\n",
              "         2.1775e+00,  2.1814e+00,  2.1406e+00,  2.2316e+00,  2.1283e+00,\n",
              "         2.2520e+00,  2.2794e+00,  2.2232e+00,  2.1796e+00,  2.1478e+00,\n",
              "         2.1461e+00,  2.1134e+00,  2.2275e+00,  2.0973e+00,  2.1262e+00,\n",
              "         2.0311e+00,  2.1470e+00,  2.1344e+00,  2.1592e+00,  2.1673e+00,\n",
              "         2.1622e+00,  2.1920e+00,  2.1655e+00,  2.1578e+00,  2.0551e+00,\n",
              "         2.0513e+00,  2.0322e+00,  2.0685e+00,  2.0141e+00,  1.9069e+00,\n",
              "         1.9015e+00,  1.8771e+00,  1.7686e+00,  1.8045e+00,  1.7456e+00,\n",
              "         1.6934e+00,  1.7005e+00,  1.7238e+00,  1.7397e+00,  1.7191e+00,\n",
              "         1.7171e+00,  1.7442e+00,  1.8557e+00,  1.9005e+00,  1.9401e+00,\n",
              "         1.8585e+00,  1.8782e+00,  1.9215e+00,  1.9579e+00,  2.0195e+00,\n",
              "         1.9512e+00,  1.9159e+00,  1.9990e+00,  1.8599e+00,  1.8488e+00,\n",
              "         1.8170e+00,  1.8327e+00,  1.8587e+00,  1.8750e+00,  1.9376e+00,\n",
              "         1.9584e+00,  2.0455e+00,  2.1884e+00,  2.1687e+00,  2.1351e+00,\n",
              "         2.2405e+00,  2.4244e+00,  2.3301e+00,  2.3190e+00,  2.3511e+00,\n",
              "         2.3184e+00,  2.3205e+00,  2.5226e+00,  2.5579e+00,  2.5401e+00,\n",
              "         2.4714e+00,  2.4510e+00,  2.5936e+00,  2.6496e+00,  2.6985e+00,\n",
              "         2.6629e+00,  2.5388e+00], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtO_C9CTSkM-"
      },
      "source": [
        "This is a way to generate the initial params from pytorch distribution directly without truncation.\n",
        "NOTE: Use either this code block below or above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcKQh9lISjqA"
      },
      "source": [
        "dist_tau_t = distributions.exponential.Exponential(torch.tensor([1/0.03], device=device))\n",
        "#tau_t = dist_tau_t.sample()\n",
        "\n",
        "dist_y = distributions.exponential.Exponential(tau)\n",
        "#y = dist_y.sample()\n",
        "\n",
        "dist_phi = distributions.normal.Normal(loc=torch.tensor([25], device=device), scale=torch.tensor([10], device=device))\n",
        "#phi = dist_phi.sample()\n",
        "\n",
        "dist_R0 = distributions.normal.Normal(loc=torch.tensor([3.6], device=device), scale=torch.tensor([0.8], device=device))\n",
        "#R0 = dist_R0.sample()\n",
        "\n",
        "dist_alpha = distributions.normal.Normal(loc=torch.tensor([0.01], device=device), scale=torch.tensor([0.01], device=device))\n",
        "#alpha = dist_alpha.sample()\n",
        "\n",
        "dist_sigma = distributions.normal.Normal(loc=torch.tensor([0.1], device=device), scale=torch.tensor([0.3], device=device))\n",
        "#sigma = dist_sigma.sample()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fI1Yjma8CL8"
      },
      "source": [
        "# Define Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CF2bx-79_eo"
      },
      "source": [
        "def calc_prior_loss(tau, phi, R0, alpha, sigma):\n",
        "  # log likelihood wrt. our prior (\"regularisation\")\n",
        "  # ll stands for log-likelihood\n",
        "  ll = torch.tensor(0.0, device=device)\n",
        "\n",
        "  #dist_tau_t = distributions.exponential.Exponential(torch.tensor([1/0.03]))\n",
        "  #ll += dist_tau_t.log_prob(tau).item()\n",
        "\n",
        "  #dist_y = distributions.exponential.Exponential(tau) #the parameter in the brasket should either be float or tensor, to avoid any inconvienience,\n",
        "                                                      # I use everything as tensor. NOTE:tau_t is already a tensor.\n",
        "  #ll += dist_y.log_prob(y).item()\n",
        "\n",
        "  #dist_phi = distribution.normal.Normal(loc=torch.tensor([25]), scale=torch.tensor([10]))\n",
        "  ll += dist_phi.log_prob(phi).item()\n",
        "\n",
        "  #dist_R0 = distribution.normal.Normal(loc=torch.tensor([3.6]), scale=torch.tensor([0.8]))\n",
        "  ll += dist_R0.log_prob(R0).item()\n",
        "\n",
        "  #dist_alpha = distribution.normal.Normal(loc=torch.tensor([0.01]), scale=torch.tensor([0.01]))\n",
        "  ll += dist_alpha.log_prob(alpha).item()\n",
        "\n",
        "  #dist_sigma = distribution.normal.Normal(loc=torch.tensor([0.1]), scale=torch.tensor([0.3]))\n",
        "  ll += dist_sigma.log_prob(sigma).item()\n",
        "\n",
        "  return ll"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt27Ab2l9_hC"
      },
      "source": [
        "def seed_init_infect(y):\n",
        "  # Initialize newly_infected, cumulative_infected, St\n",
        "  newly_infected = torch.zeros(num_observations, device=device, dtype=dtype)  # number of newly infected\n",
        "  cumulative_infected = torch.zeros(num_observations, device=device)  # cumulative number of infected\n",
        "  \n",
        "  St = torch.zeros(num_observations, device=device)  # fraction of susceptible population\n",
        "  # seed initial infection / impute first num_impute days\n",
        "  newly_infected[0:num_impute] = y.clone()\n",
        "  cumulative_infected[0] = 0.\n",
        "  cumulative_infected[1:num_impute] = torch.cumsum(newly_infected[0:num_impute - 1].clone(), dim=0)\n",
        "  St[0:num_impute] = torch.tensor([torch.maximum(population.clone() - x, torch.tensor(0)) / population for x in cumulative_infected[0:num_impute].clone()])\n",
        "  return newly_infected, cumulative_infected, St"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf9tMHun9_j0"
      },
      "source": [
        "def calc_Rt(R0, epsilon_t, sigma, ll):\n",
        "  # Initialize eta_t\n",
        "  eta_t = torch.zeros(num_observations, device=device)  # transformed reproduction number\n",
        "\n",
        "  # calculate Rt: the basic reproduction number\n",
        "  # basic reproduction number as a latent random walk\n",
        "  beta_0 = torch.log(R0)\n",
        "  eta_t[0] = beta_0\n",
        "  for t in range(1, num_observations):\n",
        "      dist_epsilon_t = torch.distributions.Normal(epsilon_t[t - 1], sigma)\n",
        "      ll += dist_epsilon_t.log_prob(epsilon_t[t])\n",
        "  eta_t[1:num_observations] = beta_0 + epsilon_t[0:num_observations-1].clone()\n",
        "  Rt = torch.exp(eta_t)\n",
        "  return Rt, ll"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcM7ArwKRp60"
      },
      "source": [
        "def calc_infections(cumulative_infected, newly_infected, St, Rt):\n",
        "  # Initialize effectively_infectious\n",
        "  effectively_infectious = torch.zeros(num_observations, device=device)  # effective number of infectious individuals\n",
        "  \n",
        "  # calculate infections\n",
        "  for t in range(num_impute, num_observations):\n",
        "      # Update cumulative newly_infected\n",
        "      cumulative_infected[t] = cumulative_infected[t - 1].clone() + newly_infected[t - 1].clone()\n",
        "      # Adjusts for portion of pop that are susceptible\n",
        "      St[t] = torch.maximum(population.clone() - cumulative_infected[t].clone(), cero) / population.clone()\n",
        "      # effective number of infectous individuals\n",
        "      ni_temp = newly_infected[:t].view(1, 1, -1).clone()\n",
        "      si_temp = torch.flip(serial_interval, (0,))[-t:].view(1, 1, -1)\n",
        "      effectively_infectious[t] = torch.nn.functional.conv1d(ni_temp, si_temp)\n",
        "      \n",
        "      newly_infected[t] = St[t].clone() * Rt[t].clone() * effectively_infectious[t].clone()\n",
        "  return newly_infected"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrSVBFldAD-l"
      },
      "source": [
        "def calc_hospit(newly_infected, alpha):\n",
        "  # Initialize expected_daily_hospit\n",
        "  expected_daily_hospit = torch.zeros(num_observations, device=device)  # expected number of daily hospitalizations\n",
        "\n",
        "  # calculate expected number of hospitalizations\n",
        "  expected_daily_hospit[0] = (1e-15) * newly_infected[0].clone()\n",
        "  for t in range(1, num_observations):\n",
        "      ni_temp = newly_infected[:t].view(1, 1, -1)\n",
        "      pi_temp = torch.flip(pi, (0,))[-t-1:-1].view(1, 1, -1)\n",
        "      expected_daily_hospit[t] = torch.nn.functional.conv1d(ni_temp, pi_temp)\n",
        "  expected_daily_hospit = alpha * expected_daily_hospit\n",
        "  return expected_daily_hospit"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvgAHKIXAEBU"
      },
      "source": [
        "def compare_results(expected_daily_hospit, phi, ll):\n",
        "  # compare observed hospitalizations to model results\n",
        "  # likelihood of the data wrt. to the model\n",
        "\n",
        "  for i in range(0, num_observations):\n",
        "      p = 1/(1+ expected_daily_hospit[i]/phi)\n",
        "      dist = torch.distributions.negative_binomial.NegativeBinomial(phi, p-torch.tensor(2.225e-5))\n",
        "      ll += dist.log_prob(observed_daily_hospit[i])\n",
        "  return ll"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZMf1XWoAtSt"
      },
      "source": [
        "def forward_pass():\n",
        "  # Initialize y\n",
        "  y = trunc_exponential(tau, 1000)\n",
        "  R0 = transform_r0(R0_prime, lower=2, upper=5)\n",
        "\n",
        "  # Calculate prior loss\n",
        "  ll = calc_prior_loss(tau, phi, R0, alpha, sigma)\n",
        "  \n",
        "  # Seed initial infections\n",
        "  newly_infected, cumulative_infected, St = seed_init_infect(y)\n",
        "  \n",
        "  # Calculate Rt & random walk loss \n",
        "  Rt, ll = calc_Rt(R0, epsilon_t, sigma, ll)\n",
        "  \n",
        "  # Calculate infections\n",
        "  newly_infected = calc_infections(cumulative_infected, newly_infected, St, Rt)\n",
        "  \n",
        "  # Calculate expected hospitalizations\n",
        "  expected_daily_hospit = calc_hospit(newly_infected, alpha)\n",
        "  \n",
        "  # Compare observed hospitalizations to model results\n",
        "  ll = compare_results(expected_daily_hospit, phi, ll)\n",
        "  return expected_daily_hospit, Rt, ll"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg2pWcC384K0"
      },
      "source": [
        "# Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "BBZ3KIq1PTqk",
        "outputId": "cc272172-c132-41ab-85da-9d0d045a6aa2"
      },
      "source": [
        "learning_rate = 1e-12\n",
        "epochs = 100\n",
        "complete_time = time.time()\n",
        "\n",
        "for k in range (epochs):\n",
        "    start_time = time.time()\n",
        "    decay = (1 - (k / (epochs*1e5))) ** 2\n",
        "    learning_rate = learning_rate * decay\n",
        "\n",
        "    # forward pass - calculate expected_daily_hospit\n",
        "    expected_daily_hospit, Rt, ll = forward_pass()\n",
        "\n",
        "    #backward pass\n",
        "    loss = -ll\n",
        "    loss.backward()\n",
        "\n",
        "    if k%5 == 0:\n",
        "      #print(f'Time Step: {k}|| Loss: {loss},  R0:{R0_prime}, grad: {R0_prime.grad}, alpha: {alpha} grad: {alpha.grad}, phi: {phi} grad: {phi.grad}, sigma: {sigma} grad {sigma.grad}, epsilon_t.mean: {epsilon_t.mean()} grad.mean {epsilon_t.grad.mean()}')\n",
        "      print(f'Time Step: {k}||R0\":{R0_prime}, grad: {R0_prime.grad}, R0:{R0}')\n",
        "\n",
        "    with torch.no_grad(): # this part is SGD. can also replace with loss.step\n",
        "        tau -= learning_rate * tau.grad\n",
        "        phi -= learning_rate * phi.grad \n",
        "        #R0_prime -= learning_rate * R0_prime.grad \n",
        "        R0_prime -= 1 * R0_prime.grad \n",
        "        alpha -= learning_rate * alpha.grad \n",
        "        sigma -= learning_rate * sigma.grad \n",
        "        epsilon_t -= learning_rate * epsilon_t.grad * 1e+8\n",
        "\n",
        "        tau.grad = None\n",
        "        phi.grad = None\n",
        "        R0_prime.grad = None\n",
        "        alpha.grad = None\n",
        "        sigma.grad = None\n",
        "        epsilon_t.grad = None\n",
        "\n",
        "    \n",
        "    if k%20 == 0:\n",
        "      plt.plot(expected_daily_hospit.cpu().detach().numpy(), label='expected_daily_hospit')\n",
        "      plt.plot(observed_daily_hospit.cpu().detach().numpy(), label='observed_daily_hospit')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "print(\"Complete Run:  %s seconds\" % (time.time() - complete_time))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Step: 0||R0\":tensor([0.5844], dtype=torch.float64, requires_grad=True), grad: tensor([1116.5424], dtype=torch.float64), R0:tensor([3.9262], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9bn48c8zM0kmKwlJQGQpSJFFRYQIclEvakVcKmJV9GrrtVpbKta2t1a8tYKtXm1L6a1WbW1dWxdslRb9YRVcqnhlN+xbWAVZskD2TGb5/v44Z5IBs8yWmQk879crr8x858w5z5xMnvnOc77ne8QYg1JKqRODI9kBKKWUShxN+kopdQLRpK+UUicQTfpKKXUC0aSvlFInEFeyA+hIUVGRGThwYLLDUEqpbmXVqlUVxpjith5L6aQ/cOBAVq5cmewwlFKqWxGR3e09puUdpZQ6gWjSV0qpE4gmfaWUOoGkdE1fqeOV1+tl7969NDU1JTsU1Y253W769etHWlpa2M/RpK9UEuzdu5fc3FwGDhyIiCQ7HNUNGWOorKxk7969DBo0KOznaXlHqSRoamqisLBQE76KmohQWFgY8bdFTfpKJYkmfBWraN5DmvTjZE9lA4s3Hkx2GEop1SFN+nHyk7+v47YXVvLCJ7uSHYpSSrVLk36c7K+26moL1+1PciRKpa7S0lIWLlwY8fMmTpwY9tn5zz33HDNmzOhwmQULFvDII48AMHv2bObMmRNxTAMHDqSioiLi54Xrsssu48iRIxw5coQnnngibuvVpB8Hzb4AuyrqAdhRXp/kaJRKXdEm/Xi78sormTlzZrLD6NDChQvJz8+Pe9LXIZtxsKOiDl/AMOykXDYfqKW2yUuuO/xxs+rE9sAbG9j4eU1c1zni5DxmffW0Tpf7y1/+wqOPPkpzczPjxo3jm9/8Jt/61rdYvnw5fr+fsWPHMm/ePCoqKrj//vvJzc2lrKyMCy64gCeeeAKHw8E777zDrFmz8Hg8DB48mGeffZacnBxWrFjBXXfdRX19PRkZGSxatIj777+fxsZGlixZwr333ssVV1zBnXfeyfr16/F6vcyePZspU6bQ2NjILbfcwpo1axg2bBiNjY0dvo5nn32Whx9+mPz8fM4880wyMjIAeOONN3jwwQdpbm6msLCQF198kd69e/Pcc8+xcuVKfve737WsY/v27Vx77bWsXr0agG3btjFt2rSW+2157LHHeOONN/B6vfz1r39l2LBhVFVV8c1vfpMdO3aQlZXFU089xciRI/nXv/7FXXfdBVgHYD/88ENWrVrV7n4Nzj02c+ZMtm/fzqhRo7j44ov51a9+1enftSPa04+DskN1AEw+/SRAe/uqe9i0aRPz5s3j448/prS0FKfTyZYtW7jyyiu57777+PGPf8xNN93E6aefDsDy5ct57LHH2LhxI9u3b+f111+noqKCBx98kMWLF7N69WpKSkqYO3cuzc3NTJs2jd/+9resWbOGxYsXk52dzc9+9jOmTZtGaWkp06ZN46GHHuLCCy9k+fLlvP/++9x9993U19fz5JNPkpWVxaZNm3jggQdYtWpVu69j//79zJo1i48//pglS5awcePGlsfOPfdcli5dyqeffsr111/PL3/5y3bXM3jwYHr06EFpaSlgfZDccsstHe7DoqIiVq9ezfTp01tKRLNmzeKss85i7dq1/M///A/f+MY3AJgzZw6PP/44paWlfPTRR2RmZra7X0M98sgjDB48mNLS0pgTPmhPPy4q65oBOOeUQmAbOyrqOLN/fnKDUt1GOD3yrvDuu++yatUqzj77bAAaGxvp1asX999/P2effTZut5tHH320ZfmxY8dyyimnAHDDDTewZMkS3G43GzduZMKECQA0Nzczfvx4tmzZQp8+fVrWnZeX12YM77zzDgsWLGhJmE1NTezZs4cPP/yQ733vewCMHDmSkSNHtvs6li1bxsSJEykutmYSnjZtGlu3bgWsk+CmTZvG/v37aW5u7vQkpttuu41nn32WuXPnMm/ePJYvX97h8ldffTUAY8aMaUnWS5Ys4bXXXgPgwgsvpLKykpqaGiZMmMAPf/hDbrzxRq6++mr69esHtL1fr7nmmg63GwtN+nFwuMFK+iNOtt7YwYO6SqUyYww333wzDz/88FHt+/fvp66uDq/XS1NTE9nZ2cAXx4SLCMYYLr74Yl5++eWjHlu3bl3YMbz22msMHTo0hlfSvjvvvJMf/vCHXHnllXzwwQfMnj27w+W/9rWv8cADD3DhhRcyZswYCgsLO1w+WEZyOp34fL4Ol505cyaXX345CxcuZMKECbz99ttA2/u1K2l5Jw6ONHjJdbvIc6eRk+GivNaT7JCU6tRFF13E3/72Nw4dOgRAVVUVu3fv5tvf/jY///nPufHGG7nnnntall++fDk7d+4kEAgwb948zj33XM455xw+/vhjysrKAKivr2fr1q0MHTqU/fv3s2LFCgBqa2vx+Xzk5uZSW1vbss5LLrmExx57DGMMAJ9++ikA559/Pi+99BIA69evZ+3ate2+jnHjxvGvf/2LysrKltp6UHV1NX379gXg+eef73SfuN1uLrnkEqZPn95paac95513Hi+++CIAH3zwAUVFReTl5bF9+3bOOOMM7rnnHs4++2w2b94MtL1fQx27z2LVadIXEbeILBeRNSKyQUQesNsHicgyESkTkXkikm63Z9j3y+zHB4as6167fYuIXBK3V5FkhxuaKchKB6A4N0OTvuoWRowYwYMPPsikSZMYOXIkF198Mc8//zxpaWn8x3/8BzNnzmTFihW89957AJx99tnMmDGD4cOHM2jQIKZOnUpxcTHPPfccN9xwAyNHjmT8+PFs3ryZ9PR05s2bx5133smZZ57JxRdfTFNTExdccAEbN25k1KhRzJs3j5/+9Kd4vV5GjhzJaaedxk9/+lMApk+fTl1dHcOHD+f+++9nzJgx7b6OPn36MHv2bMaPH8+ECRMYPnx4y2OzZ8/m2muvZcyYMRQVFYW1X2688UYcDgeTJk2Kar/Onj2bVatWMXLkSGbOnNnyYfO///u/nH766YwcOZK0tDQuvfTSdvdrqMLCQiZMmMDpp5/O3XffHVVMRzHGdPgDCJBj304DlgHnAK8C19vtvwem27e/C/zevn09MM++PQJYA2QAg4DtgLOjbY8ZM8Z0B19/epm58rGPjDHGXPvk/5nrfv9/SY5IpbqNGzcmO4SIvP/+++byyy9PdhgJ8atf/crcd999CdlWPPZrW+8lYKVpJ6922tO311Fn302zfwxwIfA3u/154Cr79hT7PvbjF4lVpJoCvGKM8RhjdgJlwNgIPp9S1pGGZvJDe/p12tNXqjuaOnUqL7zwQsvQyuNRWAdyRcQJrAK+DDyO1Us/YowJHrnYC/S1b/cFPgMwxvhEpBootNuXhqw29Dmh27oduB1gwIABEb6c5Kiqb+aUIutgV3FuBh9u06Svji8TJ05k4sSJyQ6DcePG4fEc/f/15z//mTPOOCMu658/f/4X2qZOncrOnTuPavvFL37BJZfEXqFOxn4NK+kbY/zAKBHJB+YDw7oqIGPMU8BTACUlJaarthNPRxq8R/X0a5t8NHn9uNOcSY5MqePLsmXLEr7Ntj4IurOIRu8YY44A7wPjgXwRCX5o9AP22bf3Af0B7Md7AJWh7W08p9tq9gWo8/haD+TmWEO49GCuUioVhTN6p9ju4SMimcDFwCas5B88g+Bm4B/27QX2fezH37MPLCwArrdH9wwChgAdn/nQDVQ3egHIz7KmXSjItpJ/cOy+UkqlknDKO32A5+26vgN41RjzpohsBF4RkQeBT4Gn7eWfBv4sImVAFdYIHowxG0TkVWAj4APusMtG3Vq9xzqskeu2dmWBnfwPN3iTFpNSSrWn06RvjFkLnNVG+w7aGH1jjGkCrm1nXQ8BD0UeZuqqb7aSfla6Vb8P9viPaE9fKZWC9IzcGDU2W19WstKtz8/gAd0j2tNX3dCuXbtaJlhLJTqfvs6nnzLq7aSfnWH19HtkBnv6mvSVAjqdkyYZdD59FbUGT7C8Y+3KNKeD3AwXRxq1vKPC9NZMOBDeBGVhO+kMuPSRThebO3cuzzzzDGDNMHnVVVfh8/m48cYbWb16NaeddhovvPACWVlZzJw5kwULFuByuZg0aRJz5syhvLyc73znO+zZswewphqYMGECs2fPZvv27ezYsYMBAwawc+dOnn76aU47zZpRdOLEicyZM4fhw4frfPo6n3730tLTT2/9/OyRlaY9fZXyVq1axbPPPsuyZctYunQpf/zjHzl8+DBbtmzhu9/9Lps2bSIvL48nnniCyspK5s+fz4YNG1i7di333XcfAHfddRc/+MEPWLFiBa+99hq33XZby/o3btzI4sWLefnll5k2bRqvvvoqYM3iuX//fkpKSnQ+fXQ+/W6nIXggN6P1RKyCrHQ9kKvCF0aPvCssWbKEqVOntkydfPXVV/PRRx/Rv3//lvnxb7rpJh599FG+//3v43a7ufXWW7niiiu44oorAFi8ePFRSbampoa6OmvWliuvvLIlsV133XVMmjSJBx54gFdffbVlvnidTz/x8+lrTz9G9Z4v9vTzs9J0yKbqttqa393lcrF8+XKuueYa3nzzTSZPngxAIBBg6dKllJaWUlpayr59+8jJyQFo+TAB6Nu3L4WFhaxdu5Z58+Yxbdo0oHU+/eDz9+zZc9QsmbG68847mTFjBuvWreMPf/gDTU0dX+via1/7Gm+99RZvvvlml8yn/6c//YnGxkYmTJjQMrWyzqffzTQ0+xABd1rrrszPSm85aUupVHXeeefx97//nYaGBurr65k/fz7nnXcee/bs4ZNPPgHgpZde4txzz6Wuro7q6mouu+wyfvOb37BmzRoAJk2axGOPPdayzmBppC3Tpk3jl7/8JdXV1S09d51PPwXn01cdq/f4yU53HfXpnJ+ZpuUdlfJGjx7Nf/7nfzJ27FjGjRvHbbfdRkFBAUOHDuXxxx9n+PDhHD58mOnTp1NbW8sVV1zByJEjOffcc5k7dy4Ajz76KCtXrmTkyJGMGDGC3//+9+1u75prruGVV17huuuua2nT+fQTP5++BD9hU1FJSYkJd2xustz7+loWbzrEip98paXtl//czFMf7mDbQ5d2+Vc11T1t2rQprmUMFT9z5syhurqan//8512+rQ8++IA5c+bw5ptvRr2Ott5LIrLKGFPS1vJ6IDdGVk//6Nk08zLT8AUMjV5/y1BOpVTqmzp1Ktu3b2+5WtjxSDNSjBqafV9I7MF5eGqbvviYUip6Op9+7DQjxaje4285Gzcoz22dlVvT6KV3njsZYaluwBij5b8I6Xz6R4umPK8HcmPUUU+/pin1Tj9XqcHtdlNZWRnVP61SYCX8yspK3O7IOpba049RfbOfk/O/WNMHqGnSYZuqbf369WPv3r2Ul5cnOxTVjbnd7paTvMKlST9GTV4/mWnHlndaa/pKtSUtLa3Ts0OV6gpa3omRxxcg4wtJv7Wmr5RSqUSTfoyavH4yXEfvxlw76WtPXymVajTpx8jq6R+9G91pDtKcojV9pVTK0aQfA2MMzb4AGa6jyzsiQq47jVpN+kqpFKNJPwYeXwA4erK1oDy3i5pGLe8opVKLJv0YeLxW0j+2pw9oT18plZI06cfA47Pm0j/2QC5AXqZLT85SSqWcTpO+iPQXkfdFZKOIbBCRu+z22SKyT0RK7Z/LQp5zr4iUicgWEbkkpH2y3VYmIql9VeIwtJZ32ujpZ2hPXymVesI5OcsH/JcxZrWI5AKrRGSR/dhvjDFzQhcWkRHA9cBpwMnAYhE51X74ceBiYC+wQkQWGGM20k112tPXmr5SKsV0mvSNMfuB/fbtWhHZBPTt4ClTgFeMMR5gp4iUAWPtx8qMMTsAROQVe9lum/SbWmr6X0z6WtNXSqWiiGr6IjIQOAsITnU3Q0TWisgzIlJgt/UFPgt52l67rb32Y7dxu4isFJGVqT4vSUtPv43yTp47jfpmPz5/INFhKaVUu8JO+iKSA7wGfN8YUwM8CQwGRmF9E/h1PAIyxjxljCkxxpQEr26fqoKjd9xt9vStL1F1Hi3xKKVSR1hJX0TSsBL+i8aY1wGMMQeNMX5jTAD4I60lnH1A/5Cn97Pb2mvvtpo66ukHZ9rUur5SKoWEM3pHgKeBTcaYuSHtfUIWmwqst28vAK4XkQwRGQQMAZYDK4AhIjJIRNKxDvYuiM/LSA5PhzX94Jz6WtdXSqWOcEbvTAC+DqwTkVK77b+BG0RkFGCAXcC3AYwxG0TkVawDtD7gDmOMH0BEZgBvA07gGWPMhji+loTraMhmy0ybmvSVUikknNE7S4C2rum2sIPnPAQ81Eb7wo6e1910NGQzV+fUV0qlID0jNwYdDdnskalz6iulUo8m/Rh0NGRTe/pKqVSkST8GHQ3ZzMnQpK+USj2a9GPQ5PPjdAgu5xd3o8vpICvdqWflKqVSiib9GHi8gTbr+UG5bpf29JVSKUWTfgw8vkCbwzWDct1pOmRTKZVSNOnHwOP74kXRQ2lPXymVajTpx6Cpk/JOns60qZRKMZr0Y2D19Dsq72hPXymVWjTpx8Cq6XdU3knTSyYqpVKKJv0YNHk77unnuV1a3lFKpRRN+jHw+AJkdNjTd+HxBVrO3FVKqWTTpB8Da5x+x0M2Qc/KVUqlDk36MfD4/J329EGTvlIqdWjSj0FnQzZbe/pa11dKpQZN+jHo7IzcPO3pK6VSjCb9GHR+Rq729JVSqUWTfgw8vs4O5Aavk6s9faVUatCkH6VAwNDs63waBtCrZymlUocm/Sg1+9u/KHpQjtb0lVIpRpN+lDwdXB83yOkQstOdmvSVUilDk36Umlquj9vxLszVmTaVUimk06QvIv1F5H0R2SgiG0TkLru9p4gsEpFt9u8Cu11E5FERKRORtSIyOmRdN9vLbxORm7vuZXW91uvjtl/eAcjL1Jk2lVKpI5yevg/4L2PMCOAc4A4RGQHMBN41xgwB3rXvA1wKDLF/bgeeBOtDApgFjAPGArOCHxTdkSeSnr5He/pKqdTQadI3xuw3xqy2b9cCm4C+wBTgeXux54Gr7NtTgBeMZSmQLyJ9gEuARcaYKmPMYWARMDmuryaBPL5gTb/jnn6u20VNo/b0lVKpIaKavogMBM4ClgG9jTH77YcOAL3t232Bz0Kettdua6/92G3cLiIrRWRleXl5JOElVJPX7ul3cCAXtKavlEotYSd9EckBXgO+b4ypCX3MGGMAE4+AjDFPGWNKjDElxcXF8Vhllwj29Dsasgl69SylVGoJK+mLSBpWwn/RGPO63XzQLttg/z5kt+8D+oc8vZ/d1l57t9RS0++0p69JXymVOsIZvSPA08AmY8zckIcWAMERODcD/whp/4Y9iuccoNouA70NTBKRAvsA7iS7rVtqCo7T7+RAbp47jWZ/oKUcpJRSyeQKY5kJwNeBdSJSarf9N/AI8KqI3ArsBq6zH1sIXAaUAQ3ALQDGmCoR+Tmwwl7uZ8aYqri8iiQI9vQ7G7IZOqd+Z6UgpZTqap0mfWPMEkDaefiiNpY3wB3trOsZ4JlIAkxVngh6+mDNtFmcm9HlcSmlVEf0jNwoRTJkE3SmTaVUatCkH6VIhmyCzqmvlEoNmvSj1NrT73z0DuhMm0qp1KBJP0oenx+XQ3A5w0362tNXSiWfJv0odXZR9KDW8o729JVSyadJP0oenz+sIZg5GXogVymVOjTpR8kTZk/f6RByMlxa3lFKpQRN+lHy+AJkhHmyVZ7OtKmUShGa9KPU5PWH1dMHnWlTKZU6NOlHKZKevk66ppRKFZr0o+TxRdLTd+nVs5RSKUGTfpQ8vvAO5EKwvKM9faVU8mnSj1KTNxD2rJla3lFKpQpN+lGKrLyTRk2jF2sCUqWUSh5N+lGyxumHOWQz04UvYFouvKKUUsmiST9K1hm54ff0QeffUUolnyb9KEXU09c59ZVSKUKTfpSscfrhD9kE7ekrpZJPk34UAgFDsz+yIZugM20qpZJPk34UghdQiWTIJmjSV0olnyb9KHh84V0qMSh4cfQaLe8opZJMk34Uwr0oelCPTCvpVzdq0ldKJVenSV9EnhGRQyKyPqRttojsE5FS++eykMfuFZEyEdkiIpeEtE+228pEZGb8X0riBC+KHu6Qzax0J2lO4UiDJn2lVHKFk7WeAya30f4bY8wo+2chgIiMAK4HTrOf84SIOEXECTwOXAqMAG6wl+2WIu3piwg9MtOpbmzuyrCUUqpTrs4WMMZ8KCIDw1zfFOAVY4wH2CkiZcBY+7EyY8wOABF5xV52Y8QRpwCPN5j0w6+O5WelaXlHKZV0sdT0Z4jIWrv8U2C39QU+C1lmr93WXvsXiMjtIrJSRFaWl5fHEF7XaTmQG2Z5ByA/M03LO0qppIs26T8JDAZGAfuBX8crIGPMU8aYEmNMSXFxcbxWG1fBOXTCHbIJVk9fk75SKtmiSvrGmIPGGL8xJgD8kdYSzj6gf8ii/ey29tq7pUiHbAJ2TV+TvlIquaJK+iLSJ+TuVCA4smcBcL2IZIjIIGAIsBxYAQwRkUEiko51sHdB9GEnV6QHcsEatnmkQQ/kKqWSq9MDuSLyMjARKBKRvcAsYKKIjAIMsAv4NoAxZoOIvIp1gNYH3GGM8dvrmQG8DTiBZ4wxG+L+ahIk2NMPd8gmWOWd+mY/zb4A6RF8Q1BKqXgKZ/TODW00P93B8g8BD7XRvhBYGFF0KarJG3lPPz+r9QSt4tyMLolLKaU6o13OKHi80dT0g0lfSzxKqeTRpB+Flpp+ROWddAAdwaOUSipN+lGIqrxj9/Q16SulkkmTfhQ8Pj9pTsHpkLCfE1rTV0qpZNGkHwWPL/xLJQblZ9rlHU36Sqkk0qQfhUguih6U63YhAtU6Vl8plUSa9KPQFMFF0YMcDrFO0NKevlIqiTTpR8Eq70S+63TSNaVUsmnSj4LH6ycjgsnWgnpkpWtPXymVVJr0o9AUQ09fa/pKqWTSpB8Fj9cfXdLP0pq+Uiq5NOlHweMLRFXeKchKp6pee/pKqeTRpB8Fjy+AO4qefs/sdGqbfDTb0zgopVSiadKPQrQHcgtzrBO0tLevlEoWTfpRaPT6yYzw5CyAwmwr6VfWe+IdklJKhUWTfhSavH4yo+rpW/PoV9ZpT18plRya9KPQ6PVHdFH0oJ7ZWt5RSiWXJv0IBQKGJm8gqqRflG319CvqtLyjlEoOTfoRCl5AJTM98qSfl+nC5RAqtaevlEoSTfoRarIvlRhNTV9E6JmdTpXW9JVSSaJJP0KNdtKPdGrloMKcDB29o5RKGk36EWpN+pH39MEatqnlHaVUsnSa9EXkGRE5JCLrQ9p6isgiEdlm/y6w20VEHhWRMhFZKyKjQ55zs738NhG5uWteTtdrbI6+vAPWCVo6ZFMplSzh9PSfAyYf0zYTeNcYMwR4174PcCkwxP65HXgSrA8JYBYwDhgLzAp+UHQ3Hp+d9KM4kAvWsM1KHb2jlEqSTpO+MeZDoOqY5inA8/bt54GrQtpfMJalQL6I9AEuARYZY6qMMYeBRXzxg6RbaGy2Ru9EW94pysmgvtnfckBYKaUSKdqafm9jzH779gGgt327L/BZyHJ77bb22rudxhhG70DrCVpa11dKJUPMB3KNMQYwcYgFABG5XURWisjK8vLyeK02buJxIBfQYZtKqaSINukftMs22L8P2e37gP4hy/Wz29pr/wJjzFPGmBJjTElxcXGU4XWdppiHbFpJv0KHbSqlkiDapL8ACI7AuRn4R0j7N+xRPOcA1XYZ6G1gkogU2AdwJ9lt3U4sJ2cBFGbrpGtKqeRxdbaAiLwMTASKRGQv1iicR4BXReRWYDdwnb34QuAyoAxoAG4BMMZUicjPgRX2cj8zxhx7cLhbaBmyGeXoneJcK+kfqm2KW0xKKRWuTpO+MeaGdh66qI1lDXBHO+t5BngmouhSUEtN3xVd0s/OcJGb4eJQjZZ3lFKJp2fkRqjJGyDd5cDhkKjX0buHmwPV2tNXSiWeJv0IRXsBlVAn5bk5UKNJXymVeJr0I9TQ7Is56ffKy+CgJn2lVBJo0o9QfbOf7IzYe/qHaj0EAnE7vUEppcKiST9C9R4fORmdHv/u0Ek93PgDRsfqK6USTpN+hBo8frLSY0v6vfPcABys1qSvlEosTfoRqvP44lLeAfRgrlIq4TTpR6ih2Ud2HMo7oElfKZV4mvQjVBeH8k5RTgYOgUOa9JVSCaZJP0INzT5yYizvOB1CcW6GnqCllEo4TfoRCAQMDc2x9/RBT9BSSiWHJv0INNjz7sQ6ZBOsETx6gpZSKtE06UegweMDICvG8g7AyfmZfH6kCWuOOqWUSgxN+hGos5N+dhzKO/17ZlHn8XGkwRvzupRSKlya9CPQYM+lH+uQTYABPbMA2FPVEPO6lFIqXJr0I9Da04+9vKNJXymVDJr0I9DQbCf9OPT0+/fMBDTpK6USS5N+BOo8wfJO7D39rHQXRTkZfKZJXymVQJr0I1DdaB10zXOnxWV9A3pmsrtSk75SKnE06UegJpj0M+OV9LO0vKOUSihN+hGobvSS4XLgjvHKWUEDemaxv7qRZl8gLutTSqnOaNKPQE2jlx5x6uWDNVY/YODzI41xW6dSSnVEk34EquOc9HXYplIq0WJK+iKyS0TWiUipiKy023qKyCIR2Wb/LrDbRUQeFZEyEVkrIqPj8QISKd5J/0uF2QDsqqyP2zqVUqoj8ejpX2CMGWWMKbHvzwTeNcYMAd617wNcCgyxf24HnozDthMq3km/d14GuW4XWw/Wxm2dSinVka4o70wBnrdvPw9cFdL+grEsBfJFpE8XbL/LxDvpiwhDe+ey5YAmfaVUYsSa9A3wjoisEpHb7bbexpj99u0DQG/7dl/gs5Dn7rXbjiIit4vIShFZWV5eHmN48VXd6I3bcM2goSdZSV9n21RKJUKsSf9cY8xorNLNHSJyfuiDxspkEWUzY8xTxpgSY0xJcXFxjOHFjz9gqG3ydUnSr2nycduH8PgAABOnSURBVLDGE9f1KqVUW2JK+saYffbvQ8B8YCxwMFi2sX8fshffB/QPeXo/u61bqG2yTsyKZ3kHYGjvXAC2aF1fKZUAUSd9EckWkdzgbWASsB5YANxsL3Yz8A/79gLgG/YonnOA6pAyUMqrrG8GoDA7Pa7rPTWY9A/UxHW9SinVllimi+wNzBeR4HpeMsb8U0RWAK+KyK3AbuA6e/mFwGVAGdAA3BLDthOuvNYqv/TKzYjreguy0+mVm8GWA3VxXa9SSrUl6qRvjNkBnNlGeyVwURvtBrgj2u0l2yE76RfHOemDfTD3oPb0lVJdT8/IDVN5Fyb9ESfnsfVAHU32hdeVUqqraNIPU3mthzSnxP1ALsCYAQU0+wOs31cd93UrpVQoTfphKq/1UJyTgX0MI65Gf6kAgJW7D8d93UopFUqTfpjK6zxdUtoBKMrJYFBRNqs06Sulupgm/TAdqmmiKKdrkj7A6AEFrN59WM/MVUp1KU36Ydpf3USffHeXrb9kYAGV9c3s0ssnKqW6kCb9MNQ2ealu9NKvIKvLtjHGrusv31nZZdtQSilN+mHYZ1/Zql9BZpdtY0ivHE7Kc/Pe5kOdL6yUUlHSpB+GvVXBpN91PX0R4SsjevHh1godr6+U6jKa9MOw97BVZ++b33U9fYCvDO9No9fPJ9u1xKOU6hqa9MOw93AjGS4HRTnxnWztWOMHF5Kd7mTRpoNduh2l1IlLk34YysrrGFSU3SUnZoXKcDk5/9Ri3tlwEK8/0KXbUiqlzP8OrH892VGcEDTph2Hz/lqG98lLyLa+NrofFXUeFm3U3r46TjUfMyy5qRrWvAx/61YT73ZbmvQ7caShmQM1TQw7KTch27tgWC/65mfyl6W7E7I9pRKqfAv8T5/WXn3tQTi0ObkxnWA06Xdis33R8mEJ6uk7HcJ/jBvA/22vpOyQzrGvjiOV22H1C9btN+6CzQvh16fC//uv1mU8tRCwS5tli2H9a4mP8zgXy0VUTgif7jkCwGknJybpA1xX0p9H391m/dxwVsK2q1TcffAIbP5/UPM5NFS0tntq4JUbrNsH17W2710BC++GXiNg0wKr7UsT4PNSGDo5cXEfx7Sn34llOyv5cq+cLp1351jFuRl867xTWLDmc0o/O5Kw7SoVVwfWwQcPw4G10H8sDLvCanekwaB/b10upzf0Pwfc+fDnqVBZ1prwAX49FF6eBlvfhoYq6xtAKG8jLJ5tlYpUp7Sn3wGfP8CKnVVMHd034dv+zsTBvLLiMx54YwN//fZ4XE79fFbdiDHw1j2Q2RO+txoyrWlG+HAOfOnfoO8YeLAXnPNdmPyw9VjZYnjtNigYZB3crdp+9DpfmgbYExJe/DMYdSNkFcLWf8KS38DOD+Fb7yXsJXZXmvQ78FFZBfXNfs4bUtz+Qt4mqP0cNsyHUy6AzHzoeUrM287JcPHTK4Zz1yulzF20lR9PHhbzOpXqMoc2WfX4w7vgn/dCj36wvxQun9ua8AHO/1Hr7Z8cBGfIuS9f/gr8aBuYgJX0d3wAC38EQy6BC/4blj4Bn74I3npYdL/1UzAIep9mPX/fKtjyT+h3NmQXJuJVd0uSylP5lpSUmJUrVyZt+zNeWs2SsgqW/fdFZLicbS/0h3+33tyhrn8ZTr0EAn7Y8b71DxB8Y0bo3tfX8fLyPfz2+lFMGZX4bxxKdcpTCw/3s25n9oTGKut2z8EwYwU42vnfCYfPY5WDHCHfdDcusMo5od8EiodBuT0KSJww/WPw1EHhYMjqGf32uykRWWWMKWnrMe3pt2NPZQNvrT/AzeMHfjHh1x6EN38AI69rTfgX3W+NP175jHWAKqc35A+wDkxl5MEPN1q9l+YGKD417DhmfXUEO8rr+P68UmqbfNw4bkCXnySmjkN+Hzjtf/f6Smiug4IvHb3MhvnQeARKwhwv31Bl1dkX3t3a1lgF3/iHtZ4+Z8aW8AFcbRxLG3ElDP8q7FkKny2zOlbn/xieu8x63PjhiXOs27knw1dmw2lXtb2uE5D29NtgjGH6X1bz3pZDfPTjC+id54bmelj8gHVwqnxza28G4I4VrYn83Z/BR79ufWz4ldZBqf7nwGdLIS0b/mszuO3RQDWfw9pXYdy3IS1kbp/aA5BdDA4njc1+pr+4ig+2lHPp6Scx66uncVKPrpvbX3VzzQ3Wwc1DGyHgs95f61613otTfge/Hg6eauvA6r/daX0T3bUE5n/bev65P4AB/wbZRdZ72WW//8feZpUwl8yFZX+A+grAQPFwmPQgbHsb+oyCs25Mzuves9TqWB3ZA2/92CoTBeX0tpJ/1U7rg+i8H1llImOskmxFmbVPTh4N0XSq/F5w2tfPrt5r/e+G+yGza4n1TcWZZlUHqj+z2rwNVpxRxNNRTz/hSV9EJgO/BZzAn4wxj7S3bDKSvjGG371Xxq8XbeWeycOYXpIHG/8OpS/B56thwHjrDVR3EPZ8Yv2xvru09Q/jqYUNf4fcPlYts+9oeP6rsOsjEEfrG7HnKVA01PoQqdlrPXbqpdYbcs8nUF9u9VJOPgt6n0Ygu5jnakp45ANrhMJ3hzcycdSpnD58hB7kTTU+j/UPf2AdpGVB3slWR+HzT62/cU4vaKi0EkP5FnD3sN4rnzxmJduBE1rXVb0PGg9bidnXBNm9rJ4txipjONOsJOdthM1vWttsPGwl+1DFw6F8E6TnQnPtMQGLtb5+Y+0Do28d3Q7WtowfCodA5TYYMsk6GNt/rNWhSe+6GWijEvBb+2DF01ZsS59sLf+A9S28vsL6v+s/FrbbB4CHXm79PerL4YxrofDLsPwp68PkrJushFy+Gcreg7w+MPgi6DkI3v6J9c0pt4/VySsebh2wPrDW2mfZRdB0xHo/fP4pDL0Uhn0VVj0Ln/zOiiOzwHpfBA3/Klz7wtGlrTClTNIXESewFbgY2AusAG4wxmxsa/lEJH1jDPXNfg5UN7FmTyX/WL2b9Tv28Yu+H/GV/APIvlXWHys9B6560vpqCdbX19IX4cwbOq8Zeptg/d/g1MnWiIamasjIgb2rrH/aPiOh7pB1MMwErH8oZzrsX3P0GOa0LDw9T6WqupbejTvwkMYmBpGb4STNncWRXuPIyc3DnVdERlYPcqvWkrHjHaTkVuvNmtUT+o+D3R8DAiOmWCMe0nMg9yQrWZx0hvXP4nBZv6t2WG/egL/1gFzVDithZeRCxVbrG0pWkdUzsXaq9aGYmW8lqaod1j9ZepZVZ03PPrr3YoyV0Dx1kFNsbQusGIPLGWOtPz3bitPltn5q9lm90Oxi6591/xorV7ncVlktq6e1noAXXJnWc9OzrLhdbuu11+yzPoRdbmsdR3ZbyU+c1ofw4d3WP3RzvbXv9q6EXsOtfbRlodXLq/7M+uf21ELZIqvHuG+VlShDOdKsv7m3obXzcKwB/2Z9MHgb4LPl1vsvKLPAeg1tKRhoJZu0TOtDomiI9Tr6jrG29d6DVrzj77Dq7Q0VVrIL9uTPvxvy+1sfIques96TF91vvSaXG974nvWBdtZNcOb1Hb/nU03VTlhwJ0z4vnWOwKrnrL97ZZn1+L/fY73OpU988bmONGu/14dc66L/OdaHX2iSDv7PhBow3urEhTr2g/fLX7FGLhV+2frJKoKsArjgPkiL7ht9KiX98cBsY8wl9v17AYwxD7e1fLRJ/0jFQaqfuMhKFBjE/sHYvzE47N/BNsGQTRNu8eIQcBqf9al80hnW8LBew62EkGiV260PgKZqWP4HqxzkzMCb0YNDVdWYqh30adiCk7YnaPOYNDLEG5dQqsnFLw56mmoCCI24yaaxw+f4cOLCjxcXdZJNganmsPTAIOSYepz4j4p9n5xEL1OBgwB+nKTjxYcTBwEcGOrJ7HSbsQgg9nvD4sVFGr52lzksPQjgRAiQY+oolyLqJZsepoY9jn6sdZ1O78AhHBj+mfYVrmn+O7mmjs3OIQwK7Ga180z6BT7nHN8K5qd/lZs880inGS9pfOboS71ks9fRl3JHIR7SGeovY7PzVA46elFoqsgxdWx1fpnDks9Ox8DoShMnsAu8/2KPoz/bnaeAMYzwb8Yj6aQbL9k0UBA4zHrXCCqkiPG+ZdRILjsdA6mWPBwEyDb1fDmwgx2OQVQ7elAcKAegwByhgUz2OvtR4lvNRd73+UPGrQRwUOPIo1fgEBd4P2S7cxArXWMoCBzmsOQf9fcb1iePx6I8OTOVkv41wGRjzG32/a8D44wxM0KWuR24HWDAgAFjdu+OfA6a2uoqtv3xZqyeosPekQ7rl7S2CQ7EIWSkuXCnueiRl0uPzDQcaW446+tQPDQOrzoBKrcTSM+jot7DvmofdUcO4qmtpNrv5nOKGFjxPtXOImodeWR6KjjsLMTnNwyt/YQt2WfjMD56+Cqodvakj2cnXkc6GYEGAjjx46LAd5BmyaBX82eICbA/YyDuQD05/mo+Tx+Ew/jJCtTQ4Gidn6je2YMevgry/IfZn/4l+jTvJttfQ2Vab4q8BwCodebjF6e1HXHhMl76NO+iytUbn6ThMl48jkycxkdAHPhJI9dfRbWrCJexPsgaHdnUuHqS468mx19NRVofmhxZZPlrcRo/mYE6HPhpFjfpxoNHMnEH6jmU3o8CXzl+XBxK70ux93NcxkuWv45aZz75/gp8uHDgpzKtD72a91LjKuDz9EFszTyLYu8+cv1H2OE+DZ/DHnZoTOxJ1/5/dBAgIDEeBFXd2sDC7KiHaner0TvGmKeAp8Dq6UezjtwePRn9ozfiGldKKxyMA+iVC71OAhh4zAIj23nilK6MSimVghJ9BHAf0D/kfj+7TSmlVAIkOumvAIaIyCARSQeuBxZ08hyllFJxktDyjjHGJyIzgLexhmw+Y4zZkMgYlFLqRJbwmr4xZiGwMNHbVUoppVMrK6XUCUWTvlJKnUA06Sul1AlEk75SSp1AUnqWTREpByI/JbdVEVDR6VKJlYoxQWrGlYoxQWrGlYoxQWrGlYoxQXzj+pIxps2rP6V00o+ViKxs71TkZEnFmCA140rFmCA140rFmCA140rFmCBxcWl5RymlTiCa9JVS6gRyvCf9p5IdQBtSMSZIzbhSMSZIzbhSMSZIzbhSMSZIUFzHdU1fKaXU0Y73nr5SSqkQmvSVUuoEclwmfRGZLCJbRKRMRGYmOZZdIrJOREpFZKXd1lNEFonINvt3QRfH8IyIHBKR9SFtbcYglkftfbdWREYnOK7ZIrLP3l+lInJZyGP32nFtEZFLuiim/iLyvohsFJENInKX3Z60/dVBTMneV24RWS4ia+y4HrDbB4nIMnv78+xp1BGRDPt+mf34wATG9JyI7AzZV6Ps9oS93+3tOUXkUxF5076f+H1ljDmufrCmbN4OnAKkA2uAEUmMZxdQdEzbL4GZ9u2ZwC+6OIbzgdHA+s5iAC4D3sK6vPg5wLIExzUb+FEby46w/5YZwCD7b+zsgpj6AKPt27nAVnvbSdtfHcSU7H0lQI59Ow1YZu+DV4Hr7fbfA9Pt298Ffm/fvh6Yl8CYngOuaWP5hL3f7e39EHgJeNO+n/B9dTz29McCZcaYHcaYZuAVUu+6gFOA5+3bzwNXdeXGjDEfAlVhxjAFeMFYlgL5ItIngXG1ZwrwijHGY4zZCZRh/a3jHdN+Y8xq+3YtsAnoSxL3VwcxtSdR+8oYY+rsu2n2jwEuBP5mtx+7r4L78G/ARSLxvZJ7BzG1J2HvdxHpB1wO/Mm+LyRhXx2PSb8v8FnI/b10/A/S1QzwjoisEuui7wC9jTH77dsHgN5JiKu9GFJh/82wv2o/E1L6Snhc9lfqs7B6iymxv46JCZK8r+xyRSlwCFiE9a3iiDHG18a2W+KyH68GCrs6JmNMcF89ZO+r34hIxrExtRFvvP0v8GMgYN8vJAn76nhM+qnmXGPMaOBS4A4ROT/0QWN9f0vquNlUiCHEk8BgYBSwH/h1MoIQkRzgNeD7xpia0MeStb/aiCnp+8oY4zfGjMK63vVYYFiiYzjWsTGJyOnAvVixnQ30BO5JZEwicgVwyBizKpHbbcvxmPRT6uLrxph99u9DwHysf4yDwa+Q9u9DSQitvRiSuv+MMQftf9oA8EdayxIJi0tE0rCS64vGmNft5qTur7ZiSoV9FWSMOQK8D4zHKpEEr8oXuu2WuOzHewCVCYhpsl0iM8YYD/Asid9XE4ArRWQXVsn5QuC3JGFfHY9JP2Uuvi4i2SKSG7wNTALW2/HcbC92M/CPJITXXgwLgG/YoxrOAapDyhpd7ph66lSs/RWM63p7VMMgYAiwvAu2L8DTwCZjzNyQh5K2v9qLKQX2VbGI5Nu3M4GLsY43vA9cYy927L4K7sNrgPfsb01dHdPmkA9swaqbh+6rLn+/G2PuNcb0M8YMxMpJ7xljbiQZ+ypeR4RT6QfriPxWrPriT5IYxylYoyjWABuCsWDV5t4FtgGLgZ5dHMfLWF//vVh1w1vbiwFrFMPj9r5bB5QkOK4/29tda7/x+4Qs/xM7ri3ApV0U07lYpZu1QKn9c1ky91cHMSV7X40EPrW3vx64P+R9vxzrAPJfgQy73W3fL7MfPyWBMb1n76v1wF9oHeGTsPd7SIwTaR29k/B9pdMwKKXUCeR4LO8opZRqhyZ9pZQ6gWjSV0qpE4gmfaWUOoFo0ldKqROIJn2llDqBaNJXSqkTyP8Hin/R28xrDo8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1f09e7993194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# forward pass - calculate expected_daily_hospit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mexpected_daily_hospit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d047f5d9155c>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Calculate prior loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_prior_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# Seed initial infections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-cf8fd36a9cfc>\u001b[0m in \u001b[0;36mcalc_prior_loss\u001b[0;34m(tau, phi, R0, alpha, sigma)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m#dist_R0 = distribution.normal.Normal(loc=torch.tensor([3.6]), scale=torch.tensor([0.8]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdist_R0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;31m#dist_alpha = distribution.normal.Normal(loc=torch.tensor([0.01]), scale=torch.tensor([0.01]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;31m# compute the variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m_validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msupport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The value argument must be within the support'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_checked_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The value argument must be within the support"
          ]
        }
      ]
    }
  ]
}