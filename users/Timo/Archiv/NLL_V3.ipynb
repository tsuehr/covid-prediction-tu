{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLL_V3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d17BEQFdPTqc"
      },
      "source": [
        "import scipy.stats\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import expon, truncexpon, truncnorm, nbinom, norm\n",
        "import pandas as pd\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import distributions\n",
        "from torch import rand\n",
        "from torch import autograd\n",
        "from torch import optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdBc47jlPTqe"
      },
      "source": [
        "np.random.seed(seed=101)\n",
        "torch.manual_seed(101)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "dtype = torch.float64\n",
        "device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "EaFwH9Vm7YMg",
        "outputId": "986edd5f-5430-4136-fe19-1a4e000b89f0"
      },
      "source": [
        "data = pd.read_csv('covid19model.csv')\n",
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>hospit</th>\n",
              "      <th>serial_interval</th>\n",
              "      <th>delay_distr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-02-17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046535</td>\n",
              "      <td>1.300600e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-02-18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.087065</td>\n",
              "      <td>3.004645e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-02-19</td>\n",
              "      <td>0</td>\n",
              "      <td>0.112061</td>\n",
              "      <td>4.467391e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-02-20</td>\n",
              "      <td>0</td>\n",
              "      <td>0.119346</td>\n",
              "      <td>5.547300e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-02-21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.114540</td>\n",
              "      <td>6.242203e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>2021-03-25</td>\n",
              "      <td>38</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.817211e-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>2021-03-26</td>\n",
              "      <td>31</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.349426e-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>2021-03-27</td>\n",
              "      <td>39</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.959313e-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>2021-03-28</td>\n",
              "      <td>32</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.633974e-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>2021-03-29</td>\n",
              "      <td>45</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.362655e-32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>407 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  hospit  serial_interval   delay_distr\n",
              "0    2020-02-17       0         0.046535  1.300600e-02\n",
              "1    2020-02-18       0         0.087065  3.004645e-02\n",
              "2    2020-02-19       0         0.112061  4.467391e-02\n",
              "3    2020-02-20       0         0.119346  5.547300e-02\n",
              "4    2020-02-21       0         0.114540  6.242203e-02\n",
              "..          ...     ...              ...           ...\n",
              "402  2021-03-25      38         0.000000  2.817211e-32\n",
              "403  2021-03-26      31         0.000000  2.349426e-32\n",
              "404  2021-03-27      39         0.000000  1.959313e-32\n",
              "405  2021-03-28      32         0.000000  1.633974e-32\n",
              "406  2021-03-29      45         0.000000  1.362655e-32\n",
              "\n",
              "[407 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seIKt9FY5OF"
      },
      "source": [
        "def trunc_exponential(scale, upper):\n",
        "    sample = torch.distributions.exponential.Exponential(1/scale).rsample()\n",
        "    sample = sample/torch.tensor(1-torch.exp(-upper/scale))\n",
        "    return sample\n",
        "# torch.distributions.exponential.Exponential(1/scale).sample()/torch.tensor(1-torch.exp(-upper/scale))\n",
        "\n",
        "def trunc_normal(mu, sigma, under, upper):\n",
        "    distribution = torch.distributions.normal.Normal(loc=mu, scale=sigma, validate_args=None)\n",
        "    normal_sample = distribution.rsample()\n",
        "    cumulative = distribution.cdf(torch.tensor(upper)) - distribution.cdf(torch.tensor(under))\n",
        "    return normal_sample/cumulative"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2IY_KzX7uV9"
      },
      "source": [
        "# Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7remU4ygPTqf"
      },
      "source": [
        "cero = torch.tensor(0., requires_grad=False, device=device, dtype=dtype)\n",
        "num_impute = 6\n",
        "observed_daily_hospit = torch.tensor(data.hospit, requires_grad=False, device=device, dtype=dtype)\n",
        "pi = torch.tensor(data.delay_distr, requires_grad=False, device=device, dtype=dtype)\n",
        "serial_interval = torch.tensor(data.serial_interval, requires_grad=False, device=device, dtype=dtype)\n",
        "population = torch.tensor(5793636, requires_grad=False, device=device, dtype=dtype)\n",
        "num_observations = len(observed_daily_hospit)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG5jECpf77Xk"
      },
      "source": [
        "## Initialize latent variables/parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XhscamaPTqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2614dda2-c4d4-44b5-c51e-bb184b993062"
      },
      "source": [
        "tau= torch.tensor(np.random.exponential(1 / 0.03), requires_grad=True, device=device, dtype=dtype)\n",
        "phi = torch.tensor(truncnorm.rvs((0 - 25) / 10, (np.inf - 25) / 10, loc=25, scale=10), requires_grad=True, device=device, dtype=dtype) # has to be positive, between 0-50 --> uniform # dispersion (shape) parameter for observations\n",
        "R0 = torch.tensor(truncnorm.rvs((2 - 3.6) / 0.8, (5 - 3.6) / 0.8, loc=3.6, scale=0.8), requires_grad=True, device=device, dtype=dtype)  # probably gamma or inverse gamma distribution (compare to truncated normal) # initial reproduction number\n",
        "alpha = torch.tensor(truncnorm.rvs((0 - 1/100) / 1/100, (5/100 - 1/100) / 1/100, loc=1/100, scale=1/100), requires_grad=True, device=device, dtype=dtype) # uniform distribution between (0-5%) # probability to get hospitalized\n",
        "sigma = torch.tensor(truncnorm.rvs((0 - 0.1) / 0.3, (0.5 - 0.1) / 0.3, loc=0.1, scale=0.3), requires_grad=True, device=device, dtype=dtype)  # positive, tricky, gamma or inverse gamma, log normal  --> try something out, large sigma--> prone to overfitting # standart deviation of random walk step\n",
        "\n",
        "epsilon_t = torch.zeros(num_observations, device=device)\n",
        "epsilon_t[0] = torch.distributions.Normal(cero, sigma.detach()).rsample()\n",
        "for t in range(1, num_observations):\n",
        "  epsilon_t[t] = torch.distributions.Normal(epsilon_t[t - 1].detach(), sigma.detach()).rsample()\n",
        "epsilon_t.requires_grad_(True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4062, -0.6443, -0.7379, -0.5224, -1.0346, -0.8584, -0.9320, -1.0597,\n",
              "        -1.2271, -2.1625, -1.9980, -1.9351, -2.5766, -2.6399, -2.8520, -2.3127,\n",
              "        -2.2400, -2.1588, -1.6862, -1.7545, -2.1455, -2.1636, -2.2423, -1.9797,\n",
              "        -1.7461, -1.8958, -2.0178, -1.7697, -1.1899, -1.5608, -1.2986, -0.9878,\n",
              "        -1.1975, -0.8651, -1.3561, -1.3298, -1.3777, -1.6734, -1.5581, -1.3892,\n",
              "        -0.9920, -1.1048, -1.2804, -1.7002, -1.6482, -1.9254, -1.9525, -1.6132,\n",
              "        -1.9811, -1.7413, -1.5891, -1.5620, -1.2712, -1.5568, -1.1379, -1.0850,\n",
              "        -1.0561, -0.6375, -0.5553, -0.4397, -0.1980, -0.2442, -0.0438,  0.0886,\n",
              "        -0.0346,  0.0927,  0.2458, -0.2554, -0.6296, -1.1790, -1.6244, -1.6822,\n",
              "        -1.5316, -1.8503, -1.9239, -2.1913, -2.6200, -2.6891, -2.6408, -2.6501,\n",
              "        -2.7506, -3.0649, -3.4478, -3.4980, -4.0263, -4.1605, -4.3302, -4.1965,\n",
              "        -4.3513, -4.5640, -4.2001, -4.0767, -4.0118, -4.0224, -3.5900, -3.1960,\n",
              "        -3.5165, -3.0897, -2.7679, -2.0599, -2.3264, -2.2728, -2.3868, -2.4457,\n",
              "        -2.1072, -1.4317, -1.6422, -2.2177, -2.6457, -2.4337, -2.6734, -2.3276,\n",
              "        -2.6588, -2.9793, -2.9843, -3.2477, -3.3368, -3.2478, -3.2717, -3.5486,\n",
              "        -3.2559, -3.2838, -2.9769, -2.1630, -1.9310, -2.0309, -1.8851, -1.9015,\n",
              "        -2.0187, -2.1279, -1.9944, -2.0514, -2.0136, -2.0512, -2.0931, -2.4190,\n",
              "        -2.4278, -2.5599, -2.8164, -2.5468, -2.8613, -3.0447, -2.6980, -3.3626,\n",
              "        -3.2200, -3.2626, -3.3423, -3.4049, -3.5286, -3.6759, -3.5529, -3.3115,\n",
              "        -3.2037, -2.8429, -2.4783, -2.1741, -1.6415, -1.5179, -1.8472, -1.7043,\n",
              "        -1.6049, -1.4770, -1.4599, -1.4449, -1.6367, -1.6285, -1.6432, -1.6003,\n",
              "        -1.8026, -1.7167, -1.7861, -2.0337, -1.9578, -2.4670, -2.0855, -1.8689,\n",
              "        -1.5897, -1.2418, -0.9088, -0.3114,  0.2085, -0.2372, -0.1814, -0.1722,\n",
              "        -0.2372,  0.0678, -0.3317, -0.1988, -1.1196, -1.0384, -0.6253, -0.7208,\n",
              "        -0.4989, -0.4922, -0.9951, -0.9284, -1.0117, -0.8368, -0.5952, -0.3131,\n",
              "         0.0519, -0.4966, -0.7928, -0.8935, -1.0461, -0.8409, -1.1285, -1.7481,\n",
              "        -1.5604, -1.6710, -1.8672, -1.8347, -1.3745, -1.9537, -1.7314, -1.4200,\n",
              "        -1.3934, -1.5300, -1.7519, -1.6372, -1.5728, -1.7700, -1.8836, -2.3945,\n",
              "        -2.3191, -1.8398, -2.2704, -1.9938, -2.1676, -2.2368, -1.8591, -1.6974,\n",
              "        -1.3262, -1.4363, -1.6878, -1.6224, -1.5387, -1.0397, -1.1296, -0.8485,\n",
              "        -0.8601, -0.5636, -0.8249, -0.5664, -0.8242, -0.7860, -1.2785, -1.3583,\n",
              "        -1.2094, -0.8570, -0.6449, -0.2714, -0.3515, -0.6763, -0.8196, -0.9757,\n",
              "        -1.0231, -0.7319, -1.0296, -0.8677, -0.8283, -0.7603, -0.6460, -0.7171,\n",
              "        -0.8685, -0.5866, -0.4563, -0.5788, -0.7472, -1.2121, -1.2842, -1.3632,\n",
              "        -1.0133, -0.7221, -0.6481, -0.4974, -0.6079, -0.1602, -0.7346, -0.7321,\n",
              "        -0.5599, -0.4247, -0.5425, -0.2190, -0.3136, -0.0626,  0.1494,  1.0166,\n",
              "         0.8274,  0.9900,  1.5195,  0.8736,  0.9748,  1.1319,  1.2602,  1.0284,\n",
              "         1.1556,  1.0908,  1.2538,  1.1709,  1.6944,  1.6119,  1.3155,  1.4514,\n",
              "         1.5784,  2.0880,  2.0321,  2.2719,  2.4926,  2.6567,  2.2848,  2.2638,\n",
              "         2.1597,  2.3206,  2.3380,  2.4200,  2.4763,  2.3003,  2.1518,  2.6020,\n",
              "         2.6113,  2.4885,  2.4798,  2.2825,  2.2287,  1.6632,  1.1708,  1.2397,\n",
              "         1.5780,  2.0547,  2.0981,  2.0337,  2.1404,  1.7567,  1.4868,  1.7066,\n",
              "         1.9083,  2.0455,  2.0434,  1.7166,  1.8430,  1.5980,  1.7975,  1.6326,\n",
              "         2.2069,  2.4912,  3.0972,  3.1313,  3.4253,  3.8023,  3.5228,  3.1510,\n",
              "         3.6991,  3.8266,  3.6347,  3.9249,  3.7223,  3.3062,  3.1448,  2.6121,\n",
              "         2.3787,  2.6168,  2.6262,  2.7565,  3.0695,  3.2299,  3.4249,  3.4766,\n",
              "         3.4546,  3.3117,  3.2180,  3.5295,  3.3876,  3.3875,  3.3163,  3.8985,\n",
              "         3.6657,  3.5652,  3.2327,  3.1224,  3.3068,  3.0599,  3.1539,  3.2379,\n",
              "         3.3183,  3.3682,  3.2676,  3.4098,  3.8077,  3.6387,  3.7528,  3.8877,\n",
              "         4.2399,  4.2130,  3.7059,  3.3967,  3.4823,  3.6857,  4.3476,  4.2720,\n",
              "         4.5019,  4.7881,  4.7068,  4.7690,  5.2762,  4.9082,  4.7801],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtO_C9CTSkM-"
      },
      "source": [
        "This is a way to generate the initial params from pytorch distribution directly without truncation.\n",
        "NOTE: Use either this code block below or above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcKQh9lISjqA"
      },
      "source": [
        "dist_tau_t = distributions.exponential.Exponential(torch.tensor([1/0.03], device=device))\n",
        "#tau_t = dist_tau_t.sample()\n",
        "\n",
        "dist_y = distributions.exponential.Exponential(tau)\n",
        "#y = dist_y.sample()\n",
        "\n",
        "dist_phi = distributions.normal.Normal(loc=torch.tensor([25], device=device), scale=torch.tensor([10], device=device))\n",
        "#phi = dist_phi.sample()\n",
        "\n",
        "dist_R0 = distributions.normal.Normal(loc=torch.tensor([3.6], device=device), scale=torch.tensor([0.8], device=device))\n",
        "#R0 = dist_R0.sample()\n",
        "\n",
        "dist_alpha = distributions.normal.Normal(loc=torch.tensor([0.01], device=device), scale=torch.tensor([0.01], device=device))\n",
        "#alpha = dist_alpha.sample()\n",
        "\n",
        "dist_sigma = distributions.normal.Normal(loc=torch.tensor([0.1], device=device), scale=torch.tensor([0.3], device=device))\n",
        "#sigma = dist_sigma.sample()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fI1Yjma8CL8"
      },
      "source": [
        "# Define Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CF2bx-79_eo"
      },
      "source": [
        "def calc_prior_loss(tau, phi, R0, alpha, sigma):\n",
        "  # log likelihood wrt. our prior (\"regularisation\")\n",
        "  # ll stands for log-likelihood\n",
        "  ll = torch.tensor(0.0, device=device)\n",
        "\n",
        "  #dist_tau_t = distributions.exponential.Exponential(torch.tensor([1/0.03]))\n",
        "  #ll += dist_tau_t.log_prob(tau).item()\n",
        "\n",
        "  #dist_y = distributions.exponential.Exponential(tau) #the parameter in the brasket should either be float or tensor, to avoid any inconvienience,\n",
        "                                                      # I use everything as tensor. NOTE:tau_t is already a tensor.\n",
        "  #ll += dist_y.log_prob(y).item()\n",
        "\n",
        "  #dist_phi = distribution.normal.Normal(loc=torch.tensor([25]), scale=torch.tensor([10]))\n",
        "  ll += dist_phi.log_prob(phi).item()\n",
        "\n",
        "  #dist_R0 = distribution.normal.Normal(loc=torch.tensor([3.6]), scale=torch.tensor([0.8]))\n",
        "  ll += dist_R0.log_prob(R0).item()\n",
        "\n",
        "  #dist_alpha = distribution.normal.Normal(loc=torch.tensor([0.01]), scale=torch.tensor([0.01]))\n",
        "  ll += dist_alpha.log_prob(alpha).item()\n",
        "\n",
        "  #dist_sigma = distribution.normal.Normal(loc=torch.tensor([0.1]), scale=torch.tensor([0.3]))\n",
        "  ll += dist_sigma.log_prob(sigma).item()\n",
        "\n",
        "  return ll"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt27Ab2l9_hC"
      },
      "source": [
        "def seed_init_infect(y):\n",
        "  # Initialize newly_infected, cumulative_infected, St\n",
        "  newly_infected = torch.zeros(num_observations, device=device, dtype=dtype)  # number of newly infected\n",
        "  cumulative_infected = torch.zeros(num_observations, device=device)  # cumulative number of infected\n",
        "  \n",
        "  St = torch.zeros(num_observations, device=device)  # fraction of susceptible population\n",
        "  # seed initial infection / impute first num_impute days\n",
        "  newly_infected[0:num_impute] = y.clone()\n",
        "  cumulative_infected[0] = 0.\n",
        "  cumulative_infected[1:num_impute] = torch.cumsum(newly_infected[0:num_impute - 1].clone(), dim=0)\n",
        "  St[0:num_impute] = torch.tensor([torch.maximum(population.clone() - x, torch.tensor(0)) / population for x in cumulative_infected[0:num_impute].clone()])\n",
        "  return newly_infected, cumulative_infected, St"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf9tMHun9_j0"
      },
      "source": [
        "def calc_Rt(R0, epsilon_t, sigma, ll):\n",
        "  # Initialize eta_t\n",
        "  eta_t = torch.zeros(num_observations, device=device)  # transformed reproduction number\n",
        "\n",
        "  # calculate Rt: the basic reproduction number\n",
        "  # basic reproduction number as a latent random walk\n",
        "  beta_0 = torch.log(R0)\n",
        "  eta_t[0] = beta_0\n",
        "  for t in range(1, num_observations):\n",
        "      dist_epsilon_t = torch.distributions.Normal(epsilon_t[t - 1], sigma)\n",
        "      ll += dist_epsilon_t.log_prob(epsilon_t[t - 1])\n",
        "  eta_t[1:num_observations] = beta_0 + epsilon_t[0:num_observations-1].clone()\n",
        "  Rt = torch.exp(eta_t)\n",
        "  return Rt, ll"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcM7ArwKRp60"
      },
      "source": [
        "def calc_infections(cumulative_infected, newly_infected, St, Rt):\n",
        "  # Initialize effectively_infectious\n",
        "  effectively_infectious = torch.zeros(num_observations, device=device)  # effective number of infectious individuals\n",
        "  \n",
        "  # calculate infections\n",
        "  for t in range(num_impute, num_observations):\n",
        "      # Update cumulative newly_infected\n",
        "      cumulative_infected[t] = cumulative_infected[t - 1].clone() + newly_infected[t - 1].clone()\n",
        "      # Adjusts for portion of pop that are susceptible\n",
        "      St[t] = torch.maximum(population.clone() - cumulative_infected[t].clone(), cero) / population.clone()\n",
        "      # effective number of infectous individuals\n",
        "      ni_temp = newly_infected[:t].view(1, 1, -1).clone()\n",
        "      si_temp = torch.flip(serial_interval, (0,))[-t:].view(1, 1, -1)\n",
        "      effectively_infectious[t] = torch.nn.functional.conv1d(ni_temp, si_temp)\n",
        "      \n",
        "      newly_infected[t] = St[t].clone() * Rt[t].clone() * effectively_infectious[t].clone()\n",
        "  return newly_infected"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrSVBFldAD-l"
      },
      "source": [
        "def calc_hospit(newly_infected, alpha):\n",
        "  # Initialize expected_daily_hospit\n",
        "  expected_daily_hospit = torch.zeros(num_observations, device=device)  # expected number of daily hospitalizations\n",
        "\n",
        "  # calculate expected number of hospitalizations\n",
        "  expected_daily_hospit[0] = (1e-15) * newly_infected[0].clone()\n",
        "  for t in range(1, num_observations):\n",
        "      ni_temp = newly_infected[:t].view(1, 1, -1)\n",
        "      pi_temp = torch.flip(pi, (0,))[-t-1:-1].view(1, 1, -1)\n",
        "      expected_daily_hospit[t] = torch.nn.functional.conv1d(ni_temp, pi_temp)\n",
        "  expected_daily_hospit = alpha * expected_daily_hospit\n",
        "  return expected_daily_hospit"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvgAHKIXAEBU"
      },
      "source": [
        "def compare_results(expected_daily_hospit, phi, ll):\n",
        "  # compare observed hospitalizations to model results\n",
        "  # likelihood of the data wrt. to the model\n",
        "\n",
        "  for i in range(0, num_observations):\n",
        "      p = 1/(1+ expected_daily_hospit[i]/phi)\n",
        "      dist = torch.distributions.negative_binomial.NegativeBinomial(phi, p-torch.tensor(2.225e-5))\n",
        "      ll += dist.log_prob(observed_daily_hospit[i])\n",
        "  return ll"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZMf1XWoAtSt"
      },
      "source": [
        "def forward_pass():\n",
        "  # Initialize y\n",
        "  y = trunc_exponential(tau, 1000)\n",
        "\n",
        "  # Calculate prior loss\n",
        "  ll = calc_prior_loss(tau, phi, R0, alpha, sigma)\n",
        "  \n",
        "  # Seed initial infections\n",
        "  newly_infected, cumulative_infected, St = seed_init_infect(y)\n",
        "  \n",
        "  # Calculate Rt & random walk loss \n",
        "  Rt, ll = calc_Rt(R0, epsilon_t, sigma, ll)\n",
        "  \n",
        "  # Calculate infections\n",
        "  newly_infected = calc_infections(cumulative_infected, newly_infected, St, Rt)\n",
        "  \n",
        "  # Calculate expected hospitalizations\n",
        "  expected_daily_hospit = calc_hospit(newly_infected, alpha)\n",
        "  \n",
        "  # Compare observed hospitalizations to model results\n",
        "  ll = compare_results(expected_daily_hospit, phi, ll)\n",
        "  return expected_daily_hospit, Rt, ll"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg2pWcC384K0"
      },
      "source": [
        "# Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BBZ3KIq1PTqk",
        "outputId": "27b71961-3941-454d-ed10-315de9853e07"
      },
      "source": [
        "learning_rate = 1e-12\n",
        "epochs = 100\n",
        "complete_time = time.time()\n",
        "\n",
        "for k in range (epochs):\n",
        "    start_time = time.time()\n",
        "    decay = (1 - (k / (epochs*1e5))) ** 2\n",
        "    learning_rate = learning_rate * decay\n",
        "\n",
        "    # forward pass - calculate expected_daily_hospit\n",
        "    expected_daily_hospit, Rt, ll = forward_pass()\n",
        "\n",
        "    #backward pass\n",
        "    loss = -ll\n",
        "    loss.backward()\n",
        "\n",
        "    if k%5 == 0:\n",
        "      print(f'Time Step: {k}|| Loss: {loss},  R0:{R0}, grad: {R0.grad}, alpha: {alpha} grad: {alpha.grad}, phi: {phi} grad: {phi.grad}, sigma: {sigma} grad {sigma.grad}, epsilon_t.mean: {epsilon_t.mean()} grad.mean {epsilon_t.grad.mean()}')\n",
        "      print(\"This Run:  %s seconds\" % (time.time() - start_time))\n",
        "    with torch.no_grad(): # this part is SGD. can also replace with loss.step\n",
        "        tau -= learning_rate * tau.grad\n",
        "        phi -= learning_rate * phi.grad \n",
        "        R0 -= learning_rate * R0.grad \n",
        "        alpha -= learning_rate * alpha.grad \n",
        "        sigma -= learning_rate * sigma.grad \n",
        "        epsilon_t -= learning_rate * epsilon_t.grad * 1e+8\n",
        "\n",
        "        tau.grad = None\n",
        "        phi.grad = None\n",
        "        R0.grad = None\n",
        "        alpha.grad = None\n",
        "        sigma.grad = None\n",
        "        epsilon_t.grad = None\n",
        "\n",
        "    \n",
        "    if k%100 == 0:    \n",
        "      plt.plot(expected_daily_hospit.cpu().detach().numpy(), label='expected_daily_hospit')\n",
        "      plt.plot(observed_daily_hospit.cpu().detach().numpy(), label='observed_daily_hospit')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "print(\"Complete Run:  %s seconds\" % (time.time() - complete_time))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Step: 0|| Loss: 81751.6328125,  R0:2.2797217757676145, grad: 4246.046080635508, alpha: 0.009999857608264206 grad: -135924.25, phi: 26.848677011157655 grad: 3002.17118234304, sigma: 0.2921200161058668 grad 1389.8397152383375, epsilon_t.mean: -0.37735244631767273 grad.mean 23.783302307128906\n",
            "This Run:  0.5515344142913818 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dnw8d+VyWQjCWGJgICCPBRZRJRNX7AiVsClKm5obbUuj62vWPvYpxXbqli1tYpatWprFcXWBevSUl6souKCVfaIGGQXBMIO2ZdZrvePcyZMQpZJMklmMtf388knM/c5c+aak8k191znPvcRVcUYY0xiSGrvAIwxxrQdS/rGGJNALOkbY0wCsaRvjDEJxJK+McYkkOT2DqAh3bt31379+rV3GMYYE1dWrFixT1Vz61oW00m/X79+LF++vL3DMMaYuCIiW+tbZuUdY4xJIJb0jTEmgVjSN8aYBBLTNf26+Hw+tm/fTkVFRXuHYuJYWloaffr0wev1tncoxrSpuEv627dvJysri379+iEi7R2OiUOqyv79+9m+fTv9+/dv73CMaVNxV96pqKigW7dulvBNs4kI3bp1s2+LJiHFXdIHLOGbFrP3kElUcZn0jTGmPnuLK/nHqh3YtPF1i7uavjHGNOSOf6zh31/uYmCPTIYe3bm9w4k51tOPE3l5eSxYsKDJj5swYULEZzU///zzTJ8+vcF15s2bx/333w/AzJkzmTVrVpNj6tevH/v27Wvy4yJ1zjnncOjQIQ4dOsSTTz7Zas9jYtOeYudYzVtf7GrnSGKTJf040dykH23nn38+M2bMaO8wGrRgwQJycnIs6SeoPcWVAHywfk87RxKb4rq8c/e/viR/Z1FUtznk6Gzu+u7QRtf729/+xmOPPUZVVRVjx47l2muv5b//+79ZunQpgUCAMWPGMHfuXPbt28edd95JVlYWGzdu5IwzzuDJJ58kKSmJd955h7vuuovKykoGDBjAc889R2ZmJsuWLeOWW26htLSU1NRUFi5cyJ133kl5eTmLFy/m9ttv57zzzuPmm29mzZo1+Hw+Zs6cyQUXXEB5eTnXXHMNn3/+Occffzzl5eUNvo7nnnuO3/3ud+Tk5HDiiSeSmpoKwL/+9S/uvfdeqqqq6NatGy+++CI9evTg+eefZ/ny5fzxj3+s3samTZu49NJLWblyJQAbNmxg2rRp1ffr8vjjj/Ovf/0Ln8/H3//+d44//ngOHDjAtddey+bNm8nIyODpp59m+PDhfPjhh9xyyy2AcwD2o48+YsWKFfXu19CcTTNmzGDTpk2MGDGCs846iwcffLDRv6uJb0UVPrYfdN7zOw/Z6Ky6WE+/GdauXcvcuXP55JNPyMvLw+PxsG7dOs4//3x+/etf84tf/ILvf//7DBs2DIClS5fy+OOPk5+fz6ZNm3jjjTfYt28f9957L++++y4rV65k1KhRPPzww1RVVTFt2jQeffRRPv/8c9599106derEb37zG6ZNm0ZeXh7Tpk3jvvvuY+LEiSxdupRFixbx85//nNLSUp566ikyMjJYu3Ytd999NytWrKj3dRQUFHDXXXfxySefsHjxYvLz86uXjR8/ns8++4xVq1Zx+eWX88ADD9S7nQEDBtC5c2fy8vIA54PkmmuuaXAfdu/enZUrV3LjjTdWl4juuusuTjrpJFavXs1vf/tbrrrqKgBmzZrFE088QV5eHh9//DHp6en17tdw999/PwMGDCAvL88SfoL4el8pACf07syB0ioqfIF2jij2xHVPP5IeeWt47733WLFiBaNHjwagvLyco446ijvvvJPRo0eTlpbGY489Vr3+mDFjOO644wC44oorWLx4MWlpaeTn5zNu3DgAqqqqOPXUU1m3bh29evWq3nZ2dnadMbzzzjvMmzevOmFWVFSwbds2PvroI37yk58AMHz4cIYPH17v61iyZAkTJkwgN9eZgXXatGmsX78ecE6CmzZtGgUFBVRVVTV6EtP111/Pc889x8MPP8zcuXNZunRpg+tfdNFFAIwcObI6WS9evJjXX38dgIkTJ7J//36KiooYN24ct956K1deeSUXXXQRffr0Aerer5dcckmDz2s6tsJyHwBDemXzxY5CdhdVcGy3Tu0cVWyJ66TfXlSVq6++mt/97nc12gsKCigpKcHn81FRUUGnTs6brfaYcBFBVTnrrLN4+eWXayz74osvIo7h9ddfZ9CgQS14JfW7+eabufXWWzn//PP54IMPmDlzZoPrX3zxxdx9991MnDiRkSNH0q1btwbXD5WRPB4Pfr+/wXVnzJjBueeey4IFCxg3bhxvv/02UPd+NYmtqNx5Lw3skQnArkJL+rVZeacZzjzzTF577TX27HEOFB04cICtW7fyox/9iHvuuYcrr7yS2267rXr9pUuXsmXLFoLBIHPnzmX8+PGccsopfPLJJ2zcuBGA0tJS1q9fz6BBgygoKGDZsmUAFBcX4/f7ycrKori4uHqbkydP5vHHH68ei7xq1SoAvv3tb/PSSy8BsGbNGlavXl3v6xg7diwffvgh+/fvr66thxQWFtK7d28A5syZ0+g+SUtLY/Lkydx4442Nlnbqc9ppp/Hiiy8C8MEHH9C9e3eys7PZtGkTJ5xwArfddhujR4/mq6++Aurer+Fq7zPT8RVVOD39b/XIAmBXkdX1a7Ok3wxDhgzh3nvvZdKkSQwfPpyzzjqLOXPm4PV6+d73vseMGTNYtmwZ77//PgCjR49m+vTpDB48mP79+zN16lRyc3N5/vnnueKKKxg+fDinnnoqX331FSkpKcydO5ebb76ZE088kbPOOouKigrOOOMM8vPzGTFiBHPnzuWOO+7A5/MxfPhwhg4dyh133AHAjTfeSElJCYMHD+bOO+9k5MiR9b6OXr16MXPmTE499VTGjRvH4MGDq5fNnDmTSy+9lJEjR9K9e/eI9suVV15JUlISkyZNatZ+nTlzJitWrGD48OHMmDGj+sPmD3/4A8OGDWP48OF4vV7OPvvsevdruG7dujFu3DiGDRvGz3/+82bFZOJLkVveGdTTSfoFhZb0j6CqMfszcuRIrS0/P/+Itli2aNEiPffcc9s7jDbx4IMP6q9//es2ea5o7Nd4ey+Zxj3476+0/4z5GgwGdcgdb+nMeWvaO6R2ASzXevKq1fRNVEydOpVNmzZVf7sxpj0UVfjITvciInTplMKhMl97hxRzLOm3sgkTJjBhwoT2DoOxY8dSWVlZo+2vf/0rJ5xwQlS2/+abbx7RNnXqVLZs2VKj7fe//z2TJ09u8fPFyn41saWo3EdWmpPWcjK8HCyraueIYk+jSV9E0oCPgFR3/ddU9S4ReR44HSh0V/2hquaJM4TiUeAcoMxtX+lu62rg1+7696pq40cITVQsWbKkzZ+zrg8CY1pTUYWf7DTnwjhdMlI4aD39I0TS068EJqpqiYh4gcUi8pa77Oeq+lqt9c8GBro/Y4GngLEi0hW4CxgFKLBCROap6sFovBBjjCmu8FUn/ZyMFL45UNbOEcWeRkfvuMcFSty7XvenoTlLLwBecB/3GZAjIr2AycBCVT3gJvqFwJSWhW+MMYcVlfvJTnf6sl0yvNbTr0NEQzZFxCMiecAenMQdqhXcJyKrReQREUl123oD34Q9fLvbVl977ee6QUSWi8jyvXv3NvHlGGMSWVGFj6ywnn5RhY9A0ObVDxdR0lfVgKqOAPoAY0RkGHA7cDwwGugK3NbAJiKmqk+r6ihVHRWaHsAYYyJRXOGvPpDbJcOL6uGpGYyjSSdnqeohYBEwRVUL3BJOJfAcMMZdbQfQN+xhfdy2+to7hK+//rp6grVYYvPp29TKiaTcFyDd6wGcA7mAjeCppdGkLyK5IpLj3k4HzgK+cuv0uKN1LgTWuA+ZB1wljlOAQlUtAN4GJolIFxHpAkxy20w9GpuTpj3YfPomVvkCQQJBJc1N+jkZTpnnkCX9GiIZvdMLmCMiHpwPiVdVdb6IvC8iuYAAecCP3fUX4AzX3IgzZPMaAFU9ICL3AMvc9X6jqgdaFP1bM2BXZBOURaznCXD2/Y2u9vDDDzN79mzAmWHywgsvxO/3c+WVV7Jy5UqGDh3KCy+8QEZGBjNmzGDevHkkJyczadIkZs2axd69e/nxj3/Mtm3bAGeqgXHjxjFz5kw2bdrE5s2bOeaYY9iyZQvPPvssQ4c6M4pOmDCBWbNmMXjwYJtP3+bTN2FC0yineZ2+bHVPv9TKO+EaTfqquho4qY72ifWsr8BN9SybDcxuYowxZ8WKFTz33HMsWbIEVWXs2LGcfvrprFu3jmeffZZx48Zx7bXX8uSTT3LNNdfw5ptv8tVXXyEiHDp0CIBbbrmF//mf/2H8+PFs27aNyZMns3btWgDy8/NZvHgx6enpPPLII7z66qvcfffdFBQUUFBQwKhRo/jlL3/JxIkTmT17NocOHWLMmDF85zvf4c9//nP1fPqrV6/m5JNPrvd1hObTX7FiBZ07d+aMM87gpJOcP3VoPn0R4ZlnnuGBBx7goYceqnM74fPpjxgxoknz6T/55JPMmjWLZ555pno+/X/84x+8//77XHXVVeTl5VXPpz9u3DhKSkpIS0sDnAnX8vPzOfbYY5kyZQpvvPFGjamV77//ftasWVM9z7/p2Cr9QYDqnn6otl9caUk/XHyfkRtBj7w1LF68mKlTp1ZPnXzRRRfx8ccf07dv3+r58b///e/z2GOP8dOf/pS0tDSuu+46zjvvPM477zwA3n333RoXLSkqKqKkxBkZe/7551dfKOSyyy5j0qRJ3H333bz66qvVSc3m07f59E1N1T395FDSd8o7xRWxVyZtTzbLZhTVNb97cnIyS5cu5ZJLLmH+/PlMmeKcmhAMBvnss8/Iy8sjLy+PHTt2kJnpzAEe+jAB6N27N926dWP16tXMnTuXadOmAYfn0w89ftu2bTVmyWypm2++menTp/PFF1/w5z//mYqKhmcrvPjii3nrrbeYP39+q8yn/8wzz1BeXs64ceOqp1a2+fRNuAqf09NPdcs71T19S/o1WNJvhtNOO41//OMflJWVUVpayptvvslpp53Gtm3b+PTTTwF46aWXGD9+PCUlJRQWFnLOOefwyCOP8PnnnwMwadIkHn/88eptNlSCmDZtGg888ACFhYXVPXebT9/m0zc1Ha7pe6p/p3iSqufYNw5L+s1w8skn88Mf/pAxY8YwduxYrr/+erp06cKgQYN44oknGDx4MAcPHuTGG2+kuLiY8847j+HDhzN+/HgefvhhAB577DGWL1/O8OHDGTJkCH/605/qfb5LLrmEV155hcsuu6y6zebTt/n0TU2VfifppyYfTmtZacmUWE+/Bgn1FGPRqFGjtPYY87Vr10a1jGGiZ9asWRQWFnLPPfe0+nN98MEHzJo1i/nz5zd7G/Ze6lg+2biPK59Zwis3nMIpxznlxQkPLmJ4nxweu+KIsSgdmoisUNVRdS2L7wO5JmbYfPqmvdUu74BzMLfYyjs1WNJPEDafvunoDg/ZrFnesQO5NcVl0ldVG6nRRDaffk2xXNY0zVN7yCY4Sf/rfTa9cri4O5CblpbG/v377Z/WNJuqsn///uqTvEzHEBqyaeWdhsVdT79Pnz5s374dm3bZtERaWlr1SV6mY6g9DQNYeacucZf0vV5vo2eHGmMST4W/7gO5JVV+gkElKclKwhCH5R1jjKlLqLyT4jmc1rLTklGFkirr7YdY0jfGdAiVvgApyUk1evQ2FcORLOkbYzqESn+QtOSaKe3wpGt2MDfEkr4xpkOo8AVq1PPBevp1saRvjOkQ6k761tOvzZK+MaZDqPAFawzXBOvp1yWSa+SmichSEflcRL4Ukbvd9v4iskRENorIXBFJcdtT3fsb3eX9wrZ1u9u+TkRafi6+Mca4Kv3OgdxwoaRfZEm/WiQ9/UpgoqqeCIwAprgXPP898Iiq/hdwELjOXf864KDb/oi7HiIyBLgcGApMAZ50r7trjDEt5g8qyUk1U1q2lXeO0GjSV0eJe9fr/igwEXjNbZ8DXOjevsC9j7v8THEmyrkAeEVVK1V1C86F08dE5VUYYxKeP6B4PTVPwEpNTsLrESvvhImopi8iHhHJA/YAC4FNwCFVDe3J7UBv93Zv4BsAd3kh0C28vY7HhD/XDSKyXESW21QLxphI+YPBI3r6ImLz79QSUdJX1YCqjgD64PTOj2+tgFT1aVUdpaqjQhfsNsaYxvgCSrLnyKkWbP6dmpo0ekdVDwGLgFOBHBEJzd3TB9jh3t4B9AVwl3cG9oe31/EYY4xpEX8wiNdzZEqzpF9TJKN3ckUkx72dDpwFrMVJ/pe4q10N/NO9Pc+9j7v8fXXmQZ4HXO6O7ukPDASWRuuFGGMSmz+gJNcxqVpWqpV3wkUyy2YvYI470iYJeFVV54tIPvCKiNwLrAKeddd/FviriGwEDuCM2EFVvxSRV4F8wA/cpKqB6L4cY0yi8gXq7+lvO2AXUglpNOmr6mrgiKsKq+pm6hh9o6oVwKX1bOs+4L6mh2mMMQ3zB+uu6WdaeacGOyPXGNMh+AOKp47yTraN3qnBkr4xpkPwB4N4k45MaZmpyZRU+u0Sqy5L+saYDsHfwJDNoEK5zw4hgiV9Y0wHUd+B3EybdK0GS/rGmA7BmXunrp5+aP4dS/pgSd8Y00E45Z06hmymhnr6djAXLOkbYzoIXzB4xIRrcLi8U1JpPX2wpG+M6QACQUWVIyZcA7uQSm2W9I0xcc8XCALUfXKWW94psaQPWNI3xnQA/qAzBr+hA7lFVtMHLOkbYzqAQMBN+nUN2Uy1mn44S/rGmLjnCzrlnboO5HqShE4pHqvpuyzpG2Pinj/U06/jQC44I3ispu+wpG+MiXsNHcgFp8RTXGk1fbCkb4zpAEIHcusq7wDudXKtpw+W9I0xHYA/1NOvp7yTlZZsB3JdlvSNMXHPF2isp28XUgmJ5Bq5fUVkkYjki8iXInKL2z5TRHaISJ77c07YY24XkY0isk5EJoe1T3HbNorIjNZ5ScaYROMPNtzTz0y1A7khkVwj1w/8TFVXikgWsEJEFrrLHlHVWeEri8gQnOviDgWOBt4VkW+5i5/AubD6dmCZiMxT1fxovBBjTOIK1fQ9Ddb07UAuRHaN3AKgwL1dLCJrgd4NPOQC4BVVrQS2uBdID11Ld6N7bV1E5BV3XUv6xpgWCQ3ZrOvKWeD09EurAgSCdV9SMZE0qaYvIv1wLpK+xG2aLiKrRWS2iHRx23oD34Q9bLvbVl977ee4QUSWi8jyvXv3NiU8Y0yC8jcyZDPLZtqsFnHSF5FM4HXgp6paBDwFDABG4HwTeCgaAanq06o6SlVH5ebmRmOTxpgOztfokE1L+iGR1PQRES9Own9RVd8AUNXdYcv/Asx37+4A+oY9vI/bRgPtxhjTbI0N2cxMDV09ywekt1VYMSmS0TsCPAusVdWHw9p7ha02FVjj3p4HXC4iqSLSHxgILAWWAQNFpL+IpOAc7J0XnZdhjElkvuoJ1xrp6dsInoh6+uOAHwBfiEie2/ZL4AoRGQEo8DXwIwBV/VJEXsU5QOsHblLVAICITAfeBjzAbFX9MoqvxRiToPzVE67VP/cO2IVUILLRO4uBuj4+FzTwmPuA++poX9DQ44wxpjkOT7hWd08/O5T0raZvZ+QaY+KfL8KavpV3LOkbYzqAQDCymr6doGVJ3xjTAfgaSfoZKR5EbMgmWNI3xnQAoSGb9Z2RKyLOnPpW3rGkb4yJf/5GhmwCZNuc+oAlfWNMB+BrZMgmuFfPspq+JX1jTPxrbMgm2IVUQizpG2PiXqim39AMmpl2IRXAkr4xpgPwBRWvR3BmjalbVprXevpY0jfGdAD+QLDRefKtpu+wpG+MiXv+oNY7XDMk28o7gCV9Y0wH4A9og8M1wenpV/qDVPmDbRRVbLKkb4yJe/5gkOQGhmvC4Zk2E72ub0nfGBP3fAHF20hNPyvNJl0DS/rGmA7AH4igp5/q9PSLEvxgriV9Y0zc8wUbr+lnW3kHsKRvjOkA/IFgo6N37OpZjkiukdtXRBaJSL6IfCkit7jtXUVkoYhscH93cdtFRB4TkY0islpETg7b1tXu+htE5OrWe1nGmEQSyeid6pp+pZV3GuMHfqaqQ4BTgJtEZAgwA3hPVQcC77n3Ac7GuRj6QOAG4ClwPiSAu4CxwBjgrtAHhTHGtIQ/qA3OuwOHa/rW02+Eqhao6kr3djGwFugNXADMcVebA1zo3r4AeEEdnwE5ItILmAwsVNUDqnoQWAhMieqrMcYkpEiGbGZZeQdoYk1fRPoBJwFLgB6qWuAu2gX0cG/3Br4Je9h2t62+9trPcYOILBeR5Xv37m1KeMaYBOULNN7TT01OwusRS/qRrigimcDrwE9VtSh8maoqoNEISFWfVtVRqjoqNzc3Gps0xnRw/kCwwbn04fDVs6ymHwER8eIk/BdV9Q23ebdbtsH9vcdt3wH0DXt4H7etvnZjjGkRfwRDNsE5mGs9/UaIM1fps8BaVX04bNE8IDQC52rgn2HtV7mjeE4BCt0y0NvAJBHp4h7AneS2GWNMizjlncb7sJmpyQl/Rm5yBOuMA34AfCEieW7bL4H7gVdF5DpgK3CZu2wBcA6wESgDrgFQ1QMicg+wzF3vN6p6ICqvwhiT0JzyTiQ9/WSKE/zkrEaTvqouBurbm2fWsb4CN9WzrdnA7KYEaIwxjXHKO4339LPSvGw/WNYGEcUuOyPXGBP3fIFgoxOuAXRO91JUbgdyjTEmrgWC2uiVs8BJ+oWW9I0xJr75ApGVdzqneymtCuALJO6FVCzpG2Pinj8Y2YHczunOYcxE7u1b0jfGxD1/hEM2czJSAEv6xhgT13wRDtnsnO7MtGlJ3xhj4likZ+RmW9K3pG+MiW+qSiAYaXnHTfpllvSNMSYu+QLOXI9W3omMJX1jTFzzB53hl54IevqW9C3pG2PinD8YeU/f60kiI8VjSd8YY+KV3y3vNHYRlZCcdC+HrKZvjDHxye+eXRvJGbngjOCxnr4xxsQpXxPKO2CTrlnSN8bEteqefgQHcsEmXbOkb4yJa6Ehm5GcnAXOWP1D5VWtGVJMs6RvjIlroSGbjV0YPcR6+o0QkdkiskdE1oS1zRSRHSKS5/6cE7bsdhHZKCLrRGRyWPsUt22jiMyI/ksxxiSi0OidSObTByfpV/iCVPoDrRlWzIrko/F5YEod7Y+o6gj3ZwGAiAwBLgeGuo95UkQ8IuIBngDOBoYAV7jrGmNMi4Tmxk9JjrCnn+AzbTa6l1T1IyDSC5hfALyiqpWqugXn4uhj3J+NqrpZVauAV9x1jTGmRar8btJvQnkHEnf+nZbU9KeLyGq3/NPFbesNfBO2zna3rb72I4jIDSKyXESW7927twXhGWMSQehAbsQ9/QSfiqG5Sf8pYAAwAigAHopWQKr6tKqOUtVRubm50dqsMaaDqgo4tflID+TmuEk/Uc/KTW7Og1R1d+i2iPwFmO/e3QH0DVu1j9tGA+3GGNNsVf6mnZzVtZNT0z9QlpjDNpvV0xeRXmF3pwKhkT3zgMtFJFVE+gMDgaXAMmCgiPQXkRScg73zmh+2McY4qtwDuakRlneqk35pYib9Rnv6IvIyMAHoLiLbgbuACSIyAlDga+BHAKr6pYi8CuQDfuAmVQ2425kOvA14gNmq+mXUX40xJuH4/E0bp5+R4iE1OcmSfn1U9Yo6mp9tYP37gPvqaF8ALGhSdMYY04imDtkUEbp1SmF/SWImfTsj1xgT10LlnUh7+gBdM1M4UFrZWiHFNEv6xpi4Vj1OP8KePkDXTqkJW96xpG+MiWuhnn6kJ2cBdM3wst+SvjHGxB9f9ZBN6+lHwpK+MSauVQUCeJIk4gnXALplplBWFaDCl3iTrlnSN8bENV9AIz4xKyQ0Vj8RSzyW9I0xca3KH2xSPR/CTtBKwGGblvSNMXGtKhBs0sgdgG7VPf3EG7ZpSd8YE9d8LenpW3nHGGPiS1UgiLfJPf1UwJK+McbEHV8g2KThmgDZ6ckkJ4kdyDXGmHjTnAO5IkKXTil2INcYY+JNVUCbXN4B52Cu9fSNMSbO+PxBUpvY0wfnYG4iTrpmSd8YE9ecA7lNOzkLIDcrlb0llvSNMSau+AJNr+kD9MhOY3dRJaraClHFLkv6xpi4VuVv+ugdcJJ+lT9IYXliXSC90T0lIrNFZI+IrAlr6yoiC0Vkg/u7i9suIvKYiGwUkdUicnLYY652198gIle3zssxxiSa5pyRC9Aj2xmrv6uoItohxbRI9tTzwJRabTOA91R1IPCeex/gbJyLoQ8EbgCeAudDAufaumOBMcBdoQ8KY4xpieYM2QSnpw+wuyix6vqN7ilV/Qg4UKv5AmCOe3sOcGFY+wvq+AzIEZFewGRgoaoeUNWDwEKO/CAxxpgma87JWQA9q5O+9fQj0UNVC9zbu4Ae7u3ewDdh62132+prN8aYFqnyN6+8k5vllHf2WNJvGnUOfUft8LeI3CAiy0Vk+d69e6O1WWNMB+XMp9/0VJbm9ZCT4bWafoR2u2Ub3N973PYdQN+w9fq4bfW1H0FVn1bVUao6Kjc3t5nhGWMSRaU/QKq3eamspztsM5E0N+nPA0IjcK4G/hnWfpU7iucUoNAtA70NTBKRLu4B3ElumzHGNFsgqPgCSlqyp1mPPyo7LeHKO8mNrSAiLwMTgO4ish1nFM79wKsich2wFbjMXX0BcA6wESgDrgFQ1QMicg+wzF3vN6pa++CwMcY0SZU/CNDsnn6PrFTW7yqOZkgxr9Gkr6pX1LPozDrWVeCmerYzG5jdpOiMMaYBoQubpzbjQC5Az85p7C2pJBDUJl1YPZ7ZGbnGmLhVGerpt6C8Ewgq+xNoDh5L+saYuFXpd3r6aS0o70BinaBlSd8YE7cqfC3r6ffs7JygVVBYHrWYYp0lfWNM3Ar19Jtb0+/bJQOAbw5a0jfGmJhX2cLROzkZXjJTk/nmQFk0w4pplvSNMXGr0i3vpHmbV94REfp2zbCkb4wx8aClQzYBjumazjZL+sYYE/taOmQTnLr+tiXTrdEAABRZSURBVANlCXMFLUv6xpi41dIDuQDHdMug0h9kb3FiDNu0pG+MiVuhnn5za/oAfbuGRvAkRonHkr4xJm5Fo6YfGraZKHV9S/rGmLjV0iGbAH26pAOwbX9ijNW3pG+MiVuVLTwjF5zSUM/sNOvpG2NMrKv0B/B6pMUzZB6TQGP1LekbY+JWhS/Yol5+yHG5ndiwpzghhm1a0jfGxK1Kf6BFB3FDvtUji4NlPvaVVEUhqthmSd8YE7cq/cGoJP1BPbMAWL+7419Fy5K+MSZuVfgCLRqjHxJK+usS4NKJLUr6IvK1iHwhInkistxt6yoiC0Vkg/u7i9suIvKYiGwUkdUicnI0XoAxJnFV+oOkRKGn3z0zlW6dUizpR+gMVR2hqqPc+zOA91R1IPCeex/gbGCg+3MD8FQUntsYk8DKqwJkpLS8pw9OXX+dlXea5QJgjnt7DnBhWPsL6vgMyBGRXq3w/MaYBFFa5adTanJUtjWoZxYbdhcTDHbsETwtTfoKvCMiK0TkBreth6oWuLd3AT3c272Bb8Ieu91tq0FEbhCR5SKyfO/evS0MzxjTkZVW+umUEr2kX1oVYMehjn1mbkuT/nhVPRmndHOTiHw7fKE6g16b9LGpqk+r6ihVHZWbm9vC8IwxHVlpZYCM1OiUd0IHc/MLiqKyvVjVoqSvqjvc33uAN4ExwO5Q2cb9vcddfQfQN+zhfdw2Y4xpltIqP5lRKu8M6ZWN1yOs3HYwKtuLVc1O+iLSSUSyQreBScAaYB5wtbva1cA/3dvzgKvcUTynAIVhZSBjjGmyssoAGVEq76R5PQzr3ZmVWzt20m/J3uoBvCkioe28pKr/FpFlwKsich2wFbjMXX8BcA6wESgDrmnBcxtjElyVP0hVIEhmlMo7AKOO7cKcT7e6Z/pGb7uxpNlJX1U3AyfW0b4fOLOOdgVuau7zGWNMuLIqP0DUevoAI4/twl8+3sKaHUWMPLZL1LYbS+yMXGNMXCqpdJJ+tGr6ACOP7QrQoUs8lvSNMXGprMq5ala0Ru8A5Galcmy3DJZvPRC1bcYaS/rGmLgU6ulH6+SskLH9u/KfTfvxBYJR3W6ssKRvjIlLZZVOTz9aJ2eFfGdwD4or/CzZ3DF7+5b0jTFx6XBPP7qjbE4bmEuaN4l38ndFdbuxwpK+MSYuhUbvRLunn57iYfx/5fJu/u4OeSUtS/rGmLhU2ko1fYBJQ3qws7CCNTs63pQMlvSNMXHpUJkPgKy0Vkj6Q3uQmpzEK8u2RX3b7c2SvjGm/S28Eza+26SH7CqqoGunlKhcOau2nIwUvnvi0by5agdFFb6ob789WdI3xrStnXkQXisvPwifPAp/u7hJmykorKBndlqUgzvsB6ccS1lVgDdXdqx5IS3pG2PaztZP4enTYfHDEPDD0r/A14sPL2/CgdOCwgp6dW69pH9i3xxO7JvDs4u3UOkPtNrztLXoF8OMMSZk7zrYvQaKd8GuL+Dzl532934Da95wloUr3A5bPoKu/Z0PhJLdcM0CCAYhqWYfdVdhOSOPzWnV8P930rf4wbNLmfOfr7nh2wNa9bnaiiV9Y0zrKDsAc86HknrGu9dO+AAvXgp719Zs+9vFTkno+nch51go20dFajcOlvno1Tnd+Xaw6X3odxokp0T1JZw2MJczjz+Kx9/byIUn9eaorNb7ZtFWrLxjjIk+Vfh/t0LpHphyP/wkD361G3qPgnNmwf9ucNY7djx87+/w3+/DuFuchO/tVHNbG9+Fsn0w57vwzER46HiKl75ENqX0zEqFzYvgbxfBP1tnEt9fnTuYqkCQn7y8Cn8HmJpBYvnkg1GjRuny5cvbO4yGFW6H3flOT6PHUOjcG447A5zrDBiTGLavgIpDUFwAb/8KUjpB0Q6YeAd8+3/rfszufMjqCRldD7ft+gK8GRCockpBnz7h9OBPuxU+fAC+/rjGJqo6HU3K0cNgwztOw3l/gGNOhaOOj+rLe33Fdn7298+5+tRjmXn+UCTG/79FZIWqjqpzmSX9Zio/CKmd4dETobDWWN7TfgaDzoX0HFjyZ8j9Foy+vn3iNKYpVJvWYVGF9f+Gly8/clnfsfDDBeBpQRW5/CCkZB3ehr8KNr7Lznl3c3TZV4fX6zMati87fP/yl2D3l3DcBOg7pvnPH+ae+fk8u3gLl4/uy70XDiPZE7uFEkv60XLwa+fA1M48+OC3MHQqfPkm9D8dvv1zKN3r9EZq1yQBrvk3fDXfuT35vprLKksgNbPVwzcJau96yP8nDJgIfUbC8uecHvkJl0LXAc4B0pI98Nq1UFkEV74OmbnOwdM9+ZDRzXnvH30SeNOcddfOg0PbYOt/aiZbgOnLwV8Bnfs6HZ9WcMEfF9NLDvCnSRmwdTGc9AOnvLPtU8g5xoktpPcoGD4NTrzc+QYhSTW/XURIVXnonfX8cdFGTujdmfsvPoGhR3eO4qsKU1QAVSXQfWCzHh5TSV9EpgCPAh7gGVW9v751YyLpB4OwfwPkz4NF9wG19leSF36xGdKynfubP3T+ecoPwrH/B876jVOLrCo5/JijT3I+KLoNgB0rYOVfYdjFcNzpIB7YuQr2fgW9hkPPE50/vDfD+R3jXytNGFXnJykJfOVOKTCUZMPXAefvumMFdD7GSbi1txP+d68ocu8LJCU7dfNgADa9B/s2OCNeyg44iU+DcGir8zhPKgy/DFb99fC2UjKh90g4sOXwN1ZJgqxekNkDdq48vO5RQ+D48+CzJ533c1Iy5B7vbHPUdc6B2eyjnaTbitbtKmbKox/x0zO/xS3fCUuKlcUQ8DkjhZb9BdI6OyOAkpKd0lPotSWnw+jroGgndOoOPU+AVX9z9uuEGc76vjLnfzSjq/OBWVkEg8+Hkt0sy8tj7acL2FqVheeYsZw6egyn7XyW5K79nLLSZ3+CQVOcg8671zi/O/d1Dmh7M5y2/qdDj2Gw9RPn2EefMeBNd3JNRRHsWg3dB8GNn0BS008+i5mkLyIeYD1wFrAdWAZcoar5da3f5klf1fkn8ZXB6ldh33rY9hkU5DnLh1wIp0536vZFBbDgZ87Bp6FTG97u5g/howedN9o7dzq1TkmCYD1n+iWnO2+A8lpTux41BHoOd3orWz6E9C5wzCnOmzQ1C3IHQ3Kq88bK7AG7v3B6YsMucRJDcpqzjdDr+a/vwDdLnTdV9tFQug8yj3L+WZLTnTd66V7nDRn0Hx4ZUbwLPCnO8xftBA046yenAuokoGDAWT8ly+lVZh4FHq/zT+nxHvmagwFnv6dmRfznApzk5q9wYklOgwOb3X3o7ofULECc+D0p4Ct11ju0zYkjvYuTjLN7O49J8jpJM6Or8wEs4tzP7Ons952rnH/arsc5j9/8gRN70U7nQ7yy2HnP9BgK695ynje0n/zl0G2gk2gOboWjBjv7Pz3Hadu5ynlfnHwVdMp1tvX1J877JasnlB9ynmPrf5x9XpdQUsvo6gx7TM12/uaDz4M3bnA6EwMmOq/nm8+gotBZv6oYzn/ciW/1XPjq/zmJ8oTLnPdiSif44HfOPhhwJky614klObVpf68WKK7w8emm/Ty8cD07Dpbz8W1nkJPRyGidUH5bPRfe/DEcfy5UlToHf8N1/5bz9679Ld2TCoHKIzeLILU7gE2VluPs45QsZ/+Hni810zmYPe0Fp4PYDLGU9E8FZqrqZPf+7QCq+ru61m9u0i/cv5vCJybi/GlAUOcPpIfvH7EMSNdyUnAScSpVAOyR7ryZ8l02e/qx0jOixT3tLC0mgIdy0ugb3IFfPOxMOhqvVtEvuA1B2ZA0AEXI0UOcEMgnVatIo5zv+D6ga/AgPkmmUDqTqpX00D101uIWxdQYPx6SCXBQOhPEQzd1PowCJOGh4dEMFaSQRhWVpFAsneiuBykikxLpRKaW4sWHhwDJOElsp/QiV/fhxef+ZWr/gJJU/RfsRHn1c/lIxou/xvMH3cfVFWcQ52+ZFPbPG3qtAXdgm49k0qiq97UGSEKqI3LuF5JFVwr5Ro5mfdIAuut+/Hj4NHk0Z/veI5NSNib159jgN3zhGUzP4F4GB9fznuc0JgcWkUyQIEIpGZRIBgXSkzJJp5R0+ge3sSHpOPZLDtmUkKqV7EzqSSFZLPecyE7p4cQhNevoqpCkAXJ1P7slt9H3sQQDJBHEL4c/oDO0DEEplU4NPDIyTc075b4AB925drp2SuGhy07kjEFHNe1JKwqdDg04H6jJ6fDuXU6P+8TLnU7HsmecxCtJTkIu2e0cGO4+0OkIetOdbzf/dSYc3Ip//2a+Wb+K//gGsXqPH/Zt4JDfS2/ZRzHpvB0YzaWeD5nqWcwLwclUSjobkvpzkmzgdFnJ10nH8Jr3u5waXMVaz7fYk3QUIoIAg4/O5onvndy01+iKpaR/CTBFVa937/8AGKuq08PWuQG4AeCYY44ZuXXr1iY/T1HhATb85YfUTOmCyuGUT1giAVAR/JKCIvglmRWZZ1CQ2h+feAlKbJ/O0LdiPeVJnfBqFSpJpAQryA4cpCwpk50p/RhZ8gFFni5UJGWSGThIUXI3FGFQ2So2pp9AUDx09e3moDeXTH8hGcES0oKlVCal45NUelVtoUrS6OLfQxLKrpS+BPCSHThAUXI3KiUdr1biVR8KBMVDAA8ZwRI6BYrY6z2aXN8OMoIlHEw+iszAIdKCZZQnZeJLSnFSviTjwU9u1Q4OJXenMin98F9ItdYHdRBx37clns6UejqTHiyhU7CYg8k9qEpKJS1YRpIGSA+WIhqgKikdj/oJSDKpwXL2e3uSHThAkgbZl9KbHN9ePOonRcs5lJxLd18BAUkmSQMcSs6lq38XpZ7O7E3pzdfpw+jqK6BToIgNGSfhlxT8kkxmoJBiTxcQIUn9aBPfNyJCRqAIvyTjDVZRmtxwPbzJ3Y8mPkCa+ICm9oeasnpKchK9u6Qzok8Oo/p1JSU5Ng+iqioHy3xsP1jGrsIKiiv8FFf4KKn0U+4L4A8ovoASCAbxBRV/IIg/oARVnXe44v5W+nfvxM8mDWpWHHGV9MPFRE3fGGPiTENJv60/LncAfcPu93HbjDHGtIG2TvrLgIEi0l9EUoDLgXltHIMxxiSsNi1Wq6pfRKYDb+MM2Zytql+2ZQzGGJPI2vwIpaouABa09fMaY4yxCdeMMSahWNI3xpgEYknfGGMSiCV9Y4xJIDE9y6aI7AWafkruYd2BfVEKJ1piMSaIzbhiMSaIzbhiMSaIzbhiMSaIblzHqmpuXQtiOum3lIgsr++stPYSizFBbMYVizFBbMYVizFBbMYVizFB28Vl5R1jjEkglvSNMSaBdPSk/3R7B1CHWIwJYjOuWIwJYjOuWIwJYjOuWIwJ2iiuDl3TN8YYU1NH7+kbY4wJY0nfGGMSSIdM+iIyRUTWichGEZnRzrF8LSJfiEieiCx327qKyEIR2eD+7tLKMcwWkT0isiasrc4YxPGYu+9Wi0jzrtfW/LhmisgOd3/licg5Yctud+NaJyKTWymmviKySETyReRLEbnFbW+3/dVATO29r9JEZKmIfO7Gdbfb3l9ElrjPP9edRh0RSXXvb3SX92vDmJ4XkS1h+2qE295m73f3+TwiskpE5rv3235fqWqH+sGZsnkTcByQAnwODGnHeL4GutdqewCY4d6eAfy+lWP4NnAysKaxGIBzgLdwrmZ3CrCkjeOaCfxvHesOcf+WqUB/92/saYWYegEnu7ezgPXuc7fb/mogpvbeVwJkure9wBJ3H7wKXO62/wm40b39f4E/ubcvB+a2YUzPA5fUsX6bvd/d57sVeAmY795v833VEXv6Y4CNqrpZVauAV4AL2jmm2i4A5ri35wAXtuaTqepHwIEIY7gAeEEdnwE5ItKrDeOqzwXAK6paqapbgI04f+tox1Sgqivd28XAWqA37bi/GoipPm21r1RVS9y7XvdHgYnAa2577X0V2oevAWeKNPXKus2OqT5t9n4XkT7AucAz7n2hHfZVR0z6vYFvwu5vp+F/kNamwDsiskKci74D9FDVAvf2LqBHO8RVXwyxsP+mu1+1Z4eVvto8Lvcr9Uk4vcWY2F+1YoJ23lduuSIP2AMsxPlWcUhV/XU8d3Vc7vJCoFtrx6SqoX11n7uvHhGR1Nox1RFvtP0B+AUQdO93ox32VUdM+rFmvKqeDJwN3CQi3w5fqM73t3YdNxsLMYR5ChgAjAAKgIfaIwgRyQReB36qqkXhy9prf9URU7vvK1UNqOoInOtdjwGOb+sYaqsdk4gMA27HiW000BW4rS1jEpHzgD2quqItn7cuHTHpx9TF11V1h/t7D/Amzj/G7tBXSPf3nnYIrb4Y2nX/qepu9582CPyFw2WJNotLRLw4yfVFVX3DbW7X/VVXTLGwr0JU9RCwCDgVp0QSuipf+HNXx+Uu7wzsb4OYprglMlXVSuA52n5fjQPOF5GvcUrOE4FHaYd91RGTfsxcfF1EOolIVug2MAlY48Zztbva1cA/2yG8+mKYB1zljmo4BSgMK2u0ulr11Kk4+ysU1+XuqIb+wEBgaSs8vwDPAmtV9eGwRe22v+qLKQb2Va6I5Li304GzcI43LAIucVerva9C+/AS4H33W1Nrx/RV2Ae24NTNw/dVq7/fVfV2Ve2jqv1wctL7qnol7bGvonVEOJZ+cI7Ir8epL/6qHeM4DmcUxefAl6FYcGpz7wEbgHeBrq0cx8s4X/99OHXD6+qLAWcUwxPuvvsCGNXGcf3Vfd7V7hu/V9j6v3LjWgec3Uoxjccp3awG8tyfc9pzfzUQU3vvq+HAKvf51wB3hr3vl+IcQP47kOq2p7n3N7rLj2vDmN5399Ua4G8cHuHTZu/3sBgncHj0TpvvK5uGwRhjEkhHLO8YY4yphyV9Y4xJIJb0jTEmgVjSN8aYBGJJ3xhjEoglfWOMSSCW9I0xJoH8f2gPtisPqtVSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Step: 5|| Loss: 84735.3125,  R0:2.2797217617746455, grad: 2110.959963570859, alpha: 0.010000454300091726 grad: -107634.296875, phi: 26.848676995735932 grad: 3155.7395215124325, sigma: 0.2921200091566737 grad 1389.839748301013, epsilon_t.mean: -0.38519027829170227 grad.mean 11.824082374572754\n",
            "This Run:  0.49899816513061523 seconds\n",
            "Time Step: 10|| Loss: 85371.015625,  R0:2.2797217532047274, grad: -1832.673157330728, alpha: 0.010001124318559935 grad: -101739.2890625, phi: 26.84867698032248 grad: 3198.5546933550454, sigma: 0.2921200022075152 grad 1389.8397813635113, epsilon_t.mean: -0.38999050855636597 grad.mean -10.265318870544434\n",
            "This Run:  0.499037504196167 seconds\n",
            "Time Step: 15|| Loss: 88958.1796875,  R0:2.2797217544509287, grad: 3646.969703931016, alpha: 0.010001844391973838 grad: 2668.018798828125, phi: 26.84867696497992 grad: 3319.122814995875, sigma: 0.29211999525842614 grad 1389.8398144256867, epsilon_t.mean: -0.38929253816604614 grad.mean 20.427705764770508\n",
            "This Run:  0.5706136226654053 seconds\n",
            "Time Step: 20|| Loss: 79754.0546875,  R0:2.2797217565981103, grad: -1897.7467141043453, alpha: 0.010002544813799683 grad: -187173.625, phi: 26.84867694951122 grad: 3010.1882435544103, sigma: 0.29211998830944114 grad 1389.8398474873568, epsilon_t.mean: -0.3880898058414459 grad.mean -10.629814147949219\n",
            "This Run:  0.5949513912200928 seconds\n",
            "Time Step: 25|| Loss: 74299.7734375,  R0:2.2797217753387624, grad: -502.0182403146257, alpha: 0.010003396390283857 grad: -209242.765625, phi: 26.848676934065534 grad: 2781.011292998847, sigma: 0.2921199813605949 grad 1389.8398805483537, epsilon_t.mean: -0.37759265303611755 grad.mean -2.811945676803589\n",
            "This Run:  0.5403063297271729 seconds\n",
            "Time Step: 30|| Loss: 71026.609375,  R0:2.279721792651838, grad: -349.5947989815322, alpha: 0.010004340796912113 grad: -220141.875, phi: 26.84867691915811 grad: 2648.502483456144, sigma: 0.29211997441192217 grad 1389.839913608562, epsilon_t.mean: -0.36789509654045105 grad.mean -1.9581791162490845\n",
            "This Run:  0.7053680419921875 seconds\n",
            "Time Step: 35|| Loss: 74887.2109375,  R0:2.2797218126234573, grad: -3774.2984860226384, alpha: 0.010005451108249044 grad: -233014.109375, phi: 26.84867690519016 grad: 2837.131776216339, sigma: 0.2921199674634577 grad 1389.8399466677643, epsilon_t.mean: -0.3567083775997162 grad.mean -21.140911102294922\n",
            "This Run:  0.4801640510559082 seconds\n",
            "Time Step: 40|| Loss: 71802.3046875,  R0:2.279721828197354, grad: -7240.889079733802, alpha: 0.0100066471453331 grad: -258053.65625, phi: 26.84867689219524 grad: 2736.642067224929, sigma: 0.29211996051523625 grad 1389.8399797258003, epsilon_t.mean: -0.34798505902290344 grad.mean -40.55826187133789\n",
            "This Run:  0.5030498504638672 seconds\n",
            "Time Step: 45|| Loss: 67000.453125,  R0:2.279721854886053, grad: -8646.46753873851, alpha: 0.010007815656174257 grad: -261598.9375, phi: 26.84867687994032 grad: 2548.7345734030514, sigma: 0.2921199535672926 grad 1389.8400127825412, epsilon_t.mean: -0.33303597569465637 grad.mean -48.431304931640625\n",
            "This Run:  0.4828639030456543 seconds\n",
            "Time Step: 50|| Loss: 62331.5390625,  R0:2.279721886397009, grad: -7409.17371085347, alpha: 0.0100088493642054 grad: -217844.140625, phi: 26.848676868736245 grad: 2330.820277057217, sigma: 0.2921199466196614 grad 1389.8400458377926, epsilon_t.mean: -0.3153858184814453 grad.mean -41.50087356567383\n",
            "This Run:  0.4891090393066406 seconds\n",
            "Time Step: 55|| Loss: 58000.1171875,  R0:2.2797218913186357, grad: -1143.284885738266, alpha: 0.010009542731518734 grad: -205869.9375, phi: 26.84867685635816 grad: 2218.853564859364, sigma: 0.2921199396723774 grad 1389.840078891372, epsilon_t.mean: -0.31262901425361633 grad.mean -6.4038615226745605\n",
            "This Run:  0.5352287292480469 seconds\n",
            "Time Step: 60|| Loss: 61664.67578125,  R0:2.27972190556261, grad: 118910.5563001114, alpha: 0.010010309216167702 grad: -125696.828125, phi: 26.848676844631377 grad: 2334.495618159216, sigma: 0.2921199327254754 grad 1389.8401119431562, epsilon_t.mean: -0.30465060472488403 grad.mean 666.0515747070312\n",
            "This Run:  0.6325592994689941 seconds\n",
            "Time Step: 65|| Loss: 67453.7890625,  R0:2.279721835416125, grad: -11028.329442179876, alpha: 0.01001151032699212 grad: -268543.21875, phi: 26.848676831720066 grad: 2580.1579259574833, sigma: 0.29211992577899 grad 1389.8401449929477, epsilon_t.mean: -0.3439416289329529 grad.mean -61.77278518676758\n",
            "This Run:  0.5517573356628418 seconds\n",
            "Time Step: 70|| Loss: 56273.140625,  R0:2.279721874854322, grad: -4243.701003408897, alpha: 0.010012657687478194 grad: -161353.984375, phi: 26.848676819956186 grad: 2113.101892348272, sigma: 0.2921199188329559 grad 1389.840178040604, epsilon_t.mean: -0.3218511939048767 grad.mean -23.770166397094727\n",
            "This Run:  0.6827816963195801 seconds\n",
            "Time Step: 75|| Loss: 56166.1328125,  R0:2.2797218613911774, grad: -8032.708773385222, alpha: 0.010013365362124693 grad: -143194.84375, phi: 26.84867680921191 grad: 2069.7970728383907, sigma: 0.2921199118874079 grad 1389.840211085932, epsilon_t.mean: -0.3293922543525696 grad.mean -44.99346923828125\n",
            "This Run:  0.4870109558105469 seconds\n",
            "Time Step: 80|| Loss: 59361.265625,  R0:2.279721848056584, grad: -6155.135156384095, alpha: 0.010014128323772502 grad: -200393.3125, phi: 26.84867679844438 grad: 2218.172482828144, sigma: 0.2921199049423806 grad 1389.8402441287947, epsilon_t.mean: -0.33686134219169617 grad.mean -34.47665023803711\n",
            "This Run:  0.6681308746337891 seconds\n",
            "Time Step: 85|| Loss: 56660.88671875,  R0:2.2797218854278896, grad: -9953.929710154454, alpha: 0.010014926783450626 grad: -184761.40625, phi: 26.848676787621645 grad: 2128.2598792047547, sigma: 0.2921198979979087 grad 1389.8402771690323, epsilon_t.mean: -0.3159286677837372 grad.mean -55.75476837158203\n",
            "This Run:  0.5243651866912842 seconds\n",
            "Time Step: 90|| Loss: 56797.14453125,  R0:2.279721868690127, grad: 32381.225321321894, alpha: 0.010015500094179279 grad: -89618.53125, phi: 26.848676776404517 grad: 2091.4185151790844, sigma: 0.2921198910540269 grad 1389.8403102064492, epsilon_t.mean: -0.32530391216278076 grad.mean 181.3763885498047\n",
            "This Run:  0.5550577640533447 seconds\n",
            "Time Step: 95|| Loss: 55247.234375,  R0:2.2797218720014354, grad: -6603.165519554888, alpha: 0.010016273591577612 grad: -127114.625, phi: 26.84867676541834 grad: 2039.4551641939859, sigma: 0.2921198841107699 grad 1389.8403432408907, epsilon_t.mean: -0.32344913482666016 grad.mean -36.9861946105957\n",
            "This Run:  0.6753222942352295 seconds\n",
            "Complete Run:  56.3988094329834 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}