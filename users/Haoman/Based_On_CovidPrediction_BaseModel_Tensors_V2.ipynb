{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "CovidPrediction_BaseModel_Tensors_V2.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaSNKP69zABm"
   },
   "source": [
    "To Dos:\n",
    "- Add sigma, phi and tau to optimization\n",
    "  - How to draw from negative binomial with negative phi?\n",
    "  - Tau as value to initialize y\n",
    "  - why does sigma have a gradient of 0?\n",
    "- Change loss function to negative log likelihood\n",
    "- Toy Data\n",
    "- Add prior knowledge to loss function\n",
    "- Optimize for loops\n",
    "- Check .clone() - Where do we need it and where is it redundant?\n",
    "\n",
    "\n",
    "\n",
    "Haomann: Neg. Log Likelihood & Phi Variable\n",
    "Anuar: Toy Data & Tau Variable\n",
    "Timo: Sigma Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "__This notebook is an approach proposed by Haoman to add NLL et Neg. Binomial distribution up on yt__\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VTtBtBGxMjwG"
   },
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import truncexpon, truncnorm, nbinom\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FmatRpHb3P2v"
   },
   "source": [
    "np.random.seed(seed=101)\n",
    "torch.manual_seed(101)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3g8-GkS6NU7Y",
    "outputId": "6771240a-6c16-4e1e-90d2-661ce273f16a"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kO1UX4ZMNVXp",
    "outputId": "d829fb2e-7fa5-4040-de4f-a2dd449c4530"
   },
   "source": [
    "cd /content/drive/MyDrive/CovidPrediction/"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/CovidPrediction\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfpgo2cWNLx5"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "66Bh9ONJNJMR",
    "outputId": "26282f8d-9427-44cf-bc36-0bf3d6ca726e"
   },
   "source": [
    "data = pd.read_csv('data/covid19model.csv')\n",
    "data.head(3)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hospit</th>\n",
       "      <th>serial_interval</th>\n",
       "      <th>delay_distr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046535</td>\n",
       "      <td>0.013006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087065</td>\n",
       "      <td>0.030046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112061</td>\n",
       "      <td>0.044674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  hospit  serial_interval  delay_distr\n",
       "0  2020-02-17       0         0.046535     0.013006\n",
       "1  2020-02-18       0         0.087065     0.030046\n",
       "2  2020-02-19       0         0.112061     0.044674"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6BWeg3zYNfD7"
   },
   "source": [
    "cero = torch.tensor(0, requires_grad=False, device=device, dtype=dtype)\n",
    "num_impute = 6\n",
    "observed_daily_hospit = torch.tensor(data.hospit, requires_grad=False, device=device, dtype=dtype)\n",
    "pi = torch.tensor(data.delay_distr, requires_grad=False, device=device, dtype=dtype)\n",
    "serial_interval = torch.tensor(data.serial_interval, requires_grad=False, device=device, dtype=dtype)\n",
    "population = torch.tensor(5793636, requires_grad=False, device=device, dtype=dtype)\n",
    "num_observations = len(observed_daily_hospit)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnZypONcN4DZ"
   },
   "source": [
    "Initialize latent variables / parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BVk4vgPnN3Aw"
   },
   "source": [
    "tau = np.random.exponential(1 / 0.03)\n",
    "#tau_t = torch.tensor(tau, requires_grad=True, device=device, dtype=dtype)\n",
    "# b=(upper-lower)/scale, loc=lower, scale=scale\n",
    "y = torch.tensor(truncexpon.rvs(b=(1000 - 0) / tau, loc=0, scale=tau), requires_grad=False, device=device, dtype=dtype)  # number of initial newly_infected (seed)\n",
    "\n",
    "# For trunc ((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "#phi = torch.tensor(truncnorm.rvs((0 - 0) / 5, (np.inf - 0) / 5, loc=0, scale=5), requires_grad=True, device=device, dtype=dtype)  # dispersion (shape) parameter for observations\n",
    "R0 = torch.tensor(truncnorm.rvs((2 - 3.6) / 0.8, (5 - 3.6) / 0.8, loc=3.6, scale=0.8), requires_grad=True, device=device, dtype=dtype)  # initial reproduction number\n",
    "alpha = torch.tensor(truncnorm.rvs((0 - 1/100) / 1/100, (5/100 - 1/100) / 1/100, loc=1/100, scale=1/100), requires_grad=True, device=device, dtype=dtype)  # probability to get hospitalized\n",
    "sigma = torch.tensor(truncnorm.rvs((0 - 0.05) / 0.03, (0.15 - 0.05) / 0.03, loc=0.05, scale=0.03), requires_grad=True, device=device, dtype=dtype)  # standart deviation of random walk step"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "__From Andreas' model__\n",
    "\n",
    "\"\"\"\n",
    "(model::Covid19Model)(θ) returns the log loglikelihood of our model with\n",
    "respect to the parameters θ together with inferred values of 'Rt' and\n",
    "'expected_daily_hospit'.\n",
    "\n",
    "In a 'standard' machine learning model the loss function is something like\n",
    "loss(y,ŷ,θ) = sum( (y-ŷ)^2 ) + α*θ,\n",
    "where 'y' is the observed outcome, 'ŷ' is the model estimate and α is some\n",
    "regularisation parameter.\n",
    "\n",
    "In a Bayesian framework the first term is called the log loglikelihood of the\n",
    "data wrt. the model and the regularisation term is the log likelihood of our\n",
    "parameters θ wrt. the prior.\n",
    "\n",
    "The 'standard' loss function is a special case of the Bayesian approach which\n",
    "assumes Gaussian distribtions.\n",
    "\"\"\"\n",
    "\n",
    "function evaluate(model::Covid19Model, θ)\n",
    "\t@unpack τ, y, ϕ, R0, α, σ, ϵt = θ\n",
    "\t@unpack num_obs, num_impute, observed_hospit, i2h, pop, si = model\n",
    "    ℓ = 0. #likelihood\n",
    "\n",
    "\t# log likelihood wrt. our prior (\"regularisation\")\n",
    "\tℓ += logpdf( Exponential(1 / 0.03), τ)\n",
    "\tT = typeof(τ)\n",
    "\tℓ += logpdf( truncated(Exponential(τ), T(0), T(1000)), y) # number of initial newly_infected (seed)\n",
    "\tℓ += logpdf( truncated(Normal(25, 5), 0, Inf), ϕ) # dispersion (shape) parameter for observations\n",
    "\tℓ += logpdf( truncated(Normal(3.6, 0.8), 2, 5), R0) # initial reproduction number\n",
    "\tℓ += logpdf( truncated(Normal(1/100,1/100), 0,5/100), α) # probability to get hospitalized\n",
    "\tℓ += logpdf( truncated(Normal(0.05, 0.03), 0, 0.15), σ) # standart deviation of random walk step"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFyBW5v9Iu11"
   },
   "source": [
    "# Define Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "v8i41EQqtlfI"
   },
   "source": [
    "def forward_pass():\n",
    "\n",
    "  # Initialize time series variables\n",
    "  newly_infected = torch.zeros(num_observations)  # number of newly infected\n",
    "  effectively_infectious = torch.zeros(num_observations)  # effective number of infectious individuals\n",
    "  expected_daily_hospit = torch.zeros(num_observations)  # expected number of daily hospitalizations\n",
    "  cumulative_infected = torch.zeros(num_observations)  # cumulative number of infected\n",
    "  eta_t = torch.zeros(num_observations)  # transformed reproduction number\n",
    "  epsilon_t = torch.zeros(num_observations)  # random walk\n",
    "  St = torch.zeros(num_observations)  # fraction of susceptible population\n",
    "\n",
    "  # seed initial infection / impute first num_impute days\n",
    "  newly_infected[0:num_impute] = y.clone()\n",
    "  cumulative_infected[0] = 0.\n",
    "  cumulative_infected[1:num_impute] = torch.cumsum(newly_infected[0:num_impute - 1].clone(), dim=0)\n",
    "  St[0:num_impute] = torch.tensor([torch.maximum(population.clone() - x, torch.tensor(0)) / population for x in cumulative_infected[0:num_impute].clone()])\n",
    "\n",
    "  # calculate Rt: the basic reproduction number\n",
    "  beta_0 = torch.log(R0)\n",
    "  epsilon_t[0] = torch.distributions.Normal(cero, sigma).rsample()\n",
    "  for t in range(1, num_observations):\n",
    "      epsilon_t[t] = torch.distributions.Normal(epsilon_t[t - 1].clone(), sigma).rsample()\n",
    "  eta_t = beta_0 + epsilon_t  # + RNN[X_t, t]  # .clone() necessary?\n",
    "  Rt = torch.exp(eta_t)\n",
    "\n",
    "  # calculate infections\n",
    "  for t in range(num_impute, num_observations):\n",
    "      # Update cumulative newly_infected\n",
    "      cumulative_infected[t] = cumulative_infected[t - 1].clone() + newly_infected[t - 1].clone()\n",
    "      # Adjusts for portion of pop that are susceptible\n",
    "      St[t] = torch.maximum(population.clone() - cumulative_infected[t].clone(), cero) / population.clone()\n",
    "      # effective number of infectous individuals\n",
    "      for i in range(0, t - 1):\n",
    "          effectively_infectious[t] += newly_infected[i].clone() * serial_interval[t - i].clone()\n",
    "      newly_infected[t] = St[t].clone() * Rt[t].clone() * effectively_infectious[t].clone()\n",
    "\n",
    "  # calculate expected number of hospitalizations\n",
    "  expected_daily_hospit[0] = (1e-15) * newly_infected[0].clone()\n",
    "  for t in range(1, num_observations):\n",
    "      for i in range(0, t - 1):\n",
    "          expected_daily_hospit[t] += newly_infected[i].clone() * pi[t - i].clone()\n",
    "  expected_daily_hospit = alpha * expected_daily_hospit\n",
    "  return expected_daily_hospit"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ot3EWx3k4YMm"
   },
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HmyO5HQzoiNA",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "2ac8af7d-e36b-4c78-9da4-6ccc686f231f"
   },
   "source": [
    "learning_rate = 1e-12\n",
    "for t2 in range(10):\n",
    "\n",
    "  for t in range (40):\n",
    "    # forward pass - calculate expected_daily_hospit\n",
    "    expected_daily_hospit = forward_pass()\n",
    "\n",
    "    loss = (observed_daily_hospit - expected_daily_hospit).pow(2).sum()\n",
    "      # for i in 1:num_obs\n",
    "      #   ℓ += logpdf( NegativeBinomial2(expected_daily_hospit[i], ϕ), observed_hospit[i])\n",
    "    loss -= truncnorm.logpdf(x=R0.detach().numpy() ,a=2, b=5, loc=0, scale=0.8)\n",
    "    loss += truncnorm.logpdf(x=alpha.detach().numpy(),a=0 , b=5/100, loc=0, scale=1)\n",
    "    loss += truncnorm.logpdf(x=sigma.detach().numpy(),a=0 , b=0.15, loc=0, scale=1)\n",
    "    loss.backward()\n",
    "\n",
    "    print(f'Time Step: {t}, Loss: {loss}, Observed_daily_hospit: {torch.sum(observed_daily_hospit)}, Expected_daily_hospit: {torch.sum(expected_daily_hospit)}')\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "      #tau_t -= learning_rate * tau_t.grad\n",
    "      #phi -= learning_rate * phi.grad\n",
    "      R0 -= learning_rate * R0.grad\n",
    "      alpha -= learning_rate * alpha.grad\n",
    "      sigma -= learning_rate * sigma.grad\n",
    "      print(f' R0:{R0}, grad: {R0.grad}, alpha: {alpha} grad: {alpha.grad}, sigma: {sigma} grad {sigma.grad}' )\n",
    "\n",
    "      #tau_t.grad = None\n",
    "      #phi.grad = None\n",
    "      R0.grad = None\n",
    "      alpha.grad = None\n",
    "      sigma.grad = None\n",
    "  \n",
    "  \n",
    "  plt.plot(expected_daily_hospit.detach().numpy(), label='expected_daily_hospit')\n",
    "  plt.plot(observed_daily_hospit.detach().numpy(), label='observed_daily_hospit')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Time Step: 0, Loss: 9678165.0, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 46265.0234375\n",
      " R0:2.279672145843506, grad: 49630956.0, alpha: 0.007919954136013985 grad: 2079902976.0, sigma: 0.06633935868740082 grad -605297920.0\n",
      "Time Step: 1, Loss: 47646884.0, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 40388.18359375\n",
      " R0:2.279621124267578, grad: 50986972.0, alpha: -0.004136447794735432 grad: 12056401920.0, sigma: 0.06562210619449615 grad 717252160.0\n",
      "Time Step: 2, Loss: -inf, Observed_daily_hospit: 13199.0, Expected_daily_hospit: -21183.041015625\n",
      " R0:2.2796239852905273, grad: -2871753.75, alpha: 0.0008316189050674438 grad: -4968066560.0, sigma: 0.06549075990915298 grad 131347288.0\n",
      "Time Step: 3, Loss: 1008317.25, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 1.7178809642791748\n",
      " R0:2.2796239852905273, grad: -253.41990661621094, alpha: 0.0008317555766552687 grad: -136644.8125, sigma: 0.06549075245857239 grad 4515.41064453125\n",
      "Time Step: 4, Loss: 1331909.125, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 3939.194091796875\n",
      " R0:2.279623508453369, grad: 457772.3125, alpha: -3.513053525239229e-05 grad: 866886144.0, sigma: 0.06548797339200974 grad 2780383.5\n",
      "Time Step: 5, Loss: -inf, Observed_daily_hospit: 13199.0, Expected_daily_hospit: -174.7107391357422\n",
      " R0:2.279623508453369, grad: 8572.2060546875, alpha: 0.00014062289847061038 grad: -175753440.0, sigma: 0.06548792123794556 grad 52448.8984375\n",
      "Time Step: 6, Loss: 1005637.8125, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 710.570068359375\n",
      " R0:2.279623508453369, grad: -18757.5234375, alpha: 8.09167540865019e-05 grad: 59706148.0, sigma: 0.06548792868852615 grad -7355.8125\n",
      "Time Step: 7, Loss: 996862.8125, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 416.13720703125\n",
      " R0:2.279623508453369, grad: -20577.9453125, alpha: 0.00017996947281062603 grad: -99052720.0, sigma: 0.06548811495304108 grad -185360.84375\n",
      "Time Step: 8, Loss: 1006309.0, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 534.82763671875\n",
      " R0:2.279623508453369, grad: -1219.68701171875, alpha: 0.0001753926044330001 grad: 4576871.5, sigma: 0.06548814475536346 grad -29903.994140625\n",
      "Time Step: 9, Loss: 939200.4375, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 905.7772827148438\n",
      " R0:2.279623508453369, grad: 116621.2578125, alpha: 0.0004908061819151044 grad: -315413536.0, sigma: 0.0654895156621933 grad -1367904.0\n",
      "Time Step: 10, Loss: 1065773.125, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 2221.327880859375\n",
      " R0:2.279623508453369, grad: 13671.0009765625, alpha: 0.00018024464952759445 grad: 310561536.0, sigma: 0.06548947840929031 grad 34812.25\n",
      "Time Step: 11, Loss: 1006230.8125, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 160.2420654296875\n",
      " R0:2.279623508453369, grad: -9421.04296875, alpha: 0.00019154924666509032 grad: -11304594.0, sigma: 0.06548935174942017 grad 127386.34375\n",
      "Time Step: 12, Loss: 1007068.25, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 26.90854835510254\n",
      " R0:2.279623508453369, grad: -5427.20556640625, alpha: 0.00019860212341882288 grad: -7052875.0, sigma: 0.06548933684825897 grad 15754.2958984375\n",
      "Time Step: 13, Loss: 1030650.0, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 1043.23876953125\n",
      " R0:2.279623508453369, grad: -4788.28662109375, alpha: -5.616407725028694e-05 grad: 254766208.0, sigma: 0.0654890239238739 grad 315633.46875\n",
      "Time Step: 14, Loss: -inf, Observed_daily_hospit: 13199.0, Expected_daily_hospit: -297.5962829589844\n",
      " R0:2.279623508453369, grad: 12213.208984375, alpha: 0.00019225358846597373 grad: -248417680.0, sigma: 0.06548892706632614 grad 96141.6328125\n",
      "Time Step: 15, Loss: 1013281.875, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 1007.73486328125\n",
      " R0:2.279623508453369, grad: -32515.82421875, alpha: 3.824337909463793e-05 grad: 154010208.0, sigma: 0.06548888236284256 grad 42719.8046875\n",
      "Time Step: 16, Loss: 997298.75, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 209.29574584960938\n",
      " R0:2.279623508453369, grad: -7280.97216796875, alpha: 0.00029383256332948804 grad: -255589184.0, sigma: 0.06548900157213211 grad -119246.390625\n",
      "Time Step: 17, Loss: 1007101.125, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 224.4876251220703\n",
      " R0:2.279623508453369, grad: -3627.1572265625, alpha: 0.0002965510939247906 grad: -2718531.25, sigma: 0.06548894196748734 grad 62816.92578125\n",
      "Time Step: 18, Loss: 1007224.125, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 1641.5302734375\n",
      " R0:2.279623508453369, grad: -29758.515625, alpha: -4.1959050577133894e-05 grad: 338510144.0, sigma: 0.06548920273780823 grad -259524.0\n",
      "Time Step: 19, Loss: -inf, Observed_daily_hospit: 13199.0, Expected_daily_hospit: -226.49594116210938\n",
      " R0:2.279623508453369, grad: 5083.3203125, alpha: 0.00014734588330611587 grad: -189304928.0, sigma: 0.06548917293548584 grad 29954.5703125\n",
      "Time Step: 20, Loss: 1004890.75, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 532.236328125\n",
      " R0:2.279623508453369, grad: -7183.62939453125, alpha: 0.00014119336265139282 grad: 6152518.0, sigma: 0.06548918783664703 grad -12255.17578125\n",
      "Time Step: 21, Loss: 996887.375, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 636.8012084960938\n",
      " R0:2.279623508453369, grad: -27098.748046875, alpha: 0.00017001767992042005 grad: -28824314.0, sigma: 0.06548937410116196 grad -186149.703125\n",
      "Time Step: 22, Loss: 1017618.75, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 911.9642333984375\n",
      " R0:2.279623508453369, grad: -13614.814453125, alpha: -2.656692231539637e-05 grad: 196584608.0, sigma: 0.06548923999071121 grad 137155.109375\n",
      "Time Step: 23, Loss: -inf, Observed_daily_hospit: 13199.0, Expected_daily_hospit: -140.19894409179688\n",
      " R0:2.279623508453369, grad: 3002.58740234375, alpha: 0.00010559054499026388 grad: -132157472.0, sigma: 0.06548923254013062 grad 9688.0517578125\n",
      "Time Step: 24, Loss: 1002521.1875, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 517.57568359375\n",
      " R0:2.279623508453369, grad: -10567.7705078125, alpha: 9.760829561855644e-05 grad: 7982250.5, sigma: 0.065489262342453 grad -30542.962890625\n",
      "Time Step: 25, Loss: 1006127.0625, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 254.47470092773438\n",
      " R0:2.279623508453369, grad: -6958.35009765625, alpha: 0.00011434117914177477 grad: -16732883.0, sigma: 0.06548923999071121 grad 25549.6796875\n",
      "Time Step: 26, Loss: 1007389.9375, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 122.35111236572266\n",
      " R0:2.279623508453369, grad: -4033.255859375, alpha: 0.0001219114928971976 grad: -7570316.0, sigma: 0.06548917293548584 grad 66411.1484375\n",
      "Time Step: 27, Loss: 995196.75, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 671.3914794921875\n",
      " R0:2.279623508453369, grad: -25680.001953125, alpha: 0.00010988472786266357 grad: 12026768.0, sigma: 0.06548939645290375 grad -222081.5\n",
      "Time Step: 28, Loss: 1004003.6875, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 505.38916015625\n",
      " R0:2.279623508453369, grad: -6178.78466796875, alpha: 9.007072367239743e-05 grad: 19814004.0, sigma: 0.06548939645290375 grad -2404.94580078125\n",
      "Time Step: 29, Loss: 1007867.625, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 396.9361572265625\n",
      " R0:2.279623508453369, grad: -7466.25634765625, alpha: 7.118771463865414e-05 grad: 18883010.0, sigma: 0.06548932939767838 grad 66220.3671875\n",
      "Time Step: 30, Loss: 1008672.1875, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 367.76055908203125\n",
      " R0:2.279623508453369, grad: -5417.39111328125, alpha: 2.5334327801829204e-05 grad: 45853388.0, sigma: 0.0654892697930336 grad 58262.6796875\n",
      "Time Step: 31, Loss: 1007769.875, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 115.01342010498047\n",
      " R0:2.279623508453369, grad: -1210.337158203125, alpha: 3.955837746616453e-05 grad: -14224048.0, sigma: 0.065489262342453 grad 7798.2958984375\n",
      "Time Step: 32, Loss: 1007782.4375, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 145.8957061767578\n",
      " R0:2.279623508453369, grad: 408.42828369140625, alpha: 4.656672535929829e-05 grad: -7008349.0, sigma: 0.065489262342453 grad -2522.1611328125\n",
      "Time Step: 33, Loss: 1001273.875, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 170.9840087890625\n",
      " R0:2.279623508453369, grad: 16753.7421875, alpha: 0.0001916455221362412 grad: -145078800.0, sigma: 0.06548953801393509 grad -272376.53125\n",
      "Time Step: 34, Loss: 1005705.5625, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 640.0603637695312\n",
      " R0:2.279623508453369, grad: -3645.426513671875, alpha: 0.00017262037727050483 grad: 19025142.0, sigma: 0.06548957526683807 grad -35185.5703125\n",
      "Time Step: 35, Loss: 1010696.75, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 690.145263671875\n",
      " R0:2.279623508453369, grad: 7806.966796875, alpha: 0.00011944691505050287 grad: 53173464.0, sigma: 0.06548959761857986 grad -24493.240234375\n",
      "Time Step: 36, Loss: 994549.5, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 439.4927673339844\n",
      " R0:2.27962327003479, grad: 209274.75, alpha: 0.00020996015518903732 grad: -90513248.0, sigma: 0.06548970192670822 grad -102888.9375\n",
      "Time Step: 37, Loss: 1020167.0625, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 1074.28662109375\n",
      " R0:2.27962327003479, grad: -18009.05859375, alpha: 3.640328941401094e-05 grad: 173556864.0, sigma: 0.0654895231127739 grad 177276.828125\n",
      "Time Step: 38, Loss: 1007799.5625, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 195.76385498046875\n",
      " R0:2.27962327003479, grad: -2367.944580078125, alpha: 2.4642715288791806e-05 grad: 11760575.0, sigma: 0.0654895082116127 grad 18352.845703125\n",
      "Time Step: 39, Loss: 1007786.75, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 102.89706420898438\n",
      " R0:2.27962327003479, grad: -1312.038818359375, alpha: 4.442664430825971e-05 grad: -19783930.0, sigma: 0.0654895007610321 grad 7846.74951171875\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Time Step: 0, Loss: 997514.5, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 231.1869659423828\n",
      " R0:2.27962327003479, grad: -10295.4150390625, alpha: 0.0002561927249189466 grad: -211766080.0, sigma: 0.06548964232206345 grad -141983.390625\n",
      "Time Step: 1, Loss: 1020566.625, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 1307.717041015625\n",
      " R0:2.27962327003479, grad: -10290.6630859375, alpha: 4.864684888161719e-05 grad: 207545872.0, sigma: 0.06548957526683807 grad 64212.4296875\n",
      "Time Step: 2, Loss: 1006549.0, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 237.10763549804688\n",
      " R0:2.27962327003479, grad: 11716.095703125, alpha: 6.452013622038066e-05 grad: -15873284.0, sigma: 0.06548967957496643 grad -108017.453125\n",
      "Time Step: 3, Loss: 1007566.625, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 82.56053924560547\n",
      " R0:2.27962327003479, grad: -3742.7548828125, alpha: 7.689769699936733e-05 grad: -12377562.0, sigma: 0.06548964977264404 grad 32985.33203125\n",
      "Time Step: 4, Loss: 986197.3125, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 416.8457336425781\n",
      " R0:2.27962327003479, grad: -14155.1728515625, alpha: 0.0002915756485890597 grad: -214677952.0, sigma: 0.06548991799354553 grad -267988.0\n",
      "Time Step: 5, Loss: 1035343.75, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 1609.220458984375\n",
      " R0:2.279623031616211, grad: 129313.25, alpha: -0.0001307741622440517 grad: 422349824.0, sigma: 0.0654904767870903 grad -555245.5625\n",
      "Time Step: 6, Loss: -inf, Observed_daily_hospit: 13199.0, Expected_daily_hospit: -719.5546875\n",
      " R0:2.279623031616211, grad: 23024.37890625, alpha: 0.0004818027373403311 grad: -612576896.0, sigma: 0.06549003720283508 grad 442256.78125\n",
      "Time Step: 7, Loss: 1058415.375, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 2475.175048828125\n",
      " R0:2.279623031616211, grad: -19185.37109375, alpha: 4.4598185922950506e-05 grad: 437204544.0, sigma: 0.0654902458190918 grad -208688.09375\n",
      "Time Step: 8, Loss: 1001307.75, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 214.9063720703125\n",
      " R0:2.279623031616211, grad: -11331.8515625, alpha: 0.00017955618386622518 grad: -134958000.0, sigma: 0.06549034267663956 grad -97825.2421875\n",
      "Time Step: 9, Loss: 1001467.5, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 713.7166137695312\n",
      " R0:2.279623031616211, grad: -16059.3408203125, alpha: 0.00016456130833830684 grad: 14994880.0, sigma: 0.06549042463302612 grad -83677.3125\n",
      "Time Step: 10, Loss: 985142.125, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 882.6207885742188\n",
      " R0:2.279623031616211, grad: -20685.9375, alpha: 0.00015603280917275697 grad: 8528496.0, sigma: 0.06548979133367538 grad 632188.9375\n",
      "Time Step: 11, Loss: 1007021.625, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 54.84754943847656\n",
      " R0:2.279623031616211, grad: -6591.3955078125, alpha: 0.00016483453509863466 grad: -8801726.0, sigma: 0.0654897540807724 grad 37308.53515625\n",
      "Time Step: 12, Loss: 1004783.625, Observed_daily_hospit: 13199.0, Expected_daily_hospit: 583.0218505859375\n",
      " R0:2.279623031616211, grad: -5663.66796875, alpha: 0.00014744502550456673 grad: 17389510.0, sigma: 0.06548977643251419 grad -23372.53515625\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-2491fdaff74b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0mloss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mtruncnorm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogpdf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0malpha\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscale\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mloss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mtruncnorm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogpdf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msigma\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.15\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscale\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m     \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'Time Step: {t}, Loss: {loss}, Observed_daily_hospit: {torch.sum(observed_daily_hospit)}, Expected_daily_hospit: {torch.sum(expected_daily_hospit)}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    243\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    244\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 245\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    246\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    247\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    145\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[1;32m    146\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 147\u001B[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001B[0m\u001B[1;32m    148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KVaHBOjSY4P"
   },
   "source": [
    "compare observed hospitalizations to model results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OWOxqWBXSY9i"
   },
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(expected_daily_hospit.detach().numpy(), label='expected_daily_hospit')\n",
    "plt.plot(observed_daily_hospit.detach().numpy(), label='observed_daily_hospit')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}