{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "NLL_draft4.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/tsuehr/covid-prediction-tu/blob/Epid_Model/users/Timo/NLL_V3.ipynb",
     "timestamp": 1623245192988
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxQowkq99G3j"
   },
   "source": [
    "This version is based on Timo's NLL_V3\n",
    "changes:\n",
    "\n",
    "\n",
    "*   truncnorm distribution\n",
    "*   multivariant random walk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d17BEQFdPTqc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623338129154,
     "user_tz": -120,
     "elapsed": 1172,
     "user": {
      "displayName": "Armsinrius",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64",
      "userId": "02997351779082443110"
     }
    }
   },
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon, truncexpon, truncnorm, nbinom, norm\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch import rand\n",
    "from torch import autograd\n",
    "from torch import optim\n",
    "import truncnormal\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pdBc47jlPTqe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623338132686,
     "user_tz": -120,
     "elapsed": 328,
     "user": {
      "displayName": "Armsinrius",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64",
      "userId": "02997351779082443110"
     }
    }
   },
   "source": [
    "np.random.seed(seed=101)\n",
    "torch.manual_seed(101)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "dtype = torch.float64\n",
    "device = torch.device(\"cpu\")"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "EaFwH9Vm7YMg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623338133444,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "Armsinrius",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64",
      "userId": "02997351779082443110"
     }
    },
    "outputId": "09490d07-0558-4f57-d725-16f4f16dcb77"
   },
   "source": [
    "data = pd.read_csv('covid19model.csv')\n",
    "data"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "           date  hospit  serial_interval   delay_distr\n0    2020-02-17       0         0.046535  1.300600e-02\n1    2020-02-18       0         0.087065  3.004645e-02\n2    2020-02-19       0         0.112061  4.467391e-02\n3    2020-02-20       0         0.119346  5.547300e-02\n4    2020-02-21       0         0.114540  6.242203e-02\n..          ...     ...              ...           ...\n402  2021-03-25      38         0.000000  2.817211e-32\n403  2021-03-26      31         0.000000  2.349426e-32\n404  2021-03-27      39         0.000000  1.959313e-32\n405  2021-03-28      32         0.000000  1.633974e-32\n406  2021-03-29      45         0.000000  1.362655e-32\n\n[407 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>hospit</th>\n      <th>serial_interval</th>\n      <th>delay_distr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-02-17</td>\n      <td>0</td>\n      <td>0.046535</td>\n      <td>1.300600e-02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-02-18</td>\n      <td>0</td>\n      <td>0.087065</td>\n      <td>3.004645e-02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-02-19</td>\n      <td>0</td>\n      <td>0.112061</td>\n      <td>4.467391e-02</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-02-20</td>\n      <td>0</td>\n      <td>0.119346</td>\n      <td>5.547300e-02</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-02-21</td>\n      <td>0</td>\n      <td>0.114540</td>\n      <td>6.242203e-02</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>402</th>\n      <td>2021-03-25</td>\n      <td>38</td>\n      <td>0.000000</td>\n      <td>2.817211e-32</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>2021-03-26</td>\n      <td>31</td>\n      <td>0.000000</td>\n      <td>2.349426e-32</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>2021-03-27</td>\n      <td>39</td>\n      <td>0.000000</td>\n      <td>1.959313e-32</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>2021-03-28</td>\n      <td>32</td>\n      <td>0.000000</td>\n      <td>1.633974e-32</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>2021-03-29</td>\n      <td>45</td>\n      <td>0.000000</td>\n      <td>1.362655e-32</td>\n    </tr>\n  </tbody>\n</table>\n<p>407 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4seIKt9FY5OF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623338135805,
     "user_tz": -120,
     "elapsed": 249,
     "user": {
      "displayName": "Armsinrius",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64",
      "userId": "02997351779082443110"
     }
    }
   },
   "source": [
    "def trunc_exponential(scale, upper):\n",
    "    sample = torch.distributions.exponential.Exponential(1/scale).rsample()\n",
    "    sample = sample/torch.tensor(1-torch.exp(-upper/scale))\n",
    "    return sample\n",
    "# torch.distributions.exponential.Exponential(1/scale).sample()/torch.tensor(1-torch.exp(-upper/scale))\n",
    "\n",
    "def trunc_normal(mu, sigma, under, upper):\n",
    "    distribution = torch.distributions.normal.Normal(loc=mu, scale=sigma, validate_args=None)\n",
    "    normal_sample = distribution.rsample()\n",
    "    cumulative = distribution.cdf(torch.tensor(upper)) - distribution.cdf(torch.tensor(under))\n",
    "    return normal_sample/cumulative"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2IY_KzX7uV9"
   },
   "source": [
    "# Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7remU4ygPTqf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623338137579,
     "user_tz": -120,
     "elapsed": 445,
     "user": {
      "displayName": "Armsinrius",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64",
      "userId": "02997351779082443110"
     }
    }
   },
   "source": [
    "cero = torch.tensor(0., requires_grad=False, device=device, dtype=dtype)\n",
    "num_impute = 6\n",
    "observed_daily_hospit = torch.tensor(data.hospit, requires_grad=False, device=device, dtype=dtype)\n",
    "pi = torch.tensor(data.delay_distr, requires_grad=False, device=device, dtype=dtype)\n",
    "serial_interval = torch.tensor(data.serial_interval, requires_grad=False, device=device, dtype=dtype)\n",
    "population = torch.tensor(5793636, requires_grad=False, device=device, dtype=dtype)\n",
    "num_observations = len(observed_daily_hospit)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NG5jECpf77Xk"
   },
   "source": [
    "## Initialize latent variables/parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9XhscamaPTqg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623338139909,
     "user_tz": -120,
     "elapsed": 214,
     "user": {
      "displayName": "Armsinrius",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64",
      "userId": "02997351779082443110"
     }
    },
    "outputId": "53b89798-d6c8-43ee-ec76-118b89013c5b"
   },
   "source": [
    "tau= torch.ones([407])*torch.tensor(np.random.exponential(1 / 0.03), requires_grad=True, device=device, dtype=dtype)\n",
    "phi = torch.ones([407])*torch.tensor(truncnorm.rvs((0 - 25) / 10, (np.inf - 25) / 10, loc=25, scale=10), requires_grad=True, device=device, dtype=dtype) # has to be positive, between 0-50 --> uniform # dispersion (shape) parameter for observations\n",
    "R0 = torch.ones([407])*torch.tensor(truncnorm.rvs((2 - 3.6) / 0.8, (5 - 3.6) / 0.8, loc=3.6, scale=0.8), requires_grad=True, device=device, dtype=dtype)  # probably gamma or inverse gamma distribution (compare to truncated normal) # initial reproduction number\n",
    "alpha = torch.ones([407])*torch.tensor(truncnorm.rvs((0 - 1/100) / 1/100, (5/100 - 1/100) / 1/100, loc=1/100, scale=1/100), requires_grad=True, device=device, dtype=dtype) # uniform distribution between (0-5%) # probability to get hospitalized\n",
    "sigma = torch.tensor(truncnorm.rvs((0 - 0.1) / 0.3, (0.5 - 0.1) / 0.3, loc=0.1, scale=0.3), requires_grad=True, device=device, dtype=dtype)  # positive, tricky, gamma or inverse gamma, log normal  --> try something out, large sigma--> prone to overfitting # standart deviation of random walk step\n",
    "\n",
    "epsilon_t = torch.zeros(num_observations, device=device)\n",
    "epsilon_t[0] = torch.distributions.Normal(cero, sigma.detach()).rsample()\n",
    "for t in range(1, num_observations):\n",
    "  epsilon_t[t] = torch.distributions.Normal(epsilon_t[t - 1].detach(), sigma.detach()).rsample()\n",
    "epsilon_t.requires_grad_(True)"
   ],
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.6057,  0.6792,  0.1094,  0.5416,  0.0686, -0.0793, -0.3051, -0.8462,\n        -0.9185, -0.4727, -0.8387, -1.9550, -1.8912, -1.1492, -1.0083, -1.4390,\n        -2.2672, -1.9081, -1.4017, -0.6828, -1.1667, -1.0665, -1.3718, -1.9149,\n        -2.0488, -1.8511, -1.9172, -1.4584, -1.4430, -0.7964, -1.9711, -1.9372,\n        -1.8587, -0.7378, -0.8625, -1.3158, -1.4651, -1.6309, -2.1826, -2.2134,\n        -2.5898, -2.2735, -2.3422, -1.5105, -1.9712, -2.0212, -2.2330, -1.4600,\n        -1.7913, -3.1523, -3.5586, -2.4049, -2.8478, -2.1388, -2.3728, -2.4273,\n        -1.7042, -1.8118, -1.9421, -2.1251, -1.8308, -1.6385, -1.4427, -1.7032,\n        -1.8624, -2.4621, -2.7376, -3.2286, -3.0737, -2.6626, -1.9573, -1.6427,\n        -0.7089, -0.7672, -0.6596, -1.1184, -1.3987, -0.7923,  0.0475, -0.1756,\n         0.1948,  0.4295,  0.3491,  0.2626,  0.3897,  0.2151,  0.9415,  0.7017,\n         1.0889,  0.5356,  0.0335,  0.8284,  0.9599,  1.4265,  2.1769,  1.7030,\n         1.8722,  3.0540,  3.9440,  3.7312,  4.1134,  3.7990,  4.3429,  3.9145,\n         3.9387,  3.7472,  3.8581,  4.4572,  4.2584,  4.2199,  4.5409,  3.3467,\n         3.6539,  3.0550,  3.0816,  3.5077,  3.5180,  3.3807,  3.7458,  3.0696,\n         3.7184,  3.3510,  4.0746,  3.5992,  3.0389,  3.0086,  3.1702,  2.7986,\n         2.5372,  2.8437,  3.6959,  3.0753,  3.8437,  4.1731,  5.2053,  5.0608,\n         5.0694,  4.6191,  4.7148,  4.3950,  4.2430,  4.8524,  4.3737,  4.9940,\n         5.0990,  5.2417,  4.7325,  4.9804,  4.8507,  5.1303,  5.2679,  4.8518,\n         4.0547,  4.1433,  3.7948,  4.3761,  4.4082,  5.0324,  5.0656,  5.7525,\n         6.3668,  6.5850,  5.6513,  5.5400,  6.0142,  5.6481,  5.1490,  5.6606,\n         6.8602,  7.3867,  6.9886,  6.6549,  6.2072,  5.7161,  5.3409,  5.3800,\n         5.4095,  5.4414,  6.1150,  6.5311,  6.9777,  6.8316,  6.6645,  7.2837,\n         7.0906,  6.7055,  6.8141,  6.3038,  6.0372,  6.0636,  6.2250,  6.3116,\n         6.6286,  5.7332,  5.5293,  5.1860,  5.7313,  5.5619,  6.0877,  6.5406,\n         6.6688,  6.5784,  7.3845,  7.7851,  7.3255,  7.9791,  8.0227,  8.1219,\n         7.6168,  7.4646,  7.7617,  7.7768,  8.0088,  7.7341,  7.4801,  7.6477,\n         7.3188,  6.4674,  5.9367,  5.0882,  5.9805,  6.3900,  6.0237,  6.4959,\n         6.7677,  6.6714,  6.6782,  6.8403,  6.9859,  7.2991,  6.8632,  6.9448,\n         6.8729,  7.4188,  8.0301,  7.9571,  7.3410,  6.9759,  7.6062,  6.7076,\n         5.9620,  5.6169,  5.7191,  5.9984,  6.2496,  7.2533,  7.4090,  8.2583,\n         8.0260,  8.6622,  8.6282,  8.5463,  8.5501,  8.4475,  8.8665,  8.9772,\n         8.7882,  9.1041,  9.6178,  9.1609,  8.7735,  9.1474,  9.4580,  9.5109,\n         9.5918,  9.6249,  9.7978,  9.2708,  8.2795,  7.6716,  8.0216,  8.1962,\n         7.9577,  7.9218,  8.8905,  9.0044,  9.2658,  8.8996,  8.7747,  8.4676,\n         7.9743,  8.3881,  8.3381,  8.5998,  8.6394,  8.4700,  8.9775,  9.0744,\n         8.8212,  8.3203,  7.7967,  8.4299,  9.4430,  9.5439,  9.5666,  8.6803,\n         8.8324,  8.0155,  7.6025,  7.6836,  7.9287,  7.6310,  7.3352,  8.0013,\n         8.5751,  8.0687,  7.7739,  7.6147,  7.8010,  7.5624,  7.0962,  7.8303,\n         8.0375,  7.9635,  7.7241,  7.2676,  7.0949,  6.7739,  6.9131,  7.3402,\n         7.8637,  7.3765,  5.8429,  5.5572,  4.5886,  4.5067,  5.1219,  4.7755,\n         4.8873,  4.9143,  4.7377,  4.7880,  4.4729,  4.2607,  3.9259,  3.8848,\n         4.2019,  4.1651,  4.8460,  4.8279,  5.5477,  4.9780,  4.8697,  5.4620,\n         5.5159,  6.2188,  5.9665,  5.5207,  5.8534,  5.5355,  4.5245,  4.2673,\n         4.2377,  4.3324,  3.7580,  3.6648,  2.9284,  2.2748,  2.7340,  2.7593,\n         1.6920,  1.4261,  2.2718,  2.4832,  2.6242,  3.1274,  3.5878,  3.3998,\n         2.8793,  2.9295,  2.6383,  2.9841,  2.4834,  1.6115,  0.7084,  0.0740,\n        -0.3964, -0.7497, -0.5812, -1.4278, -1.2386, -1.0049, -0.4294, -0.6265,\n        -0.4759, -1.1315, -1.4244, -2.0247, -1.6451, -2.1772, -1.1975, -0.0578,\n         0.3887,  1.0576,  1.1806,  1.2646,  2.0227,  1.8830,  1.2652,  1.4516,\n         0.8497,  0.9293,  1.1578,  1.3055,  0.4726,  0.1155,  0.5055],\n       requires_grad=True)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165,\n",
      "        24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165, 24.2165],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tau = torch.ones([407])*tau\n",
    "tau.size()\n",
    "print(tau)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtO_C9CTSkM-"
   },
   "source": [
    "This is a way to generate the initial params from pytorch distribution directly without truncation.\n",
    "NOTE: Use either this code block below or above."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JcKQh9lISjqA",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1623338645328,
     "user_tz": -120,
     "elapsed": 216,
     "user": {
      "displayName": "Armsinrius",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64",
      "userId": "02997351779082443110"
     }
    },
    "outputId": "cf2d8def-bc7c-482d-8790-8197b6dfed8a"
   },
   "source": [
    "dist_tau_t = distributions.exponential.Exponential(torch.tensor([1/0.03], device=device))\n",
    "#tau_t = dist_tau_t.sample()\n",
    "\n",
    "dist_y = distributions.exponential.Exponential(tau)\n",
    "#y = dist_y.sample()\n",
    "\n",
    "dist_phi = truncnormal.TruncatedNormal(loc=torch.tensor([25], device=device), scale=torch.tensor([10], device=device), a= torch.tensor([0], device=device), b= torch.tensor([float('inf')], device=device))\n",
    "#dist_phi = distributions.normal.Normal(loc=torch.tensor([25], device=device), scale=torch.tensor([10], device=device))\n",
    "#phi = dist_phi.sample()\n",
    "\n",
    "dist_R0 = truncnormal.TruncatedNormal(loc=torch.tensor([3.6], device=device), scale=torch.tensor([0.8], device=device), a= torch.tensor([2], device=device), b= torch.tensor([5], device=device))\n",
    "#dist_R0 = distributions.normal.Normal(loc=torch.tensor([3.6], device=device), scale=torch.tensor([0.8], device=device))\n",
    "#R0 = dist_R0.sample()\n",
    "\n",
    "dist_alpha = truncnormal.TruncatedNormal(loc=torch.tensor([0.01], device=device), scale=torch.tensor([0.01], device=device), a= torch.tensor([0], device=device), b= torch.tensor([0.05], device=device))\n",
    "#dist_alpha = distributions.normal.Normal(loc=torch.tensor([0.01], device=device), scale=torch.tensor([0.01], device=device))\n",
    "#alpha = dist_alpha.sample()\n",
    "\n",
    "dist_sigma = truncnormal.TruncatedNormal(loc=torch.tensor([0.1], device=device), scale=torch.tensor([0.3], device=device), a= torch.tensor([0], device=device), b= torch.tensor([0.5], device=device))\n",
    "#dist_sigma = distributions.normal.Normal(loc=torch.tensor([0.1], device=device), scale=torch.tensor([0.3], device=device))\n",
    "#sigma = dist_sigma.sample()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fI1Yjma8CL8"
   },
   "source": [
    "# Define Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1CF2bx-79_eo"
   },
   "source": [
    "def calc_prior_loss(tau, phi, R0, alpha, sigma):\n",
    "  # log likelihood wrt. our prior (\"regularisation\")\n",
    "  # ll stands for log-likelihood\n",
    "  ll = torch.tensor(0.0, device=device)\n",
    "\n",
    "  #dist_tau_t = distributions.exponential.Exponential(torch.tensor([1/0.03]))\n",
    "  #ll += dist_tau_t.log_prob(tau).item()\n",
    "\n",
    "  #dist_y = distributions.exponential.Exponential(tau) #the parameter in the brasket should either be float or tensor, to avoid any inconvienience,\n",
    "                                                      # I use everything as tensor. NOTE:tau_t is already a tensor.\n",
    "  #ll += dist_y.log_prob(y).item()\n",
    "\n",
    "  #dist_phi = distribution.normal.Normal(loc=torch.tensor([25]), scale=torch.tensor([10]))\n",
    "  ll += dist_phi.log_prob(phi).item()\n",
    "\n",
    "  #dist_R0 = distribution.normal.Normal(loc=torch.tensor([3.6]), scale=torch.tensor([0.8]))\n",
    "  ll += dist_R0.log_prob(R0).item()\n",
    "\n",
    "  #dist_alpha = distribution.normal.Normal(loc=torch.tensor([0.01]), scale=torch.tensor([0.01]))\n",
    "  ll += dist_alpha.log_prob(alpha).item()\n",
    "\n",
    "  #dist_sigma = distribution.normal.Normal(loc=torch.tensor([0.1]), scale=torch.tensor([0.3]))\n",
    "  ll += dist_sigma.log_prob(sigma).item()\n",
    "\n",
    "  return ll"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nt27Ab2l9_hC"
   },
   "source": [
    "def seed_init_infect(y):\n",
    "  # Initialize newly_infected, cumulative_infected, St\n",
    "  newly_infected = torch.zeros(num_observations, device=device, dtype=dtype)  # number of newly infected\n",
    "  cumulative_infected = torch.zeros(num_observations, device=device)  # cumulative number of infected\n",
    "  \n",
    "  St = torch.zeros(num_observations, device=device)  # fraction of susceptible population\n",
    "  # seed initial infection / impute first num_impute days\n",
    "  newly_infected[0:num_impute] = y.clone()\n",
    "  cumulative_infected[0] = 0.\n",
    "  cumulative_infected[1:num_impute] = torch.cumsum(newly_infected[0:num_impute - 1].clone(), dim=0)\n",
    "  St[0:num_impute] = torch.tensor([torch.maximum(population.clone() - x, torch.tensor(0)) / population for x in cumulative_infected[0:num_impute].clone()])\n",
    "  return newly_infected, cumulative_infected, St"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mf9tMHun9_j0"
   },
   "source": [
    "def calc_Rt(R0, epsilon_t, sigma, ll):\n",
    "  # Initialize eta_t\n",
    "  eta_t = torch.zeros(num_observations, device=device)  # transformed reproduction number\n",
    "\n",
    "  # calculate Rt: the basic reproduction number\n",
    "  # basic reproduction number as a latent random walk\n",
    "  beta_0 = torch.log(R0)\n",
    "  eta_t[0] = beta_0\n",
    "  for t in range(1, num_observations):\n",
    "      dist_epsilon_t = torch.distributions.Normal(epsilon_t[t - 1], sigma)\n",
    "      ll += dist_epsilon_t.log_prob(epsilon_t[t - 1])\n",
    "  eta_t[1:num_observations] = beta_0 + epsilon_t[0:num_observations-1].clone()\n",
    "  Rt = torch.exp(eta_t)\n",
    "  return Rt, ll"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AcM7ArwKRp60"
   },
   "source": [
    "def calc_infections(cumulative_infected, newly_infected, St, Rt):\n",
    "  # Initialize effectively_infectious\n",
    "  effectively_infectious = torch.zeros(num_observations, device=device)  # effective number of infectious individuals\n",
    "  \n",
    "  # calculate infections\n",
    "  for t in range(num_impute, num_observations):\n",
    "      # Update cumulative newly_infected\n",
    "      cumulative_infected[t] = cumulative_infected[t - 1].clone() + newly_infected[t - 1].clone()\n",
    "      # Adjusts for portion of pop that are susceptible\n",
    "      St[t] = torch.maximum(population.clone() - cumulative_infected[t].clone(), cero) / population.clone()\n",
    "      # effective number of infectous individuals\n",
    "      ni_temp = newly_infected[:t].view(1, 1, -1).clone()\n",
    "      si_temp = torch.flip(serial_interval, (0,))[-t:].view(1, 1, -1)\n",
    "      effectively_infectious[t] = torch.nn.functional.conv1d(ni_temp, si_temp)\n",
    "      \n",
    "      newly_infected[t] = St[t].clone() * Rt[t].clone() * effectively_infectious[t].clone()\n",
    "  return newly_infected"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JrSVBFldAD-l"
   },
   "source": [
    "def calc_hospit(newly_infected, alpha):\n",
    "  # Initialize expected_daily_hospit\n",
    "  expected_daily_hospit = torch.zeros(num_observations, device=device)  # expected number of daily hospitalizations\n",
    "\n",
    "  # calculate expected number of hospitalizations\n",
    "  expected_daily_hospit[0] = (1e-15) * newly_infected[0].clone()\n",
    "  for t in range(1, num_observations):\n",
    "      ni_temp = newly_infected[:t].view(1, 1, -1)\n",
    "      pi_temp = torch.flip(pi, (0,))[-t-1:-1].view(1, 1, -1)\n",
    "      expected_daily_hospit[t] = torch.nn.functional.conv1d(ni_temp, pi_temp)\n",
    "  expected_daily_hospit = alpha * expected_daily_hospit\n",
    "  return expected_daily_hospit"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kvgAHKIXAEBU"
   },
   "source": [
    "def compare_results(expected_daily_hospit, phi, ll):\n",
    "  # compare observed hospitalizations to model results\n",
    "  # likelihood of the data wrt. to the model\n",
    "\n",
    "  for i in range(0, num_observations):\n",
    "      p = 1/(1+ expected_daily_hospit[i]/phi)\n",
    "      dist = torch.distributions.negative_binomial.NegativeBinomial(phi, p-torch.tensor(2.225e-5))\n",
    "      ll += dist.log_prob(observed_daily_hospit[i])\n",
    "  return ll"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zZMf1XWoAtSt"
   },
   "source": [
    "def forward_pass():\n",
    "  # Initialize y\n",
    "  y = trunc_exponential(tau, 1000)\n",
    "\n",
    "  # Calculate prior loss\n",
    "  ll = calc_prior_loss(tau, phi, R0, alpha, sigma)\n",
    "  \n",
    "  # Seed initial infections\n",
    "  newly_infected, cumulative_infected, St = seed_init_infect(y)\n",
    "  \n",
    "  # Calculate Rt & random walk loss \n",
    "  Rt, ll = calc_Rt(R0, epsilon_t, sigma, ll)\n",
    "  \n",
    "  # Calculate infections\n",
    "  newly_infected = calc_infections(cumulative_infected, newly_infected, St, Rt)\n",
    "\n",
    "  # Calculate expected hospitalizations\n",
    "  expected_daily_hospit = calc_hospit(newly_infected, alpha)\n",
    "\n",
    "  # Compare observed hospitalizations to model results\n",
    "  ll = compare_results(expected_daily_hospit, phi, ll)\n",
    "  return expected_daily_hospit, Rt, ll"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2bb73561946a>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample = sample/torch.tensor(1-torch.exp(-upper/scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.5112e-17, 2.5573e-03, 6.3596e-03, 1.1081e-02, 1.6394e-02, 2.2012e-02,\n",
      "        2.7705e-02, 3.2179e-02, 3.5934e-02, 3.8895e-02, 4.1005e-02, 4.1737e-02,\n",
      "        4.1648e-02, 4.0908e-02, 3.9444e-02, 3.7509e-02, 3.5225e-02, 3.2824e-02,\n",
      "        3.0370e-02, 2.7937e-02, 2.5650e-02, 2.3473e-02, 2.1374e-02, 1.9388e-02,\n",
      "        1.7517e-02, 1.5790e-02, 1.4215e-02, 1.2769e-02, 1.1443e-02, 1.0246e-02,\n",
      "        9.2010e-03, 8.2539e-03, 7.4185e-03, 6.6971e-03, 6.0546e-03, 5.5075e-03,\n",
      "        5.0079e-03, 4.5610e-03, 4.1583e-03, 3.7859e-03, 3.4478e-03, 3.1444e-03,\n",
      "        2.8843e-03, 2.6525e-03, 2.4415e-03, 2.2416e-03, 2.0565e-03, 1.8807e-03,\n",
      "        1.7156e-03, 1.5650e-03, 1.4228e-03, 1.2924e-03, 1.1739e-03, 1.0659e-03,\n",
      "        9.7019e-04, 8.8210e-04, 8.0522e-04, 7.3743e-04, 6.7769e-04, 6.2939e-04,\n",
      "        5.9050e-04, 5.6116e-04, 5.4411e-04, 5.3584e-04, 5.4126e-04, 5.6282e-04,\n",
      "        5.9477e-04, 6.4514e-04, 7.2272e-04, 7.9685e-04, 8.6172e-04, 9.0605e-04,\n",
      "        9.2849e-04, 9.3415e-04, 9.2859e-04, 9.0891e-04, 8.7892e-04, 8.3943e-04,\n",
      "        7.9179e-04, 7.3927e-04, 6.8433e-04, 6.2868e-04, 5.7351e-04, 5.1959e-04,\n",
      "        4.6769e-04, 4.1858e-04, 3.7255e-04, 3.2995e-04, 2.9090e-04, 2.5544e-04,\n",
      "        2.2347e-04, 1.9483e-04, 1.6935e-04, 1.4681e-04, 1.2694e-04, 1.0952e-04,\n",
      "        9.4290e-05, 8.1040e-05, 6.9530e-05, 5.9568e-05, 5.0967e-05, 4.3572e-05,\n",
      "        3.7211e-05, 3.1751e-05, 2.7069e-05, 2.3059e-05, 1.9631e-05, 1.6711e-05,\n",
      "        1.4221e-05, 1.2095e-05, 1.0281e-05, 8.7344e-06, 7.4167e-06, 6.2955e-06,\n",
      "        5.3410e-06, 4.5288e-06, 3.8381e-06, 3.2510e-06, 2.7522e-06, 2.3287e-06,\n",
      "        1.9694e-06, 1.6647e-06, 1.4065e-06, 1.1878e-06, 1.0027e-06, 8.4622e-07,\n",
      "        7.1405e-07, 6.0241e-07, 5.0816e-07, 4.2860e-07, 3.6146e-07, 3.0478e-07,\n",
      "        2.5698e-07, 2.1665e-07, 1.8265e-07, 1.5397e-07, 1.2978e-07, 1.0938e-07,\n",
      "        9.2180e-08, 7.7671e-08, 6.5434e-08, 5.5118e-08, 4.6419e-08, 3.9085e-08,\n",
      "        3.2905e-08, 2.7694e-08, 2.3304e-08, 1.9606e-08, 1.6490e-08, 1.3866e-08,\n",
      "        1.1657e-08, 9.7979e-09, 8.2331e-09, 6.9167e-09, 5.8096e-09, 4.8788e-09,\n",
      "        4.0966e-09, 3.4394e-09, 2.8876e-09, 2.4243e-09, 2.0353e-09, 1.7087e-09,\n",
      "        1.4345e-09, 1.2045e-09, 1.0115e-09, 8.4949e-10, 7.1353e-10, 5.9942e-10,\n",
      "        5.0364e-10, 4.2325e-10, 3.5575e-10, 2.9908e-10, 2.5148e-10, 2.1149e-10,\n",
      "        1.7789e-10, 1.4963e-10, 1.2588e-10, 1.0593e-10, 8.9167e-11, 7.5110e-11,\n",
      "        6.3337e-11, 5.3537e-11, 4.5474e-11, 3.8750e-11, 3.3200e-11, 2.8641e-11,\n",
      "        2.4907e-11, 2.1980e-11, 1.9585e-11, 1.7731e-11, 1.6084e-11, 1.4692e-11,\n",
      "        1.3606e-11, 1.2715e-11, 1.2067e-11, 1.1604e-11, 1.1152e-11, 1.0770e-11,\n",
      "        1.0416e-11, 1.0136e-11, 9.9759e-12, 1.0005e-11, 1.0375e-11, 1.0692e-11,\n",
      "        1.0947e-11, 1.1147e-11, 1.1259e-11, 1.1378e-11, 1.1387e-11, 1.1208e-11,\n",
      "        1.0943e-11, 1.0584e-11, 1.0135e-11, 9.6331e-12, 9.1479e-12, 8.6068e-12,\n",
      "        8.0654e-12, 7.5521e-12, 7.0610e-12, 6.5824e-12, 6.1101e-12, 5.6590e-12,\n",
      "        5.2318e-12, 4.8199e-12, 4.4248e-12, 4.0389e-12, 3.6714e-12, 3.3322e-12,\n",
      "        3.0111e-12, 2.7154e-12, 2.4411e-12, 2.1881e-12, 1.9594e-12, 1.7535e-12,\n",
      "        1.5722e-12, 1.4100e-12, 1.2633e-12, 1.1319e-12, 1.0146e-12, 9.1367e-13,\n",
      "        8.2474e-13, 7.4913e-13, 6.8403e-13, 6.3132e-13, 5.8530e-13, 5.4893e-13,\n",
      "        5.1701e-13, 4.9029e-13, 4.6371e-13, 4.3814e-13, 4.1457e-13, 3.9519e-13,\n",
      "        3.8054e-13, 3.7413e-13, 3.7219e-13, 3.7045e-13, 3.6870e-13, 3.6585e-13,\n",
      "        3.6208e-13, 3.6062e-13, 3.5711e-13, 3.5437e-13, 3.5217e-13, 3.5102e-13,\n",
      "        3.5186e-13, 3.5315e-13, 3.5345e-13, 3.5680e-13, 3.6363e-13, 3.7114e-13,\n",
      "        3.7760e-13, 3.7903e-13, 3.7710e-13, 3.7191e-13, 3.6707e-13, 3.6467e-13,\n",
      "        3.6424e-13, 3.6729e-13, 3.7120e-13, 3.8436e-13, 3.9336e-13, 4.0212e-13,\n",
      "        4.1336e-13, 4.2856e-13, 4.4424e-13, 4.6895e-13, 4.9707e-13, 5.3807e-13,\n",
      "        5.9926e-13, 7.6124e-13, 9.9042e-13, 1.3684e-12, 2.2200e-12, 3.2392e-12,\n",
      "        4.8020e-12, 7.3928e-12, 1.1835e-11, 1.8098e-11, 2.8384e-11, 4.3966e-11,\n",
      "        7.0795e-11, 1.1228e-10, 2.0785e-10, 3.8070e-10, 6.4354e-10, 1.1233e-09,\n",
      "        2.0415e-09, 4.5177e-09, 9.8850e-09, 2.4231e-08, 6.6670e-08, 2.0118e-07,\n",
      "        5.0400e-07, 1.2513e-06, 2.9570e-06, 7.5136e-06, 1.9239e-05, 5.1337e-05,\n",
      "        1.4108e-04, 3.5584e-04, 8.3864e-04, 2.4688e-03, 7.2796e-03, 2.0164e-02,\n",
      "        5.5692e-02, 1.3956e-01, 3.4066e-01, 6.6489e-01, 1.1109e+00, 1.8451e+00,\n",
      "        3.3508e+00, 7.3013e+00, 1.6379e+01, 3.6023e+01, 8.2900e+01, 1.6347e+02,\n",
      "        2.9052e+02, 5.3653e+02, 1.0150e+03, 1.8274e+03, 2.7257e+03, 3.2474e+03,\n",
      "        3.5723e+03, 3.7257e+03, 3.7405e+03, 3.6501e+03, 3.4845e+03, 3.2689e+03,\n",
      "        3.0236e+03, 2.7642e+03, 2.5024e+03, 2.2468e+03, 2.0029e+03, 1.7746e+03,\n",
      "        1.5638e+03, 1.3717e+03, 1.1981e+03, 1.0426e+03, 9.0433e+02, 7.8206e+02,\n",
      "        6.7453e+02, 5.8038e+02, 4.9829e+02, 4.2697e+02, 3.6519e+02, 3.1184e+02,\n",
      "        2.6588e+02, 2.2638e+02, 1.9251e+02, 1.6351e+02, 1.3873e+02, 1.1759e+02,\n",
      "        9.9580e+01, 8.4257e+01, 7.1235e+01, 6.0181e+01, 5.0809e+01, 4.2868e+01,\n",
      "        3.6148e+01, 3.0464e+01, 2.5661e+01, 2.1605e+01, 1.8181e+01, 1.5294e+01,\n",
      "        1.2861e+01, 1.0810e+01, 9.0834e+00, 7.6301e+00, 6.4074e+00, 5.3791e+00,\n",
      "        4.5146e+00, 3.7881e+00, 3.1777e+00, 2.6651e+00, 2.2347e+00, 1.8735e+00,\n",
      "        1.5703e+00, 1.3160e+00, 1.1027e+00, 9.2377e-01, 7.7378e-01, 6.4806e-01,\n",
      "        5.4268e-01, 4.5439e-01, 3.8041e-01, 3.1844e-01, 2.6654e-01],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([407])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_daily_hospit, Rt, ll = forward_pass()\n",
    "expected_daily_hospit.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mg2pWcC384K0"
   },
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BBZ3KIq1PTqk",
    "outputId": "27b71961-3941-454d-ed10-315de9853e07"
   },
   "source": [
    "learning_rate = 1e-12\n",
    "epochs = 100\n",
    "complete_time = time.time()\n",
    "\n",
    "for k in range (epochs):\n",
    "    start_time = time.time()\n",
    "    decay = (1 - (k / (epochs*1e5))) ** 2\n",
    "    learning_rate = learning_rate * decay\n",
    "\n",
    "    # forward pass - calculate expected_daily_hospit\n",
    "    expected_daily_hospit, Rt, ll = forward_pass()\n",
    "\n",
    "    #backward pass\n",
    "    loss = -ll\n",
    "    loss.backward()\n",
    "\n",
    "    if k%5 == 0:\n",
    "      print(f'Time Step: {k}|| Loss: {loss},  R0:{R0}, grad: {R0.grad}, alpha: {alpha} grad: {alpha.grad}, phi: {phi} grad: {phi.grad}, sigma: {sigma} grad {sigma.grad}, epsilon_t.mean: {epsilon_t.mean()} grad.mean {epsilon_t.grad.mean()}')\n",
    "      print(\"This Run:  %s seconds\" % (time.time() - start_time))\n",
    "    with torch.no_grad(): # this part is SGD. can also replace with loss.step\n",
    "        tau -= learning_rate * tau.grad\n",
    "        phi -= learning_rate * phi.grad \n",
    "        R0 -= learning_rate * R0.grad \n",
    "        alpha -= learning_rate * alpha.grad \n",
    "        sigma -= learning_rate * sigma.grad \n",
    "        epsilon_t -= learning_rate * epsilon_t.grad * 1e+8\n",
    "\n",
    "        tau.grad = None\n",
    "        phi.grad = None\n",
    "        R0.grad = None\n",
    "        alpha.grad = None\n",
    "        sigma.grad = None\n",
    "        epsilon_t.grad = None\n",
    "\n",
    "    \n",
    "    if k%100 == 0:    \n",
    "      plt.plot(expected_daily_hospit.cpu().detach().numpy(), label='expected_daily_hospit')\n",
    "      plt.plot(observed_daily_hospit.cpu().detach().numpy(), label='observed_daily_hospit')\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "\n",
    "\n",
    "print(\"Complete Run:  %s seconds\" % (time.time() - complete_time))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-2bb73561946a>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample = sample/torch.tensor(1-torch.exp(-upper/scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Step: 0|| Loss: 81750.765625,  R0:2.2797217757676145, grad: 4246.042225313076, alpha: 0.009999857608264206 grad: -135924.25, phi: 26.848677011157655 grad: 3002.1711809298336, sigma: 0.2921200161058668 grad 1389.8397152383375, epsilon_t.mean: -0.37735244631767273 grad.mean 23.783279418945312\n",
      "This Run:  0.7035973072052002 seconds\n"
     ]
    }
   ]
  }
 ]
}