{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of NLL_draft2.ipynb","provenance":[{"file_id":"1qJ4eae958xwlcLJAO3XcYs4d6jjycz0n","timestamp":1622621816305},{"file_id":"https://github.com/tsuehr/covid-prediction-tu/blob/Epid_Model/users/Haoman/Based_On_CovidPrediction_BaseModel_Tensors_V2.ipynb","timestamp":1622476406271}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WaSNKP69zABm"},"source":["To Dos:\n","- Add sigma, phi and tau to optimization\n","  - How to draw from negative binomial with negative phi?\n","  - Tau as value to initialize y\n","  - why does sigma have a gradient of 0?\n","- Change loss function to negative log likelihood\n","- Toy Data\n","- Add prior knowledge to loss function\n","- Optimize for loops\n","- Check .clone() - Where do we need it and where is it redundant?\n","\n","\n","\n","Haomann: Neg. Log Likelihood & Phi Variable\n","Anuar: Toy Data & Tau Variable\n","Timo: Sigma Variable"]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"7BR5c9QpIDWI"},"source":["__This notebook is an approach proposed by Haoman to add NLL et Neg. Binomial distribution up on yt__\n","\n","todos:\n","1. forward pass needs to be checked again for bugs\n","2. the model transformation and also the further steps like the likelihood lossfunction needs to be defined\n"]},{"cell_type":"code","metadata":{"id":"VTtBtBGxMjwG","executionInfo":{"status":"ok","timestamp":1622617982719,"user_tz":-120,"elapsed":3445,"user":{"displayName":"Armsinrius","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64","userId":"02997351779082443110"}}},"source":["import scipy.stats\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.stats import expon, truncexpon, truncnorm, nbinom\n","import pandas as pd\n","import torch\n","from torch import nn\n","from torch import distributions"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"FmatRpHb3P2v","executionInfo":{"status":"ok","timestamp":1622617982720,"user_tz":-120,"elapsed":4,"user":{"displayName":"Armsinrius","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64","userId":"02997351779082443110"}}},"source":["np.random.seed(seed=101)\n","torch.manual_seed(101)\n","torch.use_deterministic_algorithms(True)\n","dtype = torch.float\n","device = torch.device(\"cpu\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3g8-GkS6NU7Y","outputId":"6771240a-6c16-4e1e-90d2-661ce273f16a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kO1UX4ZMNVXp","outputId":"d829fb2e-7fa5-4040-de4f-a2dd449c4530"},"source":["cd /content/drive/MyDrive/CovidPrediction/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/CovidPrediction\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qfpgo2cWNLx5"},"source":["# Initialization"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"66Bh9ONJNJMR","executionInfo":{"status":"ok","timestamp":1622618012359,"user_tz":-120,"elapsed":243,"user":{"displayName":"Armsinrius","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64","userId":"02997351779082443110"}},"outputId":"4cb484fb-da55-4821-92ee-98ce96f7971b"},"source":["data = pd.read_csv('data/covid19model.csv')\n","data.head(3)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>hospit</th>\n","      <th>serial_interval</th>\n","      <th>delay_distr</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-02-17</td>\n","      <td>0</td>\n","      <td>0.046535</td>\n","      <td>0.013006</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-02-18</td>\n","      <td>0</td>\n","      <td>0.087065</td>\n","      <td>0.030046</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2020-02-19</td>\n","      <td>0</td>\n","      <td>0.112061</td>\n","      <td>0.044674</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         date  hospit  serial_interval  delay_distr\n","0  2020-02-17       0         0.046535     0.013006\n","1  2020-02-18       0         0.087065     0.030046\n","2  2020-02-19       0         0.112061     0.044674"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"6BWeg3zYNfD7","executionInfo":{"status":"ok","timestamp":1622618014542,"user_tz":-120,"elapsed":220,"user":{"displayName":"Armsinrius","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64","userId":"02997351779082443110"}}},"source":["cero = torch.tensor(0, requires_grad=False, device=device, dtype=dtype)\n","num_impute = 6\n","observed_daily_hospit = torch.tensor(data.hospit, requires_grad=False, device=device, dtype=dtype)\n","pi = torch.tensor(data.delay_distr, requires_grad=False, device=device, dtype=dtype)\n","serial_interval = torch.tensor(data.serial_interval, requires_grad=False, device=device, dtype=dtype)\n","population = torch.tensor(5793636, requires_grad=False, device=device, dtype=dtype)\n","num_observations = len(observed_daily_hospit)\n","model = [observed_daily_hospit,pi,serial_interval,num_observations]"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KnZypONcN4DZ"},"source":["Initialize latent variables / parameters"]},{"cell_type":"markdown","metadata":{"id":"8pDKvDf_F-RM"},"source":["1. initialize (constrained )variables\n","2. transform to unconstrained\n","3.1 transform unconstrained to constrained, xis the unconstrained -> theta constrained  theta = f(x)\n","3.2 loss = evaluate(model, x)   evaluate(model, f(x))\n","3.3 gradient(loss)   #loss.backward()#gradient(  x -> evaluate(model, f(x)), x )\n","\n","3.4 optimize (e.g. SGD: x -= learningrate * x.grad)\n","3.5 return to 3.1\n","\n"]},{"cell_type":"code","metadata":{"id":"BVk4vgPnN3Aw","executionInfo":{"status":"ok","timestamp":1622618025703,"user_tz":-120,"elapsed":219,"user":{"displayName":"Armsinrius","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64","userId":"02997351779082443110"}}},"source":["tau = np.random.exponential(1 / 0.03)\n","tau_t = torch.tensor(tau, requires_grad=True, device=device, dtype=dtype)\n","# b=(upper-lower)/scale, loc=lower, scale=scale\n","y = torch.tensor(truncexpon.rvs(b=(1000 - 0) / tau, loc=0, scale=tau), requires_grad=False, device=device, dtype=dtype)  # number of initial newly_infected (seed)\n","\n","# For trunc ((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n","phi = torch.tensor(truncnorm.rvs((0 - 25) / 10, (np.inf - 25) / 10, loc=25, scale=10), requires_grad=True, device=device, dtype=dtype)  # dispersion (shape) parameter for observations\n","R0 = torch.tensor(truncnorm.rvs((2 - 3.6) / 0.8, (5 - 3.6) / 0.8, loc=3.6, scale=0.8), requires_grad=True, device=device, dtype=dtype)  # initial reproduction number\n","alpha = torch.tensor(truncnorm.rvs((0 - 1/100) / 1/100, (5/100 - 1/100) / 1/100, loc=1/100, scale=1/100), requires_grad=True, device=device, dtype=dtype)  # probability to get hospitalized\n","sigma = torch.tensor(truncnorm.rvs((0 - 0.1) / 0.3, (0.5 - 0.1) / 0.3, loc=0.1, scale=0.3), requires_grad=True, device=device, dtype=dtype)  # standart deviation of random walk step"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"gzU80jYUIDWl"},"source":["__From Andreas' model__\n","\n","\"\"\"\n","(model::Covid19Model)(θ) returns the log loglikelihood of our model with\n","respect to the parameters θ together with inferred values of 'Rt' and\n","'expected_daily_hospit'.\n","\n","In a 'standard' machine learning model the loss function is something like\n","loss(y,ŷ,θ) = sum( (y-ŷ)^2 ) + α*θ,\n","where 'y' is the observed outcome, 'ŷ' is the model estimate and α is some\n","regularisation parameter.\n","\n","In a Bayesian framework the first term is called the log loglikelihood of the\n","data wrt. the model and the regularisation term is the log likelihood of our\n","parameters θ wrt. the prior.\n","\n","The 'standard' loss function is a special case of the Bayesian approach which\n","assumes Gaussian distribtions.\n","\"\"\"\n","\n","function evaluate(model::Covid19Model, θ)\n","\t@unpack τ, y, ϕ, R0, α, σ, ϵt = θ\n","\t@unpack num_obs, num_impute, observed_hospit, i2h, pop, si = model\n","    ℓ = 0. #likelihood\n","\n","\t# log likelihood wrt. our prior (\"regularisation\")\n","\tℓ += logpdf( Exponential(1 / 0.03), τ)\n","\tT = typeof(τ)\n","\tℓ += logpdf( truncated(Exponential(τ), T(0), T(1000)), y) # number of initial newly_infected (seed)\n","\tℓ += logpdf( truncated(Normal(25, 5), 0, Inf), ϕ) # dispersion (shape) parameter for observations\n","\tℓ += logpdf( truncated(Normal(3.6, 0.8), 2, 5), R0) # initial reproduction number\n","\tℓ += logpdf( truncated(Normal(1/100,1/100), 0,5/100), α) # probability to get hospitalized\n","\tℓ += logpdf( truncated(Normal(0.05, 0.03), 0, 0.15), σ) # standart deviation of random walk step"]},{"cell_type":"markdown","metadata":{"id":"kFyBW5v9Iu11"},"source":["# Define Forward Pass"]},{"cell_type":"code","metadata":{"id":"v8i41EQqtlfI","executionInfo":{"status":"ok","timestamp":1622618305417,"user_tz":-120,"elapsed":226,"user":{"displayName":"Armsinrius","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64","userId":"02997351779082443110"}}},"source":["def forward_pass():\n","  # Initialize time series variables\n","  newly_infected = torch.zeros(num_observations)  # number of newly infected\n","  effectively_infectious = torch.zeros(num_observations)  # effective number of infectious individuals\n","  expected_daily_hospit = torch.zeros(num_observations)  # expected number of daily hospitalizations\n","  cumulative_infected = torch.zeros(num_observations)  # cumulative number of infected\n","  eta_t = torch.zeros(num_observations)  # transformed reproduction number\n","  epsilon_t = torch.zeros(num_observations)  # random walk\n","  St = torch.zeros(num_observations)  # fraction of susceptible population\n","\n","  # log likelihood wrt. our prior (\"regularisation\")\n","  # ll stands for log-likelihood\n","  ll = torch.tensor(0)\n","  ll += torch.tensor(expon.logpdf(tau_t, 1 / 0.03))\n","  ll += torch.tensor(truncexpon.logpdf(y,b=(1000 - 0) / tau_t, loc=0, scale=tau_t))\n","  ll += torch.tensor(truncnorm.logpdf(phi,(0 - 25) / 10, (np.inf - 25) / 10, loc=25, scale=10))\n","  ll += torch.tensor(truncnorm.logpdf(R0,(2 - 3.6) / 0.8, (5 - 3.6) / 0.8, loc=3.6, scale=0.8))\n","  ll += torch.tensor(truncnorm.logpdf(alpha,(0 - 1/100) / 1/100, (5/100 - 1/100) / 1/100, loc=1/100, scale=1/100))\n","  ll += torch.tensor(truncnorm.logpdf(sigma,(0 - 0.1) / 0.3, (0.5 - 0.1) / 0.3, loc=0.1, scale=0.3))\n","\n","  # seed initial infection / impute first num_impute days\n","  newly_infected[0:num_impute] = y.clone()\n","  cumulative_infected[0] = 0.\n","  cumulative_infected[1:num_impute] = torch.cumsum(newly_infected[0:num_impute - 1].clone(), dim=0)\n","  St[0:num_impute] = torch.tensor([torch.maximum(population.clone() - x, torch.tensor(0)) / population for x in cumulative_infected[0:num_impute].clone()])\n","\n","  # calculate Rt: the basic reproduction number\n","  # basic reproduction number as a latent random walk\n","  beta_0 = torch.log(R0)\n","  #epsilon_t[0] = torch.distributions.Normal(cero, sigma).rsample()\n","  #for t in range(1, num_observations):\n","  #    epsilon_t[t] = torch.distributions.Normal(epsilon_t[t - 1].clone(), sigma).rsample()\n","  #eta_t = beta_0 + epsilon_t  # + RNN[X_t, t]  # .clone() necessary?\n","  eta_t[0] = beta_0\n","  epsilon_t[0] = torch.distributions.Normal(cero, sigma).rsample()\n","  for t in range(1, num_observations):\n","      epsilon_t[t] = torch.distributions.Normal(epsilon_t[t - 1].clone(), sigma).rsample()\n","      dist_epsilon_t = torch.distributions.Normal(epsilon_t[t - 1], sigma)\n","      ll += dist_epsilon_t.log_prob(epsilon_t[t - 1]) #epsilon_t.log_prob(epsilon_t[t - 1])\n","      #eta_t[t] = epsilon_t[t-1]  \n","  eta_t[1:num_observations] = beta_0 + epsilon_t[0:num_observations-1].clone() \n","  Rt = torch.exp(eta_t)\n","\n","  # calculate infections\n","  for t in range(num_impute, num_observations):\n","      # Update cumulative newly_infected\n","      cumulative_infected[t] = cumulative_infected[t - 1].clone() + newly_infected[t - 1].clone()\n","      # Adjusts for portion of pop that are susceptible\n","      St[t] = torch.maximum(population.clone() - cumulative_infected[t].clone(), cero) / population.clone()\n","      # effective number of infectous individuals\n","      for i in range(0, t - 1):\n","          effectively_infectious[t] += newly_infected[i].clone() * serial_interval[t - i].clone()\n","      newly_infected[t] = St[t].clone() * Rt[t].clone() * effectively_infectious[t].clone()\n","\n","  # calculate expected number of hospitalizations\n","  expected_daily_hospit[0] = (1e-15) * newly_infected[0].clone()\n","  for t in range(1, num_observations):\n","      for i in range(0, t - 1):\n","          expected_daily_hospit[t] += newly_infected[i].clone() * pi[t - i].clone()\n","  expected_daily_hospit = alpha * expected_daily_hospit\n","\n","\t# compare observed hospitalizations to model results\n","\t# likelihood of the data wrt. to the model \n","  for i in range(1, num_observations):\n","      dist = torch.distributions.negative_binomial.NegativeBinomial(phi, 1/(1+ expected_daily_hospit[i]/phi))\n","      ll += dist.log_prob(observed_daily_hospit[i])\n","\n","\n","  return expected_daily_hospit, Rt, ll"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8QipthTUuDrS"},"source":["```\n","\t# basic reproduction number as a latent random walk\n","\tβ0 = log(R0)\n","\tηt[1] = β0\n","\tfor t in 2:num_obs\n","\t\tℓ += logpdf( Normal(ηt[t-1], σ), ϵt[t-1]) # log likelihood wrt. our prior (\"regularisation\")\n","\t\tηt[t] = ϵt[t-1] # + RNN[X_t, t]\n","\tend\n","\tRt = exp.(ηt)\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303},"id":"zkc059iZdJry","executionInfo":{"status":"error","timestamp":1622620416925,"user_tz":-120,"elapsed":211,"user":{"displayName":"Armsinrius","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64","userId":"02997351779082443110"}},"outputId":"7452cb06-dc27-409f-8cb2-6208f4af99f3"},"source":["forward_pass()"],"execution_count":27,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-6ef7c359a2f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-3be036be5b26>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# ll stands for log-likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncexpon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtau_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtau_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mlogpdf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \"\"\"\n\u001b[1;32m   1778\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0mdtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."]}]},{"cell_type":"markdown","metadata":{"id":"ot3EWx3k4YMm"},"source":["# Optimization"]},{"cell_type":"code","metadata":{"id":"HmyO5HQzoiNA","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"error","timestamp":1622618308668,"user_tz":-120,"elapsed":221,"user":{"displayName":"Armsinrius","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmkEEyBhULuOzhp9pLdQwgz4RlxxGsKteRl-QXpQ=s64","userId":"02997351779082443110"}},"outputId":"a03fe970-2276-469d-ffd9-bb04c483f301"},"source":["learning_rate = 1e-12\n","for t2 in range(10):\n","\n","  for t in range (40):\n","    # forward pass - calculate expected_daily_hospit\n","    expected_daily_hospit, Rt, ll, theta = forward_pass()\n","\n","    loss = -ll\n","\n","    loss.backward()\n","\n","    print(f'Time Step: {t}, Loss: {loss}, Observed_daily_hospit: {torch.sum(observed_daily_hospit)}, Expected_daily_hospit: {torch.sum(expected_daily_hospit)}')\n","    \n","\n","    with torch.no_grad(): # this part is SGD. can also replace with loss.step\n","      #tau_t -= learning_rate * tau_t.grad\n","      #phi -= learning_rate * phi.grad\n","      R0 -= learning_rate * R0.grad\n","      alpha -= learning_rate * alpha.grad\n","      sigma -= learning_rate * sigma.grad\n","      print(f' R0:{R0}, grad: {R0.grad}, alpha: {alpha} grad: {alpha.grad}, sigma: {sigma} grad {sigma.grad}' )\n","\n","      #tau_t.grad = None\n","      #phi.grad = None\n","      R0.grad = None\n","      alpha.grad = None\n","      sigma.grad = None\n","  \n","  \n","  plt.plot(expected_daily_hospit.detach().numpy(), label='expected_daily_hospit')\n","  plt.plot(observed_daily_hospit.detach().numpy(), label='observed_daily_hospit')\n","  plt.legend()\n","  plt.show()"],"execution_count":18,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-62ea2f404a17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# forward pass - calculate expected_daily_hospit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mexpected_daily_hospit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-3be036be5b26>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# ll stands for log-likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncexpon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtau_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtau_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mlogpdf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \"\"\"\n\u001b[1;32m   1778\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0mdtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."]}]},{"cell_type":"markdown","metadata":{"id":"9KVaHBOjSY4P"},"source":["compare observed hospitalizations to model results"]},{"cell_type":"code","metadata":{"id":"OWOxqWBXSY9i"},"source":["plt.figure(figsize=(10,10))\n","plt.plot(expected_daily_hospit.detach().numpy(), label='expected_daily_hospit')\n","plt.plot(observed_daily_hospit.detach().numpy(), label='observed_daily_hospit')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]}]}